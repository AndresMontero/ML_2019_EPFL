{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'  \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_utils import *\n",
    "from proj1_visualization import *\n",
    "from proj1_cross_validation import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [22]\n",
    "tX_num, tX_cat = split_numerical_categorical(tX,cat_cols)\n",
    "tX_test_num, tX_test_cat = split_numerical_categorical(tX_test,cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat numerical values\n",
    "best_degree = 5\n",
    "full_x_train_num_nan = replace_undef_val_with_nan(tX_num)\n",
    "full_x_train_num_std, train_mean, train_std = nan_standardize_fit(full_x_train_num_nan)\n",
    "full_x_train_num_valid = replace_nan_val_with_median(full_x_train_num_std)\n",
    "full_x_train_num_valid = replace_iqr_outliers(full_x_train_num_valid)\n",
    "# Treat categorical values\n",
    "full_x_train_ohe_cat = one_hot_encode(tX_cat)\n",
    "full_x_train_poly = build_poly(full_x_train_num_valid , best_degree)\n",
    "full_x_train = np.hstack((full_x_train_poly,full_x_train_ohe_cat))\n",
    "# Treat labels\n",
    "full_y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = split_data(full_x_train,full_y_train,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat numerical values\n",
    "x_test_num_nan = replace_undef_val_with_nan(tX_test_num)\n",
    "x_test_num_nan_std = nan_standardize_transform(x_test_num_nan,train_mean,train_std)\n",
    "x_test_num_valid_std = replace_nan_val_with_median(x_test_num_nan_std)\n",
    "x_test_num_valid_std = replace_iqr_outliers(x_test_num_valid_std)\n",
    "# Treat categorical values\n",
    "x_test_ohe_cat = one_hot_encode(tX_test_cat)\n",
    "x_test_poly = build_poly(x_test_num_valid_std , best_degree)\n",
    "x_test = np.hstack((x_test_poly,x_test_ohe_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD(51/2000): loss=0.49997250422331274, w0=-1.5750761808370984e-05, w1=5.72053204078206e-06\n",
      "GD(101/2000): loss=0.49994501529843194, w0=-3.1500017213803604e-05, w1=1.144068521298622e-05\n",
      "GD(151/2000): loss=0.4999175332232653, w0=-4.724776638384222e-05, w1=1.7160459549237987e-05\n",
      "GD(201/2000): loss=0.4998900579957213, w0=-6.299400948600901e-05, w1=2.2879855082159554e-05\n",
      "GD(251/2000): loss=0.49986258961370933, w0=-7.873874668780378e-05, w1=2.8598871844369807e-05\n",
      "GD(301/2000): loss=0.4998351280751394, w0=-9.448197815670415e-05, w1=3.431750986848433e-05\n",
      "GD(351/2000): loss=0.49980767337792187, w0=-0.00011022370406016555, w1=4.003576918711536e-05\n",
      "GD(401/2000): loss=0.49978022551996865, w0=-0.00012596392456562118, w1=4.575364983287184e-05\n",
      "GD(451/2000): loss=0.49975278449919136, w0=-0.0001417026398404819, w1=5.147115183835939e-05\n",
      "GD(501/2000): loss=0.4997253503135031, w0=-0.00015743985005213645, w1=5.7188275236180366e-05\n",
      "GD(551/2000): loss=0.4996979229608176, w0=-0.0001731755553679511, w1=6.290502005893374e-05\n",
      "GD(601/2000): loss=0.4996705024390489, w0=-0.00018890975595527024, w1=6.862138633921529e-05\n",
      "GD(651/2000): loss=0.49964308874611185, w0=-0.00020464245198141578, w1=7.433737410961731e-05\n",
      "GD(701/2000): loss=0.4996156818799225, w0=-0.00022037364361368765, w1=8.005298340272897e-05\n",
      "GD(751/2000): loss=0.49958828183839726, w0=-0.0002361033310193634, w1=8.576821425113602e-05\n",
      "GD(801/2000): loss=0.4995608886194531, w0=-0.00025183151436569836, w1=9.148306668742088e-05\n",
      "GD(851/2000): loss=0.49953350222100806, w0=-0.00026755819381992576, w1=9.719754074416272e-05\n",
      "GD(901/2000): loss=0.49950612264098027, w0=-0.0002832833695492564, w1=0.00010291163645393744\n",
      "GD(951/2000): loss=0.4994787498772897, w0=-0.0002990070417208792, w1=0.00010862535384931752\n",
      "GD(1001/2000): loss=0.4994513839278558, w0=-0.00031472921050196056, w1=0.00011433869296287231\n",
      "GD(1051/2000): loss=0.4994240247905996, w0=-0.00033044987605964515, w1=0.00012005165382716756\n",
      "GD(1101/2000): loss=0.4993966724634421, w0=-0.0003461690385610548, w1=0.00012576423647476604\n",
      "GD(1151/2000): loss=0.4993693269443061, w0=-0.0003618866981732895, w1=0.00013147644093822707\n",
      "GD(1201/2000): loss=0.49934198823111414, w0=-0.00037760285506342745, w1=0.00013718826725010662\n",
      "GD(1251/2000): loss=0.4993146563217894, w0=-0.00039331750939852403, w1=0.00014289971544295747\n",
      "GD(1301/2000): loss=0.49928733121425684, w0=-0.00040903066134561267, w1=0.00014861078554932877\n",
      "GD(1351/2000): loss=0.4992600129064412, w0=-0.00042474231107170483, w1=0.00015432147760176696\n",
      "GD(1401/2000): loss=0.4992327013962679, w0=-0.00044045245874378946, w1=0.00016003179163281476\n",
      "GD(1451/2000): loss=0.4992053966816636, w0=-0.00045616110452883357, w1=0.0001657417276750115\n",
      "GD(1501/2000): loss=0.49917809876055563, w0=-0.0004718682485937818, w1=0.00017145128576089353\n",
      "GD(1551/2000): loss=0.4991508076308716, w0=-0.0004875738911055571, w1=0.0001771604659229937\n",
      "GD(1601/2000): loss=0.4991235232905402, w0=-0.0005032780322310596, w1=0.00018286926819384148\n",
      "GD(1651/2000): loss=0.49909624573749023, w0=-0.0005189806721371678, w1=0.00018857769260596327\n",
      "GD(1701/2000): loss=0.49906897496965247, w0=-0.000534681810990738, w1=0.00019428573919188206\n",
      "GD(1751/2000): loss=0.4990417109849569, w0=-0.0005503814489586038, w1=0.00019999340798411744\n",
      "GD(1801/2000): loss=0.49901445378133524, w0=-0.0005660795862075777, w1=0.00020570069901518602\n",
      "GD(1851/2000): loss=0.49898720335671976, w0=-0.0005817762229044487, w1=0.00021140761231760067\n",
      "GD(1901/2000): loss=0.49895995970904283, w0=-0.0005974713592159851, w1=0.00021711414792387123\n",
      "GD(1951/2000): loss=0.4989327228362384, w0=-0.0006131649953089321, w1=0.00022282030586650417\n",
      "GD(2001/2000): loss=0.4989054927362406, w0=-0.0006288571313500135, w1=0.00022852608617800278\n",
      "GD(51/2000): loss=0.49989910050054215, w0=-1.574588295076153e-05, w1=5.720100345120052e-06\n",
      "GD(101/2000): loss=0.49979832032127003, w0=-3.14803081716545e-05, w1=1.1438941338888604e-05\n",
      "GD(151/2000): loss=0.49969765928992343, w0=-4.720328419711462e-05, w1=1.7156523814645786e-05\n",
      "GD(201/2000): loss=0.49959711723450356, w0=-6.291481955508044e-05, w1=2.2872848605098555e-05\n",
      "GD(251/2000): loss=0.4994966939832719, w0=-7.861492276699825e-05, w1=2.85879165423212e-05\n",
      "GD(301/2000): loss=0.49939638936475045, w0=-9.430360234782707e-05, w1=3.430172845775581e-05\n",
      "GD(351/2000): loss=0.4992962032077214, w0=-0.00010998086680604379, w1=4.001428518221283e-05\n",
      "GD(401/2000): loss=0.49919613534122587, w0=-0.00012564672464364805, w1=4.572558754587145e-05\n",
      "GD(451/2000): loss=0.4990961855945642, w0=-0.0001413011843561672, w1=5.143563637828016e-05\n",
      "GD(501/2000): loss=0.4989963537972956, w0=-0.00015694425443266117, w1=5.7144432508357295e-05\n",
      "GD(551/2000): loss=0.4988966397792377, w0=-0.0001725759433557277, w1=6.285197676439126e-05\n",
      "GD(601/2000): loss=0.4987970433704654, w0=-0.0001881962596015074, w1=6.855826997404139e-05\n",
      "GD(651/2000): loss=0.49869756440131174, w0=-0.00020380521163968832, w1=7.426331296433815e-05\n",
      "GD(701/2000): loss=0.49859820270236627, w0=-0.0002194028079335111, w1=7.99671065616837e-05\n",
      "GD(751/2000): loss=0.4984989581044759, w0=-0.00023498905693977387, w1=8.566965159185242e-05\n",
      "GD(801/2000): loss=0.4983998304387436, w0=-0.00025056396710883755, w1=9.137094887999139e-05\n",
      "GD(851/2000): loss=0.49830081953652783, w0=-0.00026612754688463025, w1=9.707099925062077e-05\n",
      "GD(901/2000): loss=0.49820192522944307, w0=-0.0002816798047046527, w1=0.0001027698035276345\n",
      "GD(951/2000): loss=0.4981031473493585, w0=-0.00029722074899998313, w1=0.00010846736253430046\n",
      "GD(1001/2000): loss=0.49800448572839867, w0=-0.0003127503881952816, w1=0.00011416367709326137\n",
      "GD(1051/2000): loss=0.4979059401989421, w0=-0.0003282687307087959, w1=0.00011985874802653487\n",
      "GD(1101/2000): loss=0.497807510593621, w0=-0.0003437757849523658, w1=0.00012555257615551416\n",
      "GD(1151/2000): loss=0.49770919674532144, w0=-0.00035927155933142827, w1=0.00013124516230096864\n",
      "GD(1201/2000): loss=0.4976109984871827, w0=-0.0003747560622450223, w1=0.00013693650728304404\n",
      "GD(1251/2000): loss=0.49751291565259675, w0=-0.00039022930208579347, w1=0.00014262661192126328\n",
      "GD(1301/2000): loss=0.4974149480752078, w0=-0.0004056912872399998, w1=0.0001483154770345267\n",
      "GD(1351/2000): loss=0.4973170955889126, w0=-0.00042114202608751594, w1=0.0001540031034411127\n",
      "GD(1401/2000): loss=0.49721935802785866, w0=-0.00043658152700183807, w1=0.00015968949195867803\n",
      "GD(1451/2000): loss=0.49712173522644565, w0=-0.00045200979835008945, w1=0.0001653746434042584\n",
      "GD(1501/2000): loss=0.49702422701932325, w0=-0.00046742684849302433, w1=0.00017105855859426896\n",
      "GD(1551/2000): loss=0.49692683324139236, w0=-0.00048283268578503373, w1=0.00017674123834450476\n",
      "GD(1601/2000): loss=0.49682955372780335, w0=-0.0004982273185741498, w1=0.00018242268347014112\n",
      "GD(1651/2000): loss=0.4967323883139565, w0=-0.0005136107552020509, w1=0.00018810289478573438\n",
      "GD(1701/2000): loss=0.4966353368355015, w0=-0.0005289830040040665, w1=0.000193781873105222\n",
      "GD(1751/2000): loss=0.4965383991283367, w0=-0.0005443440733091822, w1=0.00019945961924192334\n",
      "GD(1801/2000): loss=0.4964415750286095, w0=-0.0005596939714400444, w1=0.00020513613400854007\n",
      "GD(1851/2000): loss=0.49634486437271486, w0=-0.0005750327067129654, w1=0.0002108114182171566\n",
      "GD(1901/2000): loss=0.49624826699729574, w0=-0.0005903602874379276, w1=0.00021648547267924057\n",
      "GD(1951/2000): loss=0.49615178273924276, w0=-0.0006056767219185896, w1=0.0002221582982056433\n",
      "GD(2001/2000): loss=0.49605541143569315, w0=-0.0006209820184522896, w1=0.00022782989560660025\n",
      "GD(51/2000): loss=0.4998666077888845, w0=-1.574549172719814e-05, w1=5.7202254835250275e-06\n",
      "GD(101/2000): loss=0.4997334045639643, w0=-3.147872902865036e-05, w1=1.1439446793697942e-05\n",
      "GD(151/2000): loss=0.49960038999195167, w0=-4.719972304015288e-05, w1=1.715766445089112e-05\n",
      "GD(201/2000): loss=0.4994675637402326, w0=-6.290848488560186e-05, w1=2.287487897472621e-05\n",
      "GD(251/2000): loss=0.49933492547686725, w0=-7.860502567700784e-05, w1=2.8591090884075494e-05\n",
      "GD(301/2000): loss=0.4992024748705859, w0=-9.428935651451008e-05, w1=3.430630069706317e-05\n",
      "GD(351/2000): loss=0.49907021159078874, w0=-0.00010996148848639093, w1=4.002050893106677e-05\n",
      "GD(401/2000): loss=0.4989381353075455, w0=-0.0001256214326690901, w1=4.573371610271842e-05\n",
      "GD(451/2000): loss=0.4988062456915916, w0=-0.0001412692001272191, w1=5.144592272790616e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD(501/2000): loss=0.49867454241432807, w0=-0.00015690480191357542, w1=5.715712932177536e-05\n",
      "GD(551/2000): loss=0.4985430251478199, w0=-0.00017252824906915676, w1=6.286733639872991e-05\n",
      "GD(601/2000): loss=0.49841169356479487, w0=-0.00018813955262317542, w1=6.857654447243364e-05\n",
      "GD(651/2000): loss=0.4982805473386405, w0=-0.00020373872359307236, w1=7.428475405581171e-05\n",
      "GD(701/2000): loss=0.4981495861434045, w0=-0.00021932577298453178, w1=7.999196566105173e-05\n",
      "GD(751/2000): loss=0.49801880965379214, w0=-0.00023490071179149488, w1=8.56981797996051e-05\n",
      "GD(801/2000): loss=0.4978882175451654, w0=-0.00025046355099617423, w1=9.140339698218864e-05\n",
      "GD(851/2000): loss=0.4977578094935403, w0=-0.0002660143015690679, w1=9.710761771878547e-05\n",
      "GD(901/2000): loss=0.49762758517558736, w0=-0.0002815529744689736, w1=0.00010281084251864656\n",
      "GD(951/2000): loss=0.497497544268628, w0=-0.00029707958064300303, w1=0.00010851307189029188\n",
      "GD(1001/2000): loss=0.49736768645063484, w0=-0.00031259413102659595, w1=0.0001142143063415121\n",
      "GD(1051/2000): loss=0.497238011400229, w0=-0.00032809663654353316, w1=0.00011991454637936934\n",
      "GD(1101/2000): loss=0.49710851879667955, w0=-0.0003435871081059529, w1=0.00012561379251019888\n",
      "GD(1151/2000): loss=0.4969792083199012, w0=-0.0003590655566143624, w1=0.00013131204523961015\n",
      "GD(1201/2000): loss=0.49685007965045347, w0=-0.00037453199295765354, w1=0.0001370093050724884\n",
      "GD(1251/2000): loss=0.49672113246953936, w0=-0.0003899864280131162, w1=0.00014270557251299559\n",
      "GD(1301/2000): loss=0.4965923664590025, w0=-0.0004054288726464524, w1=0.00014840084806457194\n",
      "GD(1351/2000): loss=0.4964637813013282, w0=-0.00042085933771179054, w1=0.00015409513222993708\n",
      "GD(1401/2000): loss=0.4963353766796395, w0=-0.00043627783405169896, w1=0.0001597884255110915\n",
      "GD(1451/2000): loss=0.4962071522776973, w0=-0.0004516843724971997, w1=0.00016548072840931786\n",
      "GD(1501/2000): loss=0.4960791077798982, w0=-0.0004670789638677834, w1=0.00017117204142518198\n",
      "GD(1551/2000): loss=0.4959512428712735, w0=-0.00048246161897142186, w1=0.00017686236505853425\n",
      "GD(1601/2000): loss=0.4958235572374876, w0=-0.0004978323486045827, w1=0.00018255169980851106\n",
      "GD(1651/2000): loss=0.49569605056483623, w0=-0.0005131911635522442, w1=0.0001882400461735359\n",
      "GD(1701/2000): loss=0.49556872254024564, w0=-0.0005285380745879069, w1=0.00019392740465132082\n",
      "GD(1751/2000): loss=0.4954415728512708, w0=-0.0005438730924736088, w1=0.00019961377573886755\n",
      "GD(1801/2000): loss=0.49531460118609427, w0=-0.00055919622795994, w1=0.0002052991599324687\n",
      "GD(1851/2000): loss=0.4951878072335239, w0=-0.0005745074917860538, w1=0.00021098355772770927\n",
      "GD(1901/2000): loss=0.49506119068299337, w0=-0.0005898068946796838, w1=0.00021666696961946747\n",
      "GD(1951/2000): loss=0.4949347512245579, w0=-0.0006050944473571554, w1=0.00022234939610191678\n",
      "GD(2001/2000): loss=0.4948084885488961, w0=-0.0006203701605233996, w1=0.0002280308376685263\n",
      "1\n",
      "0\n",
      "0.69064\n",
      "[[0.69064]\n",
      " [0.6566 ]\n",
      " [0.66808]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 1\n",
    "degrees = np.asarray(range(1,4))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(50/2000): loss=0.4999560328730805, w(0)=-1.7999494721739857e-05, w1=3.5480791707477293e-06\n",
      "SGD(100/2000): loss=0.5001926794149707, w(0)=-3.399670654765714e-05, w1=1.0489958052191082e-05\n",
      "SGD(150/2000): loss=0.4996817964838604, w(0)=-5.1992623872818504e-05, w1=1.3375506850854295e-05\n",
      "SGD(200/2000): loss=0.49961034577844315, w(0)=-7.198936799854934e-05, w1=2.36637956134491e-05\n",
      "SGD(250/2000): loss=0.5003647068815094, w(0)=-8.39825402078926e-05, w1=2.823389416660846e-05\n",
      "SGD(300/2000): loss=0.49992163320844546, w(0)=-0.00010997139578886805, w1=3.3456361532792676e-05\n",
      "SGD(350/2000): loss=0.49938066192564445, w(0)=-0.0001299581496448557, w1=3.814024383261656e-05\n",
      "SGD(400/2000): loss=0.4995744662692441, w(0)=-0.00014594592209955548, w1=3.7837670888478076e-05\n",
      "SGD(450/2000): loss=0.5005391964889622, w(0)=-0.00015792810810679348, w1=4.704865296964899e-05\n",
      "SGD(500/2000): loss=0.5001973942162212, w(0)=-0.00017790936626798227, w1=5.55638469687169e-05\n",
      "SGD(550/2000): loss=0.5000674954478292, w(0)=-0.0001958924469887238, w1=5.868068685671567e-05\n",
      "SGD(600/2000): loss=0.5004918472268828, w(0)=-0.00022186905190885135, w1=6.267544022026408e-05\n",
      "SGD(650/2000): loss=0.5002505385346953, w(0)=-0.00023985106889768746, w1=7.30116297486714e-05\n",
      "SGD(700/2000): loss=0.4990493888375584, w(0)=-0.00025782371918221456, w1=7.762022002396391e-05\n",
      "SGD(750/2000): loss=0.5007738802967074, w(0)=-0.00027978567844677945, w1=8.479849398883905e-05\n",
      "SGD(800/2000): loss=0.49809226188251243, w(0)=-0.00029176236020024934, w1=9.123099353895322e-05\n",
      "SGD(850/2000): loss=0.5002930195956794, w(0)=-0.00030973834919809123, w1=9.552125074055433e-05\n",
      "SGD(900/2000): loss=0.5000849010732262, w(0)=-0.00032170122331118663, w1=0.00010075355381298452\n",
      "SGD(950/2000): loss=0.4980349268552071, w(0)=-0.0003376639384979387, w1=0.00010765821233118472\n",
      "SGD(1000/2000): loss=0.49878057434236683, w(0)=-0.00034763525044063427, w1=0.00011775126307879766\n",
      "SGD(1050/2000): loss=0.4990225101039216, w(0)=-0.00036558883898662976, w1=0.00011946586140824155\n",
      "SGD(1100/2000): loss=0.5000302092802922, w(0)=-0.0003735535417726031, w1=0.00012796704716078327\n",
      "SGD(1150/2000): loss=0.4990667925305608, w(0)=-0.00038152290154241713, w1=0.00012298605273773798\n",
      "SGD(1200/2000): loss=0.4976173595398367, w(0)=-0.0003974818212901733, w1=0.00013312716524241272\n",
      "SGD(1250/2000): loss=0.4986969984462488, w(0)=-0.0004094494816705126, w1=0.00014056167148427117\n",
      "SGD(1300/2000): loss=0.5018902653354955, w(0)=-0.00042341412532732376, w1=0.00014542229442775136\n",
      "SGD(1350/2000): loss=0.49787381410427634, w(0)=-0.0004533748483784811, w1=0.00015302090248925994\n",
      "SGD(1400/2000): loss=0.49730781804854607, w(0)=-0.00047332218088138775, w1=0.00016169357582730484\n",
      "SGD(1450/2000): loss=0.500661576393225, w(0)=-0.000485266044327785, w1=0.0001704231416664758\n",
      "SGD(1500/2000): loss=0.5023582370747631, w(0)=-0.0004992302048158798, w1=0.00018010323913305438\n",
      "SGD(1550/2000): loss=0.5008271657975527, w(0)=-0.000503179742577448, w1=0.00018774578503266286\n",
      "SGD(1600/2000): loss=0.4992700573074712, w(0)=-0.0005151187765492465, w1=0.00019320917594695136\n",
      "SGD(1650/2000): loss=0.49735079961097767, w(0)=-0.0005370638569065949, w1=0.00020569173130064909\n",
      "SGD(1700/2000): loss=0.5000045164655116, w(0)=-0.0005489929348877437, w1=0.00020735195886312845\n",
      "SGD(1750/2000): loss=0.5020237195598807, w(0)=-0.0005629660943298411, w1=0.00021383285442051444\n",
      "SGD(1800/2000): loss=0.49939057700448375, w(0)=-0.0005729136968917678, w1=0.00021675296254208498\n",
      "SGD(1850/2000): loss=0.4978467445558795, w(0)=-0.0005808698452519763, w1=0.00022680170134095067\n",
      "SGD(1900/2000): loss=0.49992766713005393, w(0)=-0.000596801398417472, w1=0.00023647837406464374\n",
      "SGD(1950/2000): loss=0.4977924118662855, w(0)=-0.0006087281988484144, w1=0.00023794870501171538\n",
      "SGD(2000/2000): loss=0.5030625413335145, w(0)=-0.0006226771360314885, w1=0.0002460389461568933\n",
      "SGD(50/2000): loss=0.5000667224233023, w(0)=-1.199748524317055e-05, w1=1.9022068554849966e-06\n",
      "SGD(100/2000): loss=0.49927915422399627, w(0)=-3.997504270670089e-05, w1=6.205879349942255e-06\n",
      "SGD(150/2000): loss=0.4996822927654351, w(0)=-4.7944760941946675e-05, w1=1.1552635526554412e-05\n",
      "SGD(200/2000): loss=0.5004508683288603, w(0)=-6.78994596909545e-05, w1=1.7625610953343185e-05\n",
      "SGD(250/2000): loss=0.49859196416802504, w(0)=-7.984749865458122e-05, w1=2.0587995577511925e-05\n",
      "SGD(300/2000): loss=0.4990982579625731, w(0)=-9.578437272968559e-05, w1=2.4723251728265006e-05\n",
      "SGD(350/2000): loss=0.49846444576331705, w(0)=-9.971641099391896e-05, w1=2.0373467267003593e-05\n",
      "SGD(400/2000): loss=0.4977456557015348, w(0)=-0.00011563464044298984, w1=2.0038807686669452e-05\n",
      "SGD(450/2000): loss=0.4962701472246318, w(0)=-0.00013754411309033497, w1=2.386346500751935e-05\n",
      "SGD(500/2000): loss=0.497741914210788, w(0)=-0.00015344873708556287, w1=3.0002867810959237e-05\n",
      "SGD(550/2000): loss=0.4960296159879617, w(0)=-0.00017133137411160974, w1=3.4252414092353773e-05\n",
      "SGD(600/2000): loss=0.495769454715381, w(0)=-0.00019119447199045415, w1=4.130328073805223e-05\n",
      "SGD(650/2000): loss=0.5014544723753619, w(0)=-0.00020106139794557758, w1=4.828033146085496e-05\n",
      "SGD(700/2000): loss=0.4942927400130552, w(0)=-0.0002209135183823495, w1=5.4144929398187386e-05\n",
      "SGD(750/2000): loss=0.5021327109585858, w(0)=-0.00023674684946145362, w1=6.681641803012967e-05\n",
      "SGD(800/2000): loss=0.4977870740142882, w(0)=-0.00025058299548054, w1=7.581629800672298e-05\n",
      "SGD(850/2000): loss=0.494910084582018, w(0)=-0.00026240692005097147, w1=7.718555775827922e-05\n",
      "SGD(900/2000): loss=0.5011121310874767, w(0)=-0.0002802220532879943, w1=8.054260836824795e-05\n",
      "SGD(950/2000): loss=0.5021607099917408, w(0)=-0.0003039994399230229, w1=8.81071129515282e-05\n",
      "SGD(1000/2000): loss=0.4979891235334622, w(0)=-0.00031777992958975453, w1=9.672938726943968e-05\n",
      "SGD(1050/2000): loss=0.4937641419632722, w(0)=-0.0003255667873066453, w1=0.00010174317415828217\n",
      "SGD(1100/2000): loss=0.4951162774775504, w(0)=-0.00033933617854086236, w1=0.00010783316029801273\n",
      "SGD(1150/2000): loss=0.49592313326298965, w(0)=-0.0003610805624053546, w1=0.00011602647545171457\n",
      "SGD(1200/2000): loss=0.4948951892051771, w(0)=-0.00038880357271100634, w1=0.0001282947044016858\n",
      "SGD(1250/2000): loss=0.5025665026522959, w(0)=-0.00040051972686603595, w1=0.00013322853622327218\n",
      "SGD(1300/2000): loss=0.49239565251348505, w(0)=-0.0004222330255248388, w1=0.00013974113563279322\n",
      "SGD(1350/2000): loss=0.4946794217705113, w(0)=-0.0004359157845921589, w1=0.00014479595066822583\n",
      "SGD(1400/2000): loss=0.49353319492025066, w(0)=-0.00045363565687021434, w1=0.00015303330180278479\n",
      "SGD(1450/2000): loss=0.4913435091757419, w(0)=-0.00047132742277350897, w1=0.00016304705680938303\n",
      "SGD(1500/2000): loss=0.49318246689542683, w(0)=-0.0004889963220357287, w1=0.00016987863797203503\n",
      "SGD(1550/2000): loss=0.4922816594728503, w(0)=-0.0004986099954811817, w1=0.000166548535694377\n",
      "SGD(1600/2000): loss=0.49260143269706375, w(0)=-0.0005142573440713929, w1=0.000174679997229214\n",
      "SGD(1650/2000): loss=0.5039465208941232, w(0)=-0.0005318729587398065, w1=0.00017638077167815382\n",
      "SGD(1700/2000): loss=0.4931382735075043, w(0)=-0.000547491998478004, w1=0.0001810653385201769\n",
      "SGD(1750/2000): loss=0.4891894785346663, w(0)=-0.0005610970308017202, w1=0.00018498273112648107\n",
      "SGD(1800/2000): loss=0.5091659779549885, w(0)=-0.0005806695488148911, w1=0.00019444320035198788\n",
      "SGD(1850/2000): loss=0.5045457237818477, w(0)=-0.0005962557275316456, w1=0.00019962386652138165\n",
      "SGD(1900/2000): loss=0.48281809943232623, w(0)=-0.0006217158629116671, w1=0.00020716131736855782\n",
      "SGD(1950/2000): loss=0.5080671854372798, w(0)=-0.0006312780611385714, w1=0.00021352847805164663\n",
      "SGD(2000/2000): loss=0.5051212722225311, w(0)=-0.0006408200864145556, w1=0.0002192087179551559\n",
      "1\n",
      "0\n",
      "0.69008\n",
      "[[0.69008]\n",
      " [0.6566 ]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 2\n",
    "degrees = np.asarray(range(1,3))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0.6566\n",
      "[[0.6566]\n",
      " [0.3434]\n",
      " [0.3434]\n",
      " [0.3434]\n",
      " [0.6566]\n",
      " [0.6566]\n",
      " [0.6566]\n",
      " [0.3434]\n",
      " [0.3434]\n",
      " [0.6566]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 3\n",
    "degrees = np.asarray(range(1,11))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1e-06\n",
      "0.817\n",
      "[[0.81652 0.8166 ]\n",
      " [0.81688 0.817  ]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 4\n",
    "degrees = np.asarray(range(4,6))\n",
    "lambdas = np.logspace(-7,-6,2)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "#Iteration: 0, Loss: 138629.4361119856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianvillarroel/Documents/Docs_Adrian/EPFL/Courses/Machine_learning/ML_2019_EPFL/projects/project1/scripts/implementations_utils.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = y.T.dot(np.log(pred)) + (1 - y).T.dot(np.log(1 - pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 250, Loss: 153950.50504662874\n",
      "#Iteration: 500, Loss: nan\n",
      "#Iteration: 750, Loss: 153839.02954251014\n",
      "#Iteration: 1000, Loss: nan\n",
      "#Iteration: 1250, Loss: 153548.70853493735\n",
      "#Iteration: 1500, Loss: nan\n",
      "#Iteration: 1750, Loss: 153198.40905724769\n",
      "#Iteration: 2000, Loss: nan\n",
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 153950.50504662874\n",
      "#Iteration: 500, Loss: nan\n",
      "#Iteration: 750, Loss: 153839.02954251014\n",
      "#Iteration: 1000, Loss: nan\n",
      "#Iteration: 1250, Loss: 153548.70853493735\n",
      "#Iteration: 1500, Loss: nan\n",
      "#Iteration: 1750, Loss: 153198.40905724769\n",
      "#Iteration: 2000, Loss: nan\n",
      "5\n",
      "1e-07\n",
      "0.79502\n",
      "[[0.79052 0.79052]\n",
      " [0.79502 0.79502]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 5\n",
    "degrees = np.asarray(range(4,6))\n",
    "lambdas = np.logspace(-7,-6,2)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "4\n",
      "1e-07\n",
      "0.79052\n",
      "[[0.79052 0.79052]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 5\n",
    "degrees = np.asarray(range(4,5))\n",
    "lambdas = np.logspace(-7,-6,2)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = 1e-5\n",
    "lambda_ = best_lambda\n",
    "weights, loss = ridge_regression(y_train,x_train,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = least_squares(y_train,x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD(51/2000): loss=0.498008967536016, w0=-3.428704855974191e-05, w1=1.2542584521976463e-05\n",
      "GD(101/2000): loss=0.4961789938662344, w0=-6.817374129066865e-05, w1=2.5114613293158463e-05\n",
      "GD(151/2000): loss=0.494488630926867, w0=-0.00010167693092135272, w1=3.771292478816873e-05\n",
      "GD(201/2000): loss=0.4929194976044192, w0=-0.00013481234907622975, w1=5.0334568769426166e-05\n",
      "GD(251/2000): loss=0.4914558345624867, w0=-0.0001675946883977117, w1=6.2976791681685e-05\n",
      "GD(301/2000): loss=0.49008412401576157, w0=-0.00020003767849343835, w1=7.563702309685602e-05\n",
      "GD(351/2000): loss=0.48879276495615576, w0=-0.00023215415617703437, w1=8.831286313174699e-05\n",
      "GD(401/2000): loss=0.4875717957253721, w0=-0.0002639561304351158, w1=0.0001010020707671358\n",
      "GD(451/2000): loss=0.48641265701427655, w0=-0.00029545484252036197, w1=0.0001137025530019339\n",
      "GD(501/2000): loss=0.48530798938182923, w0=-0.0003266608215400682, w1=0.00012641235478113563\n",
      "GD(551/2000): loss=0.4842514602505461, w0=-0.0003575839358814899, w1=0.00013912964964082073\n",
      "GD(601/2000): loss=0.4832376160731641, w0=-0.00038823344078933535, w1=0.0001518527310176998\n",
      "GD(651/2000): loss=0.48226175599492704, w0=-0.0004186180223867866, w1=0.00016458000417460242\n",
      "GD(701/2000): loss=0.48131982387345806, w0=-0.0004487458384092659, w1=0.00017730997869692104\n",
      "GD(751/2000): loss=0.48040831597708883, w0=-0.0004786245558997047, w1=0.00019004126151836797\n",
      "GD(801/2000): loss=0.479524202074234, w0=-0.0005082613860951545, w1=0.0002027725504374915\n",
      "GD(851/2000): loss=0.47866485796081437, w0=-0.0005376631167171172, w1=0.00021550262808926228\n",
      "GD(901/2000): loss=0.47782800775820233, w0=-0.0005668361418618231, w1=0.00022823035633868228\n",
      "GD(951/2000): loss=0.4770116745578695, w0=-0.0005957864896717794, w1=0.00024095467106581884\n",
      "GD(1001/2000): loss=0.47621413819695935, w0=-0.0006245198479561325, w1=0.0002536745773139288\n",
      "GD(1051/2000): loss=0.4754338991266297, w0=-0.0006530415879146609, w1=0.0002663891447744337\n",
      "GD(1101/2000): loss=0.4746696474866291, w0=-0.000681356786108453, w1=0.00027909750358444423\n",
      "GD(1151/2000): loss=0.4739202366290366, w0=-0.0007094702448094658, w1=0.0002917988404143238\n",
      "GD(1201/2000): loss=0.4731846604446012, w0=-0.0007373865108511169, w1=0.0003044923948244433\n",
      "GD(1251/2000): loss=0.47246203393949077, w0=-0.0007651098930927917, w1=0.0003171774558718101\n",
      "GD(1301/2000): loss=0.47175157659080846, w0=-0.0007926444786025825, w1=0.00032985335894867895\n",
      "GD(1351/2000): loss=0.4710525980780313, w0=-0.0008199941476546545, w1=0.0003425194828365641\n",
      "GD(1401/2000): loss=0.47036448604624914, w0=-0.0008471625876303248, w1=0.00035517524696028897\n",
      "GD(1451/2000): loss=0.4696866956072312, w0=-0.000874153305905184, w1=0.0003678201088278362\n",
      "GD(1501/2000): loss=0.4690187403271699, w0=-0.0009009696417983436, w1=0.000380453561642804\n",
      "GD(1551/2000): loss=0.4683601844865141, w0=-0.0009276147776541267, w1=0.00039307513207723587\n",
      "GD(1601/2000): loss=0.46771063642852995, w0=-0.0009540917491211915, w1=0.0004056843781934883\n",
      "GD(1651/2000): loss=0.46706974283988933, w0=-0.000980403454689149, w1=0.000418280887504624\n",
      "GD(1701/2000): loss=0.4664371838293627, w0=-0.0010065526645381957, w1=0.0004308642751635835\n",
      "GD(1751/2000): loss=0.46581266869013915, w0=-0.0010325420287530642, w1=0.0004434341822721\n",
      "GD(1801/2000): loss=0.46519593224791, w0=-0.001058374084948731, w1=0.00045599027430097525\n",
      "GD(1851/2000): loss=0.46458673171103715, w0=-0.0010840512653517138, w1=0.00046853223961393955\n",
      "GD(1901/2000): loss=0.4639848439512559, w0=-0.0011095759033774798, w1=0.0004810597880878894\n",
      "GD(1951/2000): loss=0.4633900631537063, w0=-0.0011349502397414342, w1=0.0004935726498228078\n",
      "GD(2001/2000): loss=0.46280219878394036, w0=-0.00116017642813812, w1=0.0005060705739351594\n",
      "GD(51/2000): loss=0.49802219216206556, w0=-3.4529973487376946e-05, w1=1.2606556830168696e-05\n",
      "GD(101/2000): loss=0.4961962040701439, w0=-6.864894483250921e-05, w1=2.5235181520065487e-05\n",
      "GD(151/2000): loss=0.49450254205150945, w0=-0.00010237385370646925, w1=3.788319136289729e-05\n",
      "GD(201/2000): loss=0.4929244289421242, w0=-0.0001357205546253391, w1=5.054807982194765e-05\n",
      "GD(251/2000): loss=0.49144741824077565, w0=-0.00016870389394012456, w1=6.322750459505658e-05\n",
      "GD(301/2000): loss=0.4900590634454973, w0=-0.00020133778118821595, w1=7.591927652197337e-05\n",
      "GD(351/2000): loss=0.4887486346574632, w0=-0.00023363525522436258, w1=8.862134927356708e-05\n",
      "GD(401/2000): loss=0.48750687567421036, w0=-0.0002656085455179987, w1=0.00010133180976635767\n",
      "GD(451/2000): loss=0.48632579576737356, w0=-0.0002972691289749514, w1=0.0001140488692499756\n",
      "GD(501/2000): loss=0.48519849117358665, w0=-0.00032862778261489955, w1=0.0001267708550189984\n",
      "GD(551/2000): loss=0.484118992040936, w0=-0.00035969463241128846, w1=0.00013949620270416814\n",
      "GD(601/2000): loss=0.4830821311845196, w0=-0.0003904791985775697, w1=0.00015222344910128816\n",
      "GD(651/2000): loss=0.4820834315280527, w0=-0.0004209904375625131, w1=0.0001649512254991462\n",
      "GD(701/2000): loss=0.4811190095566408, w0=-0.0004512367809977909, w1=0.00017767825147063844\n",
      "GD(751/2000): loss=0.4801854924896503, w0=-0.00048122617182293166, w1=0.00019040332909388348\n",
      "GD(801/2000): loss=0.47927994721129336, w0=-0.0005109660977960118, w1=0.0002031253375725414\n",
      "GD(851/2000): loss=0.4783998192780071, w0=-0.0005404636225829477, w1=0.00021584322822679644\n",
      "GD(901/2000): loss=0.4775428805627628, w0=-0.0005697254146039206, w1=0.00022855601982854295\n",
      "GD(951/2000): loss=0.4767071843028754, w0=-0.0005987577738021905, w1=0.00024126279425624103\n",
      "GD(1001/2000): loss=0.47589102649467857, w0=-0.0006275666564882835, w1=0.0002539626924466907\n",
      "GD(1051/2000): loss=0.4750929127298364, w0=-0.0006561576984011623, w1=0.0002666549106226314\n",
      "GD(1101/2000): loss=0.474311529697753, w0=-0.0006845362361174807, w1=0.0002793386967766021\n",
      "GD(1151/2000): loss=0.47354572068958994, w0=-0.0007127073269302859, w1=0.00029201334739291634\n",
      "GD(1201/2000): loss=0.4727944645345368, w0=-0.0007406757673095227, w1=0.00030467820439092526\n",
      "GD(1251/2000): loss=0.47205685748045506, w0=-0.0007684461100483631, w1=0.00031733265227395645\n",
      "GD(1301/2000): loss=0.4713320976007951, w0=-0.0007960226801916606, w1=0.0003299761154694482\n",
      "GD(1351/2000): loss=0.4706194713694727, w0=-0.000823409589835696, w1=0.00034260805584684196\n",
      "GD(1401/2000): loss=0.46991834209658867, w0=-0.0008506107518817678, w1=0.0003552279704007702\n",
      "GD(1451/2000): loss=0.46922813996174256, w0=-0.0008776298928200619, w1=0.0003678353890879714\n",
      "GD(1501/2000): loss=0.46854835341926265, w0=-0.000904470564614589, w1=0.0003804298728071981\n",
      "GD(1551/2000): loss=0.4678785217818719, w0=-0.0009311361557547092, w1=0.00039301101151215486\n",
      "GD(1601/2000): loss=0.4672182288168815, w0=-0.0009576299015339463, w1=0.0004055784224482235\n",
      "GD(1651/2000): loss=0.46656709721263906, w0=-0.0009839548936122896, w1=0.0004181317485043875\n",
      "GD(1701/2000): loss=0.4659247837932023, w0=-0.0010101140889140164, w1=0.00043067065667239075\n",
      "GD(1751/2000): loss=0.4652909753765601, w0=-0.001036110317909253, w1=0.00044319483660572973\n",
      "GD(1801/2000): loss=0.4646653851865866, w0=-0.001061946292323897, w1=0.00045570399927161105\n",
      "GD(1851/2000): loss=0.4640477497416615, w0=-0.001087624612319264, w1=0.0004681978756894924\n",
      "GD(1901/2000): loss=0.4634378261538049, w0=-0.0011131477731797397, w1=0.0004806762157502844\n",
      "GD(1951/2000): loss=0.46283538978153893, w0=-0.0011385181715439163, w1=0.0004931387871107051\n",
      "GD(2001/2000): loss=0.46224023218771254, w0=-0.0011637381112120822, w1=0.0005055853741576749\n",
      "[0.4628022  0.46224023]\n",
      "[0.96214375 0.96150278]\n",
      "[0.675592 0.675296]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 1\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(50/2000): loss=0.501039671462663, w(0)=-2.1927381545026525e-05, w1=1.1068327802511765e-05\n",
      "SGD(100/2000): loss=0.49934926696556037, w(0)=-4.782160013950155e-05, w1=1.0102490916102534e-05\n",
      "SGD(150/2000): loss=0.49776999596434274, w(0)=-0.00010885720708351211, w1=1.5846895104484017e-05\n",
      "SGD(200/2000): loss=0.48007379750805756, w(0)=-0.00014597839527303615, w1=3.1917279663436526e-05\n",
      "SGD(250/2000): loss=0.4804912998071614, w(0)=-0.0002004454026782483, w1=3.7644390118481506e-05\n",
      "SGD(300/2000): loss=0.46663531940065395, w(0)=-0.0002462849903179082, w1=5.550906803256989e-05\n",
      "SGD(350/2000): loss=0.3395710925211699, w(0)=-0.0002955683543515372, w1=7.845587927932728e-05\n",
      "SGD(400/2000): loss=0.4815800425147755, w(0)=-0.0003224920181258003, w1=9.381807635984358e-05\n",
      "SGD(450/2000): loss=0.5276251490783027, w(0)=-0.00033795534764145027, w1=0.00011119067494515082\n",
      "SGD(500/2000): loss=0.4718079376536416, w(0)=-0.0004056496048556763, w1=0.00013378197232042892\n",
      "SGD(550/2000): loss=0.4809293228126758, w(0)=-0.00044041504653636053, w1=0.0001633004582411852\n",
      "SGD(600/2000): loss=0.5100223000293002, w(0)=-0.0004710470739812568, w1=0.0001788635841341258\n",
      "SGD(650/2000): loss=0.47414906455983113, w(0)=-0.0004753972222490671, w1=0.00019239606235729197\n",
      "SGD(700/2000): loss=0.5150511745776241, w(0)=-0.0005146187758329804, w1=0.00020749193472116627\n",
      "SGD(750/2000): loss=0.5114763538515504, w(0)=-0.0005534423277401455, w1=0.00021805404796662836\n",
      "SGD(800/2000): loss=0.5256648091595585, w(0)=-0.0005919953276482971, w1=0.00022615047530681352\n",
      "SGD(850/2000): loss=0.46312507651543416, w(0)=-0.0006125372034759673, w1=0.0002306963046073592\n",
      "SGD(900/2000): loss=0.4695314363851423, w(0)=-0.000661454368469456, w1=0.00024794408942907157\n",
      "SGD(950/2000): loss=0.5864424771775055, w(0)=-0.0007141798083323031, w1=0.00026544025255183993\n",
      "SGD(1000/2000): loss=0.5220294497727287, w(0)=-0.0007317860629065156, w1=0.00028887444880949255\n",
      "SGD(1050/2000): loss=0.4271284387949021, w(0)=-0.0007502684322783009, w1=0.00030119698573959975\n",
      "SGD(1100/2000): loss=0.4893128571861497, w(0)=-0.0007786913165648737, w1=0.0003094484173988442\n",
      "SGD(1150/2000): loss=0.5664932397827587, w(0)=-0.000802104737292623, w1=0.000337420315577236\n",
      "SGD(1200/2000): loss=0.36473646598454906, w(0)=-0.0008322190849466642, w1=0.00036601718784783733\n",
      "SGD(1250/2000): loss=0.469245735199732, w(0)=-0.0008704231634889501, w1=0.000377230038141852\n",
      "SGD(1300/2000): loss=0.46945450492126256, w(0)=-0.0009002336976391054, w1=0.00038484066142869297\n",
      "SGD(1350/2000): loss=0.4243334627703357, w(0)=-0.000924471748646001, w1=0.0004034195897584889\n",
      "SGD(1400/2000): loss=0.4056421402587027, w(0)=-0.0009774205338113227, w1=0.00042266155007570396\n",
      "SGD(1450/2000): loss=0.09034087310161616, w(0)=-0.0009780637869174886, w1=0.0004553691176946126\n",
      "SGD(1500/2000): loss=0.7438629231756454, w(0)=-0.0009880775624953463, w1=0.0004749941132440535\n",
      "SGD(1550/2000): loss=0.5228217515980359, w(0)=-0.0010140861960173156, w1=0.00048120275654976903\n",
      "SGD(1600/2000): loss=0.36197299899206065, w(0)=-0.0010340806184497302, w1=0.00048695551607615746\n",
      "SGD(1650/2000): loss=0.36197243275607704, w(0)=-0.0010518050453863159, w1=0.000493009806692758\n",
      "SGD(1700/2000): loss=0.24900788473729157, w(0)=-0.0010660312012780563, w1=0.0005024210784316032\n",
      "SGD(1750/2000): loss=0.39686263819703865, w(0)=-0.0010841216279210684, w1=0.0005061242244667138\n",
      "SGD(1800/2000): loss=0.4096250422157787, w(0)=-0.0010969040395573959, w1=0.0005171641923084966\n",
      "SGD(1850/2000): loss=0.5012206737780857, w(0)=-0.0011134079813565356, w1=0.0005246166438984276\n",
      "SGD(1900/2000): loss=0.5803908657863962, w(0)=-0.0011425949430443798, w1=0.0005305060740575669\n",
      "SGD(1950/2000): loss=0.5147019858651508, w(0)=-0.0011748917431366327, w1=0.0005251958796145883\n",
      "SGD(2000/2000): loss=0.4952750418785568, w(0)=-0.001192701428395058, w1=0.0005406520954827512\n",
      "SGD(50/2000): loss=0.49622846682689814, w(0)=-5.705645027182261e-05, w1=1.4430344508235711e-05\n",
      "SGD(100/2000): loss=0.5000038990445992, w(0)=-7.416100294184826e-05, w1=2.7751288377512102e-05\n",
      "SGD(150/2000): loss=0.4984893735441652, w(0)=-0.00011718869906824514, w1=4.537401013140371e-05\n",
      "SGD(200/2000): loss=0.5134425005084625, w(0)=-0.0001335655581863885, w1=6.191063054406054e-05\n",
      "SGD(250/2000): loss=0.49604283851253994, w(0)=-0.00017588546479947918, w1=7.614607057085654e-05\n",
      "SGD(300/2000): loss=0.4809057370612761, w(0)=-0.0002009742120331634, w1=9.104266830741398e-05\n",
      "SGD(350/2000): loss=0.49269225874402245, w(0)=-0.00024766023662878734, w1=0.00010548709831999028\n",
      "SGD(400/2000): loss=0.4962844474891147, w(0)=-0.00028089764691261224, w1=0.0001243583700495549\n",
      "SGD(450/2000): loss=0.4778929969076544, w(0)=-0.0003390897387338073, w1=0.00012874203397477953\n",
      "SGD(500/2000): loss=0.5072237304933443, w(0)=-0.0003801635613655709, w1=0.00014833172424376611\n",
      "SGD(550/2000): loss=0.27985406213055464, w(0)=-0.0004198050333102156, w1=0.00015592244142612896\n",
      "SGD(600/2000): loss=0.4857726846913521, w(0)=-0.0004427989744676444, w1=0.00017433579871531884\n",
      "SGD(650/2000): loss=0.35989412712317026, w(0)=-0.00047917046527169575, w1=0.00017905389169850557\n",
      "SGD(700/2000): loss=0.4790008243757417, w(0)=-0.0005543464204443437, w1=0.00020065902903088398\n",
      "SGD(750/2000): loss=0.4776920803829293, w(0)=-0.0005870529610871194, w1=0.0002131337157440471\n",
      "SGD(800/2000): loss=0.4542594457489679, w(0)=-0.0006075092297366543, w1=0.00022334292986154593\n",
      "SGD(850/2000): loss=0.437447673460792, w(0)=-0.0006638005287930183, w1=0.0002523430331191124\n",
      "SGD(900/2000): loss=0.33763340827596205, w(0)=-0.0006929715967537413, w1=0.0002646547422888963\n",
      "SGD(950/2000): loss=0.4682958727490398, w(0)=-0.0007495038269313104, w1=0.00027437436611645787\n",
      "SGD(1000/2000): loss=0.44886918262481423, w(0)=-0.0007807742447608363, w1=0.0002848705507318339\n",
      "SGD(1050/2000): loss=0.4033302820609689, w(0)=-0.0008131923861578055, w1=0.0002985697081218329\n",
      "SGD(1100/2000): loss=0.43366916537349204, w(0)=-0.0008373508067787776, w1=0.00031864779233130064\n",
      "SGD(1150/2000): loss=0.45239233061972567, w(0)=-0.0008738697893241662, w1=0.0003177203572054315\n",
      "SGD(1200/2000): loss=0.5104746304878399, w(0)=-0.0008662821072469353, w1=0.0003248529898289963\n",
      "SGD(1250/2000): loss=0.4795354870530231, w(0)=-0.0008924037522923554, w1=0.00033315712460128507\n",
      "SGD(1300/2000): loss=0.5252030026003796, w(0)=-0.0009182458679639021, w1=0.00033535096561317936\n",
      "SGD(1350/2000): loss=0.4758333038466377, w(0)=-0.0009514301643145854, w1=0.0003557869376071316\n",
      "SGD(1400/2000): loss=0.41463955511807143, w(0)=-0.0009612264324738009, w1=0.0003677216918631217\n",
      "SGD(1450/2000): loss=0.39954535466239666, w(0)=-0.000997622082292491, w1=0.00037727409455392007\n",
      "SGD(1500/2000): loss=0.384708213569975, w(0)=-0.0010118190047469272, w1=0.0003910519286058643\n",
      "SGD(1550/2000): loss=0.44854075005307037, w(0)=-0.0010143471736228146, w1=0.0004087248801203662\n",
      "SGD(1600/2000): loss=0.4791225408514774, w(0)=-0.0010375850725788825, w1=0.0004235259772623843\n",
      "SGD(1650/2000): loss=0.5482955117471754, w(0)=-0.0010779920692104577, w1=0.0004387532744422733\n",
      "SGD(1700/2000): loss=0.4040634604196185, w(0)=-0.0010922070202502875, w1=0.0004561269895995798\n",
      "SGD(1750/2000): loss=0.5080046121524512, w(0)=-0.0011127604048127855, w1=0.00046438189631943657\n",
      "SGD(1800/2000): loss=0.4891652108135847, w(0)=-0.0011561370067255975, w1=0.00046994715562567437\n",
      "SGD(1850/2000): loss=0.3646746625094704, w(0)=-0.001200817361597854, w1=0.0004850773682914351\n",
      "SGD(1900/2000): loss=0.28927261812687677, w(0)=-0.0012621754790807045, w1=0.0005102466738942798\n",
      "SGD(1950/2000): loss=0.48538643983543744, w(0)=-0.0012573553771377287, w1=0.0005274184708090023\n",
      "SGD(2000/2000): loss=0.3149794310473352, w(0)=-0.0013060407056816356, w1=0.00053208791122281\n",
      "[0.49527504 0.31497943]\n",
      "[0.96212014 0.96104572]\n",
      "[0.67208  0.667984]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 2\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2730447  0.27282586]\n",
      "[  76886.14547321 1538054.20836699]\n",
      "[0.657896 0.656768]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 3\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2730471  0.27283294]\n",
      "[0.73954686 0.7399415 ]\n",
      "[0.81504  0.815104]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 4\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 86643.3975699927\n",
      "#Iteration: 250, Loss: 52616.21519581793\n",
      "#Iteration: 500, Loss: 51958.76076355233\n",
      "#Iteration: 750, Loss: 51703.97083734654\n",
      "#Iteration: 1000, Loss: 51559.57237741574\n",
      "#Iteration: 1250, Loss: 51463.719710887104\n",
      "#Iteration: 1500, Loss: 51394.720306089774\n",
      "#Iteration: 1750, Loss: 51342.655767373646\n",
      "#Iteration: 2000, Loss: 51302.17121988065\n",
      "#Iteration: 0, Loss: 86643.39756999268\n",
      "#Iteration: 250, Loss: 52445.21518742959\n",
      "#Iteration: 500, Loss: 51748.661202790216\n",
      "#Iteration: 750, Loss: 51481.83358100553\n",
      "#Iteration: 1000, Loss: 51331.417638854124\n",
      "#Iteration: 1250, Loss: 51231.626299937605\n",
      "#Iteration: 1500, Loss: 51159.646912556425\n",
      "#Iteration: 1750, Loss: 51105.19295191711\n",
      "#Iteration: 2000, Loss: 51062.75682266512\n",
      "[51302.02774771 51062.60629291]\n",
      "[51156.46754558 51352.67693744]\n",
      "[0.813512 0.81428 ]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 5\n",
    "k_fold = 2\n",
    "degree = 3\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 86643.3975699927\n",
      "#Iteration: 250, Loss: 52616.215197568265\n",
      "#Iteration: 500, Loss: 51958.760765570136\n",
      "#Iteration: 750, Loss: 51703.970839533744\n",
      "#Iteration: 1000, Loss: 51559.57237974359\n",
      "#Iteration: 1250, Loss: 51463.71971333894\n",
      "#Iteration: 1500, Loss: 51394.72030865099\n",
      "#Iteration: 1750, Loss: 51342.65577002993\n",
      "#Iteration: 2000, Loss: 51302.17122261809\n",
      "#Iteration: 0, Loss: 86643.39756999268\n",
      "#Iteration: 250, Loss: 52445.21518923439\n",
      "#Iteration: 500, Loss: 51748.66120487704\n",
      "#Iteration: 750, Loss: 51481.83358326398\n",
      "#Iteration: 1000, Loss: 51331.41764125384\n",
      "#Iteration: 1250, Loss: 51231.62630246293\n",
      "#Iteration: 1500, Loss: 51159.646915194135\n",
      "#Iteration: 1750, Loss: 51105.19295465376\n",
      "#Iteration: 2000, Loss: 51062.75682548692\n",
      "[51302.02775045 51062.60629573]\n",
      "[51156.46754671 51352.6769381 ]\n",
      "[0.813512 0.81428 ]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 6\n",
    "k_fold = 2\n",
    "degree = 3\n",
    "lambda_ = 1e-6\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(weights, x_val)\n",
    "y_val = relabel_y_negative(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, recall_score, precision_score\n",
    "print(confusion_matrix(y_val,y_pred))\n",
    "print(accuracy_score(y_val,y_pred))\n",
    "print(f1_score(y_val,y_pred))\n",
    "print(recall_score(y_val,y_pred))\n",
    "print(precision_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_y_counts(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../results/ridge_reg_submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, x_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (ml_2019)",
   "language": "python",
   "name": "ml_2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
