{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'  \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_utils import *\n",
    "from proj1_visualization import *\n",
    "from proj1_cross_validation import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [22]\n",
    "tX_num, tX_cat = split_numerical_categorical(tX,cat_cols)\n",
    "tX_test_num, tX_test_cat = split_numerical_categorical(tX_test,cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat numerical values\n",
    "best_degree = 5\n",
    "full_x_train_num_nan = replace_undef_val_with_nan(tX_num)\n",
    "full_x_train_num_std, train_mean, train_std = nan_standardize_fit(full_x_train_num_nan)\n",
    "full_x_train_num_valid = replace_nan_val_with_median(full_x_train_num_std)\n",
    "full_x_train_num_valid = replace_iqr_outliers(full_x_train_num_valid)\n",
    "# Treat categorical values\n",
    "full_x_train_ohe_cat = one_hot_encode(tX_cat)\n",
    "full_x_train_poly = build_poly(full_x_train_num_valid , best_degree)\n",
    "full_x_train = np.hstack((full_x_train_poly,full_x_train_ohe_cat))\n",
    "# Treat labels\n",
    "full_y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = split_data(full_x_train,full_y_train,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat numerical values\n",
    "x_test_num_nan = replace_undef_val_with_nan(tX_test_num)\n",
    "x_test_num_nan_std = nan_standardize_transform(x_test_num_nan,train_mean,train_std)\n",
    "x_test_num_valid_std = replace_nan_val_with_median(x_test_num_nan_std)\n",
    "x_test_num_valid_std = replace_iqr_outliers(x_test_num_valid_std)\n",
    "# Treat categorical values\n",
    "x_test_ohe_cat = one_hot_encode(tX_test_cat)\n",
    "x_test_poly = build_poly(x_test_num_valid_std , best_degree)\n",
    "x_test = np.hstack((x_test_poly,x_test_ohe_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 1\n",
    "degrees = np.asarray(range(1,4))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 2\n",
    "degrees = np.asarray(range(1,6))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 3\n",
    "degrees = np.asarray(range(1,11))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 4\n",
    "degrees = np.asarray(range(1,10))\n",
    "lambdas = np.logspace(-10,0,11)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 5\n",
    "degrees = np.asarray(range(1,4))\n",
    "lambdas = np.logspace(-7,0,8)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 5\n",
    "degrees = np.asarray(range(1,4))\n",
    "lambdas = np.logspace(-7,0,8)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = 1e-5\n",
    "lambda_ = best_lambda\n",
    "weights, loss = ridge_regression(y_train,x_train,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = least_squares(y_train,x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 1\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 2\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 3\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 4\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 5\n",
    "k_fold = 5\n",
    "degree = 3\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_flag = 6\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(weights, x_val)\n",
    "y_val = relabel_y_negative(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, recall_score, precision_score\n",
    "print(confusion_matrix(y_val,y_pred))\n",
    "print(accuracy_score(y_val,y_pred))\n",
    "print(f1_score(y_val,y_pred))\n",
    "print(recall_score(y_val,y_pred))\n",
    "print(precision_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_y_counts(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../results/ridge_reg_submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, x_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (ml_2019)",
   "language": "python",
   "name": "ml_2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
