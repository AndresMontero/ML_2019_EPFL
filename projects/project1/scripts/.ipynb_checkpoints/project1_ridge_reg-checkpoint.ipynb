{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'  \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_utils import *\n",
    "from proj1_visualization import *\n",
    "from proj1_cross_validation import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [22]\n",
    "tX_num, tX_cat = split_numerical_categorical(tX,cat_cols)\n",
    "tX_test_num, tX_test_cat = split_numerical_categorical(tX_test,cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat numerical values\n",
    "best_degree = 5\n",
    "full_x_train_num_nan = replace_undef_val_with_nan(tX_num)\n",
    "full_x_train_num_std, train_mean, train_std = nan_standardize_fit(full_x_train_num_nan)\n",
    "full_x_train_num_valid = replace_nan_val_with_median(full_x_train_num_std)\n",
    "full_x_train_num_valid = replace_iqr_outliers(full_x_train_num_valid)\n",
    "# Treat categorical values\n",
    "full_x_train_ohe_cat = one_hot_encode(tX_cat)\n",
    "full_x_train_poly = build_poly(full_x_train_num_valid , best_degree)\n",
    "full_x_train = np.hstack((full_x_train_poly,full_x_train_ohe_cat))\n",
    "# Treat labels\n",
    "full_y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = split_data(full_x_train,full_y_train,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat numerical values\n",
    "x_test_num_nan = replace_undef_val_with_nan(tX_test_num)\n",
    "x_test_num_nan_std = nan_standardize_transform(x_test_num_nan,train_mean,train_std)\n",
    "x_test_num_valid_std = replace_nan_val_with_median(x_test_num_nan_std)\n",
    "x_test_num_valid_std = replace_iqr_outliers(x_test_num_valid_std)\n",
    "# Treat categorical values\n",
    "x_test_ohe_cat = one_hot_encode(tX_test_cat)\n",
    "x_test_poly = build_poly(x_test_num_valid_std , best_degree)\n",
    "x_test = np.hstack((x_test_poly,x_test_ohe_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD(51/250): loss=0.4998666077888844, w0=-1.574549172719813e-05, w1=5.7202254835250115e-06\n",
      "GD(101/250): loss=0.4997334045639643, w0=-3.1478729028650354e-05, w1=1.1439446793697914e-05\n",
      "GD(151/250): loss=0.4996003899919515, w0=-4.7199723040152836e-05, w1=1.7157664450891093e-05\n",
      "GD(201/250): loss=0.4994675637402328, w0=-6.290848488560183e-05, w1=2.2874878974726176e-05\n",
      "GD(251/250): loss=0.4993349254768674, w0=-7.86050256770078e-05, w1=2.859109088407545e-05\n",
      "GD(51/250): loss=0.49945929321180516, w0=-1.5724069440337368e-05, w1=5.719362926469267e-06\n",
      "GD(101/250): loss=0.4989233403480238, w0=-3.139235035229946e-05, w1=1.1435967605298048e-05\n",
      "GD(151/250): loss=0.498392089099657, w0=-4.700513268759817e-05, w1=1.7149823976126334e-05\n",
      "GD(201/250): loss=0.4978654877754954, w0=-6.256270470291062e-05, w1=2.2860941918120816e-05\n",
      "GD(251/250): loss=0.49734348529462546, w0=-7.80653529701785e-05, w1=2.856933125036101e-05\n",
      "GD(51/250): loss=0.49908845496763055, w0=-1.5709414210005838e-05, w1=5.7235209125553165e-06\n",
      "GD(101/250): loss=0.4982107882498994, w0=-3.133403987350933e-05, w1=1.1452572252113147e-05\n",
      "GD(151/250): loss=0.4973649020881248, w0=-4.687550715971387e-05, w1=1.718687206455532e-05\n",
      "GD(201/250): loss=0.4965488387589108, w0=-6.233539692856154e-05, w1=2.2926146983137135e-05\n",
      "GD(251/250): loss=0.49576077107216837, w0=-7.771524237827595e-05, w1=2.867013195744127e-05\n",
      "GD(51/250): loss=0.49360214430036, w0=-1.5450332382453568e-05, w1=5.741921044123435e-06\n",
      "GD(101/250): loss=0.4888568677504362, w0=-3.034878287524883e-05, w1=1.1518655423273135e-05\n",
      "GD(151/250): loss=0.4852072175240686, w0=-4.477601399545487e-05, w1=1.731953003898246e-05\n",
      "GD(201/250): loss=0.48230212651552806, w0=-5.879678945143736e-05, w1=2.3136213884495364e-05\n",
      "GD(251/250): loss=0.47991530493091367, w0=-7.246344838462599e-05, w1=2.896218121235763e-05\n",
      "GD(51/250): loss=0.49163081225946276, w0=-1.51722695769608e-05, w1=5.86974686269348e-06\n",
      "GD(101/250): loss=0.4875705795189666, w0=-2.9684924555129015e-05, w1=1.1834387957197511e-05\n",
      "GD(151/250): loss=0.4841842036763564, w0=-4.3771096129486944e-05, w1=1.7780243444161147e-05\n",
      "GD(201/250): loss=0.4812063470265299, w0=-5.749994863281495e-05, w1=2.3680138618361442e-05\n",
      "GD(251/250): loss=0.47853391147548746, w0=-7.09155469422645e-05, w1=2.952864026835191e-05\n",
      "GD(51/250): loss=0.47763887251264603, w0=-1.3792941187450685e-05, w1=5.896129049811668e-06\n",
      "GD(101/250): loss=0.4690496465068554, w0=-2.62595025974996e-05, w1=1.1558620303853913e-05\n",
      "GD(151/250): loss=0.4626625434321044, w0=-3.7855101339549724e-05, w1=1.7035856349287538e-05\n",
      "GD(201/250): loss=0.45775317511427016, w0=-4.8757100922864854e-05, w1=2.2377491920983253e-05\n",
      "GD(251/250): loss=0.45390051804149306, w0=-5.907947018386266e-05, w1=2.7614303895073264e-05\n",
      "8\n",
      "0\n",
      "0.68368\n",
      "[[0.66738]\n",
      " [0.6566 ]\n",
      " [0.67232]\n",
      " [0.65738]\n",
      " [0.67382]\n",
      " [0.68368]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 1\n",
    "degrees = np.asarray(range(3,9))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas,max_iters = 250,gamma = 0.01)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(50/2000): loss=0.4999560328730805, w(0)=-1.7999494721739857e-05, w1=3.5480791707477293e-06\n",
      "SGD(100/2000): loss=0.5001926794149707, w(0)=-3.399670654765714e-05, w1=1.0489958052191082e-05\n",
      "SGD(150/2000): loss=0.4996817964838604, w(0)=-5.1992623872818504e-05, w1=1.3375506850854295e-05\n",
      "SGD(200/2000): loss=0.49961034577844315, w(0)=-7.198936799854934e-05, w1=2.36637956134491e-05\n",
      "SGD(250/2000): loss=0.5003647068815094, w(0)=-8.39825402078926e-05, w1=2.823389416660846e-05\n",
      "SGD(300/2000): loss=0.49992163320844546, w(0)=-0.00010997139578886805, w1=3.3456361532792676e-05\n",
      "SGD(350/2000): loss=0.49938066192564445, w(0)=-0.0001299581496448557, w1=3.814024383261656e-05\n",
      "SGD(400/2000): loss=0.4995744662692441, w(0)=-0.00014594592209955548, w1=3.7837670888478076e-05\n",
      "SGD(450/2000): loss=0.5005391964889622, w(0)=-0.00015792810810679348, w1=4.704865296964899e-05\n",
      "SGD(500/2000): loss=0.5001973942162212, w(0)=-0.00017790936626798227, w1=5.55638469687169e-05\n",
      "SGD(550/2000): loss=0.5000674954478292, w(0)=-0.0001958924469887238, w1=5.868068685671567e-05\n",
      "SGD(600/2000): loss=0.5004918472268828, w(0)=-0.00022186905190885135, w1=6.267544022026408e-05\n",
      "SGD(650/2000): loss=0.5002505385346953, w(0)=-0.00023985106889768746, w1=7.30116297486714e-05\n",
      "SGD(700/2000): loss=0.4990493888375584, w(0)=-0.00025782371918221456, w1=7.762022002396391e-05\n",
      "SGD(750/2000): loss=0.5007738802967074, w(0)=-0.00027978567844677945, w1=8.479849398883905e-05\n",
      "SGD(800/2000): loss=0.49809226188251243, w(0)=-0.00029176236020024934, w1=9.123099353895322e-05\n",
      "SGD(850/2000): loss=0.5002930195956794, w(0)=-0.00030973834919809123, w1=9.552125074055433e-05\n",
      "SGD(900/2000): loss=0.5000849010732262, w(0)=-0.00032170122331118663, w1=0.00010075355381298452\n",
      "SGD(950/2000): loss=0.4980349268552071, w(0)=-0.0003376639384979387, w1=0.00010765821233118472\n",
      "SGD(1000/2000): loss=0.49878057434236683, w(0)=-0.00034763525044063427, w1=0.00011775126307879766\n",
      "SGD(1050/2000): loss=0.4990225101039216, w(0)=-0.00036558883898662976, w1=0.00011946586140824155\n",
      "SGD(1100/2000): loss=0.5000302092802922, w(0)=-0.0003735535417726031, w1=0.00012796704716078327\n",
      "SGD(1150/2000): loss=0.4990667925305608, w(0)=-0.00038152290154241713, w1=0.00012298605273773798\n",
      "SGD(1200/2000): loss=0.4976173595398367, w(0)=-0.0003974818212901733, w1=0.00013312716524241272\n",
      "SGD(1250/2000): loss=0.4986969984462488, w(0)=-0.0004094494816705126, w1=0.00014056167148427117\n",
      "SGD(1300/2000): loss=0.5018902653354955, w(0)=-0.00042341412532732376, w1=0.00014542229442775136\n",
      "SGD(1350/2000): loss=0.49787381410427634, w(0)=-0.0004533748483784811, w1=0.00015302090248925994\n",
      "SGD(1400/2000): loss=0.49730781804854607, w(0)=-0.00047332218088138775, w1=0.00016169357582730484\n",
      "SGD(1450/2000): loss=0.500661576393225, w(0)=-0.000485266044327785, w1=0.0001704231416664758\n",
      "SGD(1500/2000): loss=0.5023582370747631, w(0)=-0.0004992302048158798, w1=0.00018010323913305438\n",
      "SGD(1550/2000): loss=0.5008271657975527, w(0)=-0.000503179742577448, w1=0.00018774578503266286\n",
      "SGD(1600/2000): loss=0.4992700573074712, w(0)=-0.0005151187765492465, w1=0.00019320917594695136\n",
      "SGD(1650/2000): loss=0.49735079961097767, w(0)=-0.0005370638569065949, w1=0.00020569173130064909\n",
      "SGD(1700/2000): loss=0.5000045164655116, w(0)=-0.0005489929348877437, w1=0.00020735195886312845\n",
      "SGD(1750/2000): loss=0.5020237195598807, w(0)=-0.0005629660943298411, w1=0.00021383285442051444\n",
      "SGD(1800/2000): loss=0.49939057700448375, w(0)=-0.0005729136968917678, w1=0.00021675296254208498\n",
      "SGD(1850/2000): loss=0.4978467445558795, w(0)=-0.0005808698452519763, w1=0.00022680170134095067\n",
      "SGD(1900/2000): loss=0.49992766713005393, w(0)=-0.000596801398417472, w1=0.00023647837406464374\n",
      "SGD(1950/2000): loss=0.4977924118662855, w(0)=-0.0006087281988484144, w1=0.00023794870501171538\n",
      "SGD(2000/2000): loss=0.5030625413335145, w(0)=-0.0006226771360314885, w1=0.0002460389461568933\n",
      "SGD(50/2000): loss=0.5000667224233023, w(0)=-1.199748524317055e-05, w1=1.9022068554849966e-06\n",
      "SGD(100/2000): loss=0.49927915422399627, w(0)=-3.997504270670089e-05, w1=6.205879349942255e-06\n",
      "SGD(150/2000): loss=0.4996822927654351, w(0)=-4.7944760941946675e-05, w1=1.1552635526554412e-05\n",
      "SGD(200/2000): loss=0.5004508683288603, w(0)=-6.78994596909545e-05, w1=1.7625610953343185e-05\n",
      "SGD(250/2000): loss=0.49859196416802504, w(0)=-7.984749865458122e-05, w1=2.0587995577511925e-05\n",
      "SGD(300/2000): loss=0.4990982579625731, w(0)=-9.578437272968559e-05, w1=2.4723251728265006e-05\n",
      "SGD(350/2000): loss=0.49846444576331705, w(0)=-9.971641099391896e-05, w1=2.0373467267003593e-05\n",
      "SGD(400/2000): loss=0.4977456557015348, w(0)=-0.00011563464044298984, w1=2.0038807686669452e-05\n",
      "SGD(450/2000): loss=0.4962701472246318, w(0)=-0.00013754411309033497, w1=2.386346500751935e-05\n",
      "SGD(500/2000): loss=0.497741914210788, w(0)=-0.00015344873708556287, w1=3.0002867810959237e-05\n",
      "SGD(550/2000): loss=0.4960296159879617, w(0)=-0.00017133137411160974, w1=3.4252414092353773e-05\n",
      "SGD(600/2000): loss=0.495769454715381, w(0)=-0.00019119447199045415, w1=4.130328073805223e-05\n",
      "SGD(650/2000): loss=0.5014544723753619, w(0)=-0.00020106139794557758, w1=4.828033146085496e-05\n",
      "SGD(700/2000): loss=0.4942927400130552, w(0)=-0.0002209135183823495, w1=5.4144929398187386e-05\n",
      "SGD(750/2000): loss=0.5021327109585858, w(0)=-0.00023674684946145362, w1=6.681641803012967e-05\n",
      "SGD(800/2000): loss=0.4977870740142882, w(0)=-0.00025058299548054, w1=7.581629800672298e-05\n",
      "SGD(850/2000): loss=0.494910084582018, w(0)=-0.00026240692005097147, w1=7.718555775827922e-05\n",
      "SGD(900/2000): loss=0.5011121310874767, w(0)=-0.0002802220532879943, w1=8.054260836824795e-05\n",
      "SGD(950/2000): loss=0.5021607099917408, w(0)=-0.0003039994399230229, w1=8.81071129515282e-05\n",
      "SGD(1000/2000): loss=0.4979891235334622, w(0)=-0.00031777992958975453, w1=9.672938726943968e-05\n",
      "SGD(1050/2000): loss=0.4937641419632722, w(0)=-0.0003255667873066453, w1=0.00010174317415828217\n",
      "SGD(1100/2000): loss=0.4951162774775504, w(0)=-0.00033933617854086236, w1=0.00010783316029801273\n",
      "SGD(1150/2000): loss=0.49592313326298965, w(0)=-0.0003610805624053546, w1=0.00011602647545171457\n",
      "SGD(1200/2000): loss=0.4948951892051771, w(0)=-0.00038880357271100634, w1=0.0001282947044016858\n",
      "SGD(1250/2000): loss=0.5025665026522959, w(0)=-0.00040051972686603595, w1=0.00013322853622327218\n",
      "SGD(1300/2000): loss=0.49239565251348505, w(0)=-0.0004222330255248388, w1=0.00013974113563279322\n",
      "SGD(1350/2000): loss=0.4946794217705113, w(0)=-0.0004359157845921589, w1=0.00014479595066822583\n",
      "SGD(1400/2000): loss=0.49353319492025066, w(0)=-0.00045363565687021434, w1=0.00015303330180278479\n",
      "SGD(1450/2000): loss=0.4913435091757419, w(0)=-0.00047132742277350897, w1=0.00016304705680938303\n",
      "SGD(1500/2000): loss=0.49318246689542683, w(0)=-0.0004889963220357287, w1=0.00016987863797203503\n",
      "SGD(1550/2000): loss=0.4922816594728503, w(0)=-0.0004986099954811817, w1=0.000166548535694377\n",
      "SGD(1600/2000): loss=0.49260143269706375, w(0)=-0.0005142573440713929, w1=0.000174679997229214\n",
      "SGD(1650/2000): loss=0.5039465208941232, w(0)=-0.0005318729587398065, w1=0.00017638077167815382\n",
      "SGD(1700/2000): loss=0.4931382735075043, w(0)=-0.000547491998478004, w1=0.0001810653385201769\n",
      "SGD(1750/2000): loss=0.4891894785346663, w(0)=-0.0005610970308017202, w1=0.00018498273112648107\n",
      "SGD(1800/2000): loss=0.5091659779549885, w(0)=-0.0005806695488148911, w1=0.00019444320035198788\n",
      "SGD(1850/2000): loss=0.5045457237818477, w(0)=-0.0005962557275316456, w1=0.00019962386652138165\n",
      "SGD(1900/2000): loss=0.48281809943232623, w(0)=-0.0006217158629116671, w1=0.00020716131736855782\n",
      "SGD(1950/2000): loss=0.5080671854372798, w(0)=-0.0006312780611385714, w1=0.00021352847805164663\n",
      "SGD(2000/2000): loss=0.5051212722225311, w(0)=-0.0006408200864145556, w1=0.0002192087179551559\n",
      "1\n",
      "0\n",
      "0.69008\n",
      "[[0.69008]\n",
      " [0.6566 ]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 2\n",
    "degrees = np.asarray(range(1,3))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0.6566\n",
      "[[0.6566]\n",
      " [0.3434]\n",
      " [0.3434]\n",
      " [0.3434]\n",
      " [0.6566]\n",
      " [0.6566]\n",
      " [0.6566]\n",
      " [0.3434]\n",
      " [0.3434]\n",
      " [0.6566]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 3\n",
    "degrees = np.asarray(range(1,11))\n",
    "lambdas = np.asarray([0])\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1e-06\n",
      "0.817\n",
      "[[0.81652 0.8166 ]\n",
      " [0.81688 0.817  ]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 4\n",
    "degrees = np.asarray(range(4,6))\n",
    "lambdas = np.logspace(-7,-6,2)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "#Iteration: 0, Loss: 138629.4361119856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianvillarroel/Documents/Docs_Adrian/EPFL/Courses/Machine_learning/ML_2019_EPFL/projects/project1/scripts/implementations_utils.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = y.T.dot(np.log(pred)) + (1 - y).T.dot(np.log(1 - pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 250, Loss: 153950.50504662874\n",
      "#Iteration: 500, Loss: nan\n",
      "#Iteration: 750, Loss: 153839.02954251014\n",
      "#Iteration: 1000, Loss: nan\n",
      "#Iteration: 1250, Loss: 153548.70853493735\n",
      "#Iteration: 1500, Loss: nan\n",
      "#Iteration: 1750, Loss: 153198.40905724769\n",
      "#Iteration: 2000, Loss: nan\n",
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 153950.50504662874\n",
      "#Iteration: 500, Loss: nan\n",
      "#Iteration: 750, Loss: 153839.02954251014\n",
      "#Iteration: 1000, Loss: nan\n",
      "#Iteration: 1250, Loss: 153548.70853493735\n",
      "#Iteration: 1500, Loss: nan\n",
      "#Iteration: 1750, Loss: 153198.40905724769\n",
      "#Iteration: 2000, Loss: nan\n",
      "5\n",
      "1e-07\n",
      "0.79502\n",
      "[[0.79052 0.79052]\n",
      " [0.79502 0.79502]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 5\n",
    "degrees = np.asarray(range(4,6))\n",
    "lambdas = np.logspace(-7,-6,2)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 100085.00273272581\n",
      "#Iteration: 500, Loss: 98529.91098768296\n",
      "#Iteration: 750, Loss: 97532.75526541306\n",
      "#Iteration: 1000, Loss: 96846.72202589607\n",
      "#Iteration: 1250, Loss: 96330.28601335015\n",
      "#Iteration: 1500, Loss: 95920.23375664669\n",
      "#Iteration: 1750, Loss: 95582.66385091135\n",
      "#Iteration: 2000, Loss: 95297.34123557618\n",
      "4\n",
      "1e-07\n",
      "0.79052\n",
      "[[0.79052 0.79052]]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 5\n",
    "degrees = np.asarray(range(4,5))\n",
    "lambdas = np.logspace(-7,-6,2)\n",
    "best_degree, best_lambda, accuracy_score, accuracy_scores_grid = degree_lambda_grid_search(y,tX,[22],0.8,method_flag,degrees,lambdas)\n",
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(accuracy_score)\n",
    "print(accuracy_scores_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = 1e-5\n",
    "lambda_ = best_lambda\n",
    "weights, loss = ridge_regression(y_train,x_train,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = least_squares(y_train,x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD(51/2000): loss=0.498008967536016, w0=-3.428704855974191e-05, w1=1.2542584521976463e-05\n",
      "GD(101/2000): loss=0.4961789938662344, w0=-6.817374129066865e-05, w1=2.5114613293158463e-05\n",
      "GD(151/2000): loss=0.494488630926867, w0=-0.00010167693092135272, w1=3.771292478816873e-05\n",
      "GD(201/2000): loss=0.4929194976044192, w0=-0.00013481234907622975, w1=5.0334568769426166e-05\n",
      "GD(251/2000): loss=0.4914558345624867, w0=-0.0001675946883977117, w1=6.2976791681685e-05\n",
      "GD(301/2000): loss=0.49008412401576157, w0=-0.00020003767849343835, w1=7.563702309685602e-05\n",
      "GD(351/2000): loss=0.48879276495615576, w0=-0.00023215415617703437, w1=8.831286313174699e-05\n",
      "GD(401/2000): loss=0.4875717957253721, w0=-0.0002639561304351158, w1=0.0001010020707671358\n",
      "GD(451/2000): loss=0.48641265701427655, w0=-0.00029545484252036197, w1=0.0001137025530019339\n",
      "GD(501/2000): loss=0.48530798938182923, w0=-0.0003266608215400682, w1=0.00012641235478113563\n",
      "GD(551/2000): loss=0.4842514602505461, w0=-0.0003575839358814899, w1=0.00013912964964082073\n",
      "GD(601/2000): loss=0.4832376160731641, w0=-0.00038823344078933535, w1=0.0001518527310176998\n",
      "GD(651/2000): loss=0.48226175599492704, w0=-0.0004186180223867866, w1=0.00016458000417460242\n",
      "GD(701/2000): loss=0.48131982387345806, w0=-0.0004487458384092659, w1=0.00017730997869692104\n",
      "GD(751/2000): loss=0.48040831597708883, w0=-0.0004786245558997047, w1=0.00019004126151836797\n",
      "GD(801/2000): loss=0.479524202074234, w0=-0.0005082613860951545, w1=0.0002027725504374915\n",
      "GD(851/2000): loss=0.47866485796081437, w0=-0.0005376631167171172, w1=0.00021550262808926228\n",
      "GD(901/2000): loss=0.47782800775820233, w0=-0.0005668361418618231, w1=0.00022823035633868228\n",
      "GD(951/2000): loss=0.4770116745578695, w0=-0.0005957864896717794, w1=0.00024095467106581884\n",
      "GD(1001/2000): loss=0.47621413819695935, w0=-0.0006245198479561325, w1=0.0002536745773139288\n",
      "GD(1051/2000): loss=0.4754338991266297, w0=-0.0006530415879146609, w1=0.0002663891447744337\n",
      "GD(1101/2000): loss=0.4746696474866291, w0=-0.000681356786108453, w1=0.00027909750358444423\n",
      "GD(1151/2000): loss=0.4739202366290366, w0=-0.0007094702448094658, w1=0.0002917988404143238\n",
      "GD(1201/2000): loss=0.4731846604446012, w0=-0.0007373865108511169, w1=0.0003044923948244433\n",
      "GD(1251/2000): loss=0.47246203393949077, w0=-0.0007651098930927917, w1=0.0003171774558718101\n",
      "GD(1301/2000): loss=0.47175157659080846, w0=-0.0007926444786025825, w1=0.00032985335894867895\n",
      "GD(1351/2000): loss=0.4710525980780313, w0=-0.0008199941476546545, w1=0.0003425194828365641\n",
      "GD(1401/2000): loss=0.47036448604624914, w0=-0.0008471625876303248, w1=0.00035517524696028897\n",
      "GD(1451/2000): loss=0.4696866956072312, w0=-0.000874153305905184, w1=0.0003678201088278362\n",
      "GD(1501/2000): loss=0.4690187403271699, w0=-0.0009009696417983436, w1=0.000380453561642804\n",
      "GD(1551/2000): loss=0.4683601844865141, w0=-0.0009276147776541267, w1=0.00039307513207723587\n",
      "GD(1601/2000): loss=0.46771063642852995, w0=-0.0009540917491211915, w1=0.0004056843781934883\n",
      "GD(1651/2000): loss=0.46706974283988933, w0=-0.000980403454689149, w1=0.000418280887504624\n",
      "GD(1701/2000): loss=0.4664371838293627, w0=-0.0010065526645381957, w1=0.0004308642751635835\n",
      "GD(1751/2000): loss=0.46581266869013915, w0=-0.0010325420287530642, w1=0.0004434341822721\n",
      "GD(1801/2000): loss=0.46519593224791, w0=-0.001058374084948731, w1=0.00045599027430097525\n",
      "GD(1851/2000): loss=0.46458673171103715, w0=-0.0010840512653517138, w1=0.00046853223961393955\n",
      "GD(1901/2000): loss=0.4639848439512559, w0=-0.0011095759033774798, w1=0.0004810597880878894\n",
      "GD(1951/2000): loss=0.4633900631537063, w0=-0.0011349502397414342, w1=0.0004935726498228078\n",
      "GD(2001/2000): loss=0.46280219878394036, w0=-0.00116017642813812, w1=0.0005060705739351594\n",
      "GD(51/2000): loss=0.49802219216206556, w0=-3.4529973487376946e-05, w1=1.2606556830168696e-05\n",
      "GD(101/2000): loss=0.4961962040701439, w0=-6.864894483250921e-05, w1=2.5235181520065487e-05\n",
      "GD(151/2000): loss=0.49450254205150945, w0=-0.00010237385370646925, w1=3.788319136289729e-05\n",
      "GD(201/2000): loss=0.4929244289421242, w0=-0.0001357205546253391, w1=5.054807982194765e-05\n",
      "GD(251/2000): loss=0.49144741824077565, w0=-0.00016870389394012456, w1=6.322750459505658e-05\n",
      "GD(301/2000): loss=0.4900590634454973, w0=-0.00020133778118821595, w1=7.591927652197337e-05\n",
      "GD(351/2000): loss=0.4887486346574632, w0=-0.00023363525522436258, w1=8.862134927356708e-05\n",
      "GD(401/2000): loss=0.48750687567421036, w0=-0.0002656085455179987, w1=0.00010133180976635767\n",
      "GD(451/2000): loss=0.48632579576737356, w0=-0.0002972691289749514, w1=0.0001140488692499756\n",
      "GD(501/2000): loss=0.48519849117358665, w0=-0.00032862778261489955, w1=0.0001267708550189984\n",
      "GD(551/2000): loss=0.484118992040936, w0=-0.00035969463241128846, w1=0.00013949620270416814\n",
      "GD(601/2000): loss=0.4830821311845196, w0=-0.0003904791985775697, w1=0.00015222344910128816\n",
      "GD(651/2000): loss=0.4820834315280527, w0=-0.0004209904375625131, w1=0.0001649512254991462\n",
      "GD(701/2000): loss=0.4811190095566408, w0=-0.0004512367809977909, w1=0.00017767825147063844\n",
      "GD(751/2000): loss=0.4801854924896503, w0=-0.00048122617182293166, w1=0.00019040332909388348\n",
      "GD(801/2000): loss=0.47927994721129336, w0=-0.0005109660977960118, w1=0.0002031253375725414\n",
      "GD(851/2000): loss=0.4783998192780071, w0=-0.0005404636225829477, w1=0.00021584322822679644\n",
      "GD(901/2000): loss=0.4775428805627628, w0=-0.0005697254146039206, w1=0.00022855601982854295\n",
      "GD(951/2000): loss=0.4767071843028754, w0=-0.0005987577738021905, w1=0.00024126279425624103\n",
      "GD(1001/2000): loss=0.47589102649467857, w0=-0.0006275666564882835, w1=0.0002539626924466907\n",
      "GD(1051/2000): loss=0.4750929127298364, w0=-0.0006561576984011623, w1=0.0002666549106226314\n",
      "GD(1101/2000): loss=0.474311529697753, w0=-0.0006845362361174807, w1=0.0002793386967766021\n",
      "GD(1151/2000): loss=0.47354572068958994, w0=-0.0007127073269302859, w1=0.00029201334739291634\n",
      "GD(1201/2000): loss=0.4727944645345368, w0=-0.0007406757673095227, w1=0.00030467820439092526\n",
      "GD(1251/2000): loss=0.47205685748045506, w0=-0.0007684461100483631, w1=0.00031733265227395645\n",
      "GD(1301/2000): loss=0.4713320976007951, w0=-0.0007960226801916606, w1=0.0003299761154694482\n",
      "GD(1351/2000): loss=0.4706194713694727, w0=-0.000823409589835696, w1=0.00034260805584684196\n",
      "GD(1401/2000): loss=0.46991834209658867, w0=-0.0008506107518817678, w1=0.0003552279704007702\n",
      "GD(1451/2000): loss=0.46922813996174256, w0=-0.0008776298928200619, w1=0.0003678353890879714\n",
      "GD(1501/2000): loss=0.46854835341926265, w0=-0.000904470564614589, w1=0.0003804298728071981\n",
      "GD(1551/2000): loss=0.4678785217818719, w0=-0.0009311361557547092, w1=0.00039301101151215486\n",
      "GD(1601/2000): loss=0.4672182288168815, w0=-0.0009576299015339463, w1=0.0004055784224482235\n",
      "GD(1651/2000): loss=0.46656709721263906, w0=-0.0009839548936122896, w1=0.0004181317485043875\n",
      "GD(1701/2000): loss=0.4659247837932023, w0=-0.0010101140889140164, w1=0.00043067065667239075\n",
      "GD(1751/2000): loss=0.4652909753765601, w0=-0.001036110317909253, w1=0.00044319483660572973\n",
      "GD(1801/2000): loss=0.4646653851865866, w0=-0.001061946292323897, w1=0.00045570399927161105\n",
      "GD(1851/2000): loss=0.4640477497416615, w0=-0.001087624612319264, w1=0.0004681978756894924\n",
      "GD(1901/2000): loss=0.4634378261538049, w0=-0.0011131477731797397, w1=0.0004806762157502844\n",
      "GD(1951/2000): loss=0.46283538978153893, w0=-0.0011385181715439163, w1=0.0004931387871107051\n",
      "GD(2001/2000): loss=0.46224023218771254, w0=-0.0011637381112120822, w1=0.0005055853741576749\n",
      "[0.4628022  0.46224023]\n",
      "[0.96214375 0.96150278]\n",
      "[0.675592 0.675296]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 1\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(50/2000): loss=0.501039671462663, w(0)=-2.1927381545026525e-05, w1=1.1068327802511765e-05\n",
      "SGD(100/2000): loss=0.49934926696556037, w(0)=-4.782160013950155e-05, w1=1.0102490916102534e-05\n",
      "SGD(150/2000): loss=0.49776999596434274, w(0)=-0.00010885720708351211, w1=1.5846895104484017e-05\n",
      "SGD(200/2000): loss=0.48007379750805756, w(0)=-0.00014597839527303615, w1=3.1917279663436526e-05\n",
      "SGD(250/2000): loss=0.4804912998071614, w(0)=-0.0002004454026782483, w1=3.7644390118481506e-05\n",
      "SGD(300/2000): loss=0.46663531940065395, w(0)=-0.0002462849903179082, w1=5.550906803256989e-05\n",
      "SGD(350/2000): loss=0.3395710925211699, w(0)=-0.0002955683543515372, w1=7.845587927932728e-05\n",
      "SGD(400/2000): loss=0.4815800425147755, w(0)=-0.0003224920181258003, w1=9.381807635984358e-05\n",
      "SGD(450/2000): loss=0.5276251490783027, w(0)=-0.00033795534764145027, w1=0.00011119067494515082\n",
      "SGD(500/2000): loss=0.4718079376536416, w(0)=-0.0004056496048556763, w1=0.00013378197232042892\n",
      "SGD(550/2000): loss=0.4809293228126758, w(0)=-0.00044041504653636053, w1=0.0001633004582411852\n",
      "SGD(600/2000): loss=0.5100223000293002, w(0)=-0.0004710470739812568, w1=0.0001788635841341258\n",
      "SGD(650/2000): loss=0.47414906455983113, w(0)=-0.0004753972222490671, w1=0.00019239606235729197\n",
      "SGD(700/2000): loss=0.5150511745776241, w(0)=-0.0005146187758329804, w1=0.00020749193472116627\n",
      "SGD(750/2000): loss=0.5114763538515504, w(0)=-0.0005534423277401455, w1=0.00021805404796662836\n",
      "SGD(800/2000): loss=0.5256648091595585, w(0)=-0.0005919953276482971, w1=0.00022615047530681352\n",
      "SGD(850/2000): loss=0.46312507651543416, w(0)=-0.0006125372034759673, w1=0.0002306963046073592\n",
      "SGD(900/2000): loss=0.4695314363851423, w(0)=-0.000661454368469456, w1=0.00024794408942907157\n",
      "SGD(950/2000): loss=0.5864424771775055, w(0)=-0.0007141798083323031, w1=0.00026544025255183993\n",
      "SGD(1000/2000): loss=0.5220294497727287, w(0)=-0.0007317860629065156, w1=0.00028887444880949255\n",
      "SGD(1050/2000): loss=0.4271284387949021, w(0)=-0.0007502684322783009, w1=0.00030119698573959975\n",
      "SGD(1100/2000): loss=0.4893128571861497, w(0)=-0.0007786913165648737, w1=0.0003094484173988442\n",
      "SGD(1150/2000): loss=0.5664932397827587, w(0)=-0.000802104737292623, w1=0.000337420315577236\n",
      "SGD(1200/2000): loss=0.36473646598454906, w(0)=-0.0008322190849466642, w1=0.00036601718784783733\n",
      "SGD(1250/2000): loss=0.469245735199732, w(0)=-0.0008704231634889501, w1=0.000377230038141852\n",
      "SGD(1300/2000): loss=0.46945450492126256, w(0)=-0.0009002336976391054, w1=0.00038484066142869297\n",
      "SGD(1350/2000): loss=0.4243334627703357, w(0)=-0.000924471748646001, w1=0.0004034195897584889\n",
      "SGD(1400/2000): loss=0.4056421402587027, w(0)=-0.0009774205338113227, w1=0.00042266155007570396\n",
      "SGD(1450/2000): loss=0.09034087310161616, w(0)=-0.0009780637869174886, w1=0.0004553691176946126\n",
      "SGD(1500/2000): loss=0.7438629231756454, w(0)=-0.0009880775624953463, w1=0.0004749941132440535\n",
      "SGD(1550/2000): loss=0.5228217515980359, w(0)=-0.0010140861960173156, w1=0.00048120275654976903\n",
      "SGD(1600/2000): loss=0.36197299899206065, w(0)=-0.0010340806184497302, w1=0.00048695551607615746\n",
      "SGD(1650/2000): loss=0.36197243275607704, w(0)=-0.0010518050453863159, w1=0.000493009806692758\n",
      "SGD(1700/2000): loss=0.24900788473729157, w(0)=-0.0010660312012780563, w1=0.0005024210784316032\n",
      "SGD(1750/2000): loss=0.39686263819703865, w(0)=-0.0010841216279210684, w1=0.0005061242244667138\n",
      "SGD(1800/2000): loss=0.4096250422157787, w(0)=-0.0010969040395573959, w1=0.0005171641923084966\n",
      "SGD(1850/2000): loss=0.5012206737780857, w(0)=-0.0011134079813565356, w1=0.0005246166438984276\n",
      "SGD(1900/2000): loss=0.5803908657863962, w(0)=-0.0011425949430443798, w1=0.0005305060740575669\n",
      "SGD(1950/2000): loss=0.5147019858651508, w(0)=-0.0011748917431366327, w1=0.0005251958796145883\n",
      "SGD(2000/2000): loss=0.4952750418785568, w(0)=-0.001192701428395058, w1=0.0005406520954827512\n",
      "SGD(50/2000): loss=0.49622846682689814, w(0)=-5.705645027182261e-05, w1=1.4430344508235711e-05\n",
      "SGD(100/2000): loss=0.5000038990445992, w(0)=-7.416100294184826e-05, w1=2.7751288377512102e-05\n",
      "SGD(150/2000): loss=0.4984893735441652, w(0)=-0.00011718869906824514, w1=4.537401013140371e-05\n",
      "SGD(200/2000): loss=0.5134425005084625, w(0)=-0.0001335655581863885, w1=6.191063054406054e-05\n",
      "SGD(250/2000): loss=0.49604283851253994, w(0)=-0.00017588546479947918, w1=7.614607057085654e-05\n",
      "SGD(300/2000): loss=0.4809057370612761, w(0)=-0.0002009742120331634, w1=9.104266830741398e-05\n",
      "SGD(350/2000): loss=0.49269225874402245, w(0)=-0.00024766023662878734, w1=0.00010548709831999028\n",
      "SGD(400/2000): loss=0.4962844474891147, w(0)=-0.00028089764691261224, w1=0.0001243583700495549\n",
      "SGD(450/2000): loss=0.4778929969076544, w(0)=-0.0003390897387338073, w1=0.00012874203397477953\n",
      "SGD(500/2000): loss=0.5072237304933443, w(0)=-0.0003801635613655709, w1=0.00014833172424376611\n",
      "SGD(550/2000): loss=0.27985406213055464, w(0)=-0.0004198050333102156, w1=0.00015592244142612896\n",
      "SGD(600/2000): loss=0.4857726846913521, w(0)=-0.0004427989744676444, w1=0.00017433579871531884\n",
      "SGD(650/2000): loss=0.35989412712317026, w(0)=-0.00047917046527169575, w1=0.00017905389169850557\n",
      "SGD(700/2000): loss=0.4790008243757417, w(0)=-0.0005543464204443437, w1=0.00020065902903088398\n",
      "SGD(750/2000): loss=0.4776920803829293, w(0)=-0.0005870529610871194, w1=0.0002131337157440471\n",
      "SGD(800/2000): loss=0.4542594457489679, w(0)=-0.0006075092297366543, w1=0.00022334292986154593\n",
      "SGD(850/2000): loss=0.437447673460792, w(0)=-0.0006638005287930183, w1=0.0002523430331191124\n",
      "SGD(900/2000): loss=0.33763340827596205, w(0)=-0.0006929715967537413, w1=0.0002646547422888963\n",
      "SGD(950/2000): loss=0.4682958727490398, w(0)=-0.0007495038269313104, w1=0.00027437436611645787\n",
      "SGD(1000/2000): loss=0.44886918262481423, w(0)=-0.0007807742447608363, w1=0.0002848705507318339\n",
      "SGD(1050/2000): loss=0.4033302820609689, w(0)=-0.0008131923861578055, w1=0.0002985697081218329\n",
      "SGD(1100/2000): loss=0.43366916537349204, w(0)=-0.0008373508067787776, w1=0.00031864779233130064\n",
      "SGD(1150/2000): loss=0.45239233061972567, w(0)=-0.0008738697893241662, w1=0.0003177203572054315\n",
      "SGD(1200/2000): loss=0.5104746304878399, w(0)=-0.0008662821072469353, w1=0.0003248529898289963\n",
      "SGD(1250/2000): loss=0.4795354870530231, w(0)=-0.0008924037522923554, w1=0.00033315712460128507\n",
      "SGD(1300/2000): loss=0.5252030026003796, w(0)=-0.0009182458679639021, w1=0.00033535096561317936\n",
      "SGD(1350/2000): loss=0.4758333038466377, w(0)=-0.0009514301643145854, w1=0.0003557869376071316\n",
      "SGD(1400/2000): loss=0.41463955511807143, w(0)=-0.0009612264324738009, w1=0.0003677216918631217\n",
      "SGD(1450/2000): loss=0.39954535466239666, w(0)=-0.000997622082292491, w1=0.00037727409455392007\n",
      "SGD(1500/2000): loss=0.384708213569975, w(0)=-0.0010118190047469272, w1=0.0003910519286058643\n",
      "SGD(1550/2000): loss=0.44854075005307037, w(0)=-0.0010143471736228146, w1=0.0004087248801203662\n",
      "SGD(1600/2000): loss=0.4791225408514774, w(0)=-0.0010375850725788825, w1=0.0004235259772623843\n",
      "SGD(1650/2000): loss=0.5482955117471754, w(0)=-0.0010779920692104577, w1=0.0004387532744422733\n",
      "SGD(1700/2000): loss=0.4040634604196185, w(0)=-0.0010922070202502875, w1=0.0004561269895995798\n",
      "SGD(1750/2000): loss=0.5080046121524512, w(0)=-0.0011127604048127855, w1=0.00046438189631943657\n",
      "SGD(1800/2000): loss=0.4891652108135847, w(0)=-0.0011561370067255975, w1=0.00046994715562567437\n",
      "SGD(1850/2000): loss=0.3646746625094704, w(0)=-0.001200817361597854, w1=0.0004850773682914351\n",
      "SGD(1900/2000): loss=0.28927261812687677, w(0)=-0.0012621754790807045, w1=0.0005102466738942798\n",
      "SGD(1950/2000): loss=0.48538643983543744, w(0)=-0.0012573553771377287, w1=0.0005274184708090023\n",
      "SGD(2000/2000): loss=0.3149794310473352, w(0)=-0.0013060407056816356, w1=0.00053208791122281\n",
      "[0.49527504 0.31497943]\n",
      "[0.96212014 0.96104572]\n",
      "[0.67208  0.667984]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 2\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2730447  0.27282586]\n",
      "[  76886.14547321 1538054.20836699]\n",
      "[0.657896 0.656768]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 3\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2730471  0.27283294]\n",
      "[0.73954686 0.7399415 ]\n",
      "[0.81504  0.815104]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 4\n",
    "k_fold = 2\n",
    "degree = 5\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 86643.3975699927\n",
      "#Iteration: 250, Loss: 52616.21519581793\n",
      "#Iteration: 500, Loss: 51958.76076355233\n",
      "#Iteration: 750, Loss: 51703.97083734654\n",
      "#Iteration: 1000, Loss: 51559.57237741574\n",
      "#Iteration: 1250, Loss: 51463.719710887104\n",
      "#Iteration: 1500, Loss: 51394.720306089774\n",
      "#Iteration: 1750, Loss: 51342.655767373646\n",
      "#Iteration: 2000, Loss: 51302.17121988065\n",
      "#Iteration: 0, Loss: 86643.39756999268\n",
      "#Iteration: 250, Loss: 52445.21518742959\n",
      "#Iteration: 500, Loss: 51748.661202790216\n",
      "#Iteration: 750, Loss: 51481.83358100553\n",
      "#Iteration: 1000, Loss: 51331.417638854124\n",
      "#Iteration: 1250, Loss: 51231.626299937605\n",
      "#Iteration: 1500, Loss: 51159.646912556425\n",
      "#Iteration: 1750, Loss: 51105.19295191711\n",
      "#Iteration: 2000, Loss: 51062.75682266512\n",
      "[51302.02774771 51062.60629291]\n",
      "[51156.46754558 51352.67693744]\n",
      "[0.813512 0.81428 ]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 5\n",
    "k_fold = 2\n",
    "degree = 3\n",
    "lambda_ = 1e-5\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 86643.3975699927\n",
      "#Iteration: 250, Loss: 52616.215197568265\n",
      "#Iteration: 500, Loss: 51958.760765570136\n",
      "#Iteration: 750, Loss: 51703.970839533744\n",
      "#Iteration: 1000, Loss: 51559.57237974359\n",
      "#Iteration: 1250, Loss: 51463.71971333894\n",
      "#Iteration: 1500, Loss: 51394.72030865099\n",
      "#Iteration: 1750, Loss: 51342.65577002993\n",
      "#Iteration: 2000, Loss: 51302.17122261809\n",
      "#Iteration: 0, Loss: 86643.39756999268\n",
      "#Iteration: 250, Loss: 52445.21518923439\n",
      "#Iteration: 500, Loss: 51748.66120487704\n",
      "#Iteration: 750, Loss: 51481.83358326398\n",
      "#Iteration: 1000, Loss: 51331.41764125384\n",
      "#Iteration: 1250, Loss: 51231.62630246293\n",
      "#Iteration: 1500, Loss: 51159.646915194135\n",
      "#Iteration: 1750, Loss: 51105.19295465376\n",
      "#Iteration: 2000, Loss: 51062.75682548692\n",
      "[51302.02775045 51062.60629573]\n",
      "[51156.46754671 51352.6769381 ]\n",
      "[0.813512 0.81428 ]\n"
     ]
    }
   ],
   "source": [
    "method_flag = 6\n",
    "k_fold = 2\n",
    "degree = 3\n",
    "lambda_ = 1e-6\n",
    "gamma = 2.2e-6\n",
    "max_iters = 2000 \n",
    "losses_tr, losses_va, accuracy_scores = k_fold_cross_validation(y,tX,cat_cols,method_flag,k_fold,degree,lambda_,gamma,max_iters)\n",
    "print(losses_tr)\n",
    "print(losses_va)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(weights, x_val)\n",
    "y_val = relabel_y_negative(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, recall_score, precision_score\n",
    "print(confusion_matrix(y_val,y_pred))\n",
    "print(accuracy_score(y_val,y_pred))\n",
    "print(f1_score(y_val,y_pred))\n",
    "print(recall_score(y_val,y_pred))\n",
    "print(precision_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_y_counts(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../results/ridge_reg_submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, x_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
