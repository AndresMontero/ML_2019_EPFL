{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from proj1_helpers import *\n",
    "from proj1_utils import *\n",
    "from implementations_utils import *\n",
    "from implementations import *\n",
    "from proj1_visualization import *\n",
    "from proj1_cross_validation import *\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y_trainRaw, tX_trainRaw, ids_train = load_csv_data(DATA_TRAIN_PATH)\n",
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "y_testRaw, tX_testRaw, ids_test = load_csv_data(DATA_TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of Training \n",
    "\n",
    "cat_cols = [22]\n",
    "full_x_train_num, full_x_train_cat = split_numerical_categorical(tX_trainRaw,cat_cols)\n",
    "\n",
    "# Treat numerical values\n",
    "full_x_train_num_nan = replace_undef_val_with_nan(full_x_train_num)\n",
    "full_x_train_num_nan_std, train_mean, train_std = nan_standardize_fit(full_x_train_num_nan)\n",
    "\n",
    "full_x_train_num_valid_std = replace_nan_val_with_median(full_x_train_num_nan_std)\n",
    "full_x_train_num_valid_std = replace_iqr_outliers(full_x_train_num_valid_std)\n",
    "\n",
    "# Treat categorical values\n",
    "full_x_train_ohe_cat = one_hot_encode(full_x_train_cat)\n",
    "x_train_poly = build_poly(full_x_train_num_valid_std,3)\n",
    "full_x_train = np.hstack((x_train_poly,full_x_train_ohe_cat))\n",
    "\n",
    "# Treat labels\n",
    "full_y_train = y_trainRaw\n",
    "full_y_train = relabel_y_non_negative(full_y_train).reshape(-1,1)\n",
    "full_y_train = full_y_train.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and validation set\n",
    "x_train, y_train, x_val, y_val = split_data(full_x_train,full_y_train,0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of Test\n",
    "\n",
    "cat_cols = [22]\n",
    "x_test_num, x_test_cat = split_numerical_categorical(tX_testRaw,cat_cols)\n",
    "\n",
    "# Treat numerical values\n",
    "x_test_num_nan = replace_undef_val_with_nan(x_test_num)\n",
    "x_test_num_nan_std = nan_standardize_transform(x_test_num_nan,train_mean,train_std)\n",
    "x_test_num_valid_std = replace_nan_val_with_median(x_test_num_nan_std)\n",
    "x_test_num_valid_std = replace_iqr_outliers(x_test_num_valid_std)\n",
    "x_test_ohe_cat = one_hot_encode(x_test_cat)\n",
    "x_test_poly = build_poly(x_test_num_valid_std,3)\n",
    "x_test = np.hstack((x_test_poly,x_test_ohe_cat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 84725.66497321552\n",
      "#Iteration: 500, Loss: 83314.93088593178\n",
      "#Iteration: 750, Loss: 82787.21469085384\n",
      "#Iteration: 1000, Loss: 82494.51500940116\n"
     ]
    }
   ],
   "source": [
    "# Best Degree was polynomial 3\n",
    "max_iters = 1000\n",
    "gamma = 0.000001\n",
    "w_initial = np.zeros((full_x_train.shape[1], 1))\n",
    "weights, loss_tr,losses = logistic_regression(y_train, x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81084"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = relabel_y_negative(y_val)\n",
    "y_pred = predict_labels(weights, x_val)\n",
    "accuracy_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 138629.4361119856\n",
      "#Iteration: 250, Loss: 84726.22275867395\n",
      "#Iteration: 500, Loss: 83315.7173661692\n",
      "#Iteration: 750, Loss: 82788.14487469665\n",
      "#Iteration: 1000, Loss: 82495.55465048923\n"
     ]
    }
   ],
   "source": [
    "w_initial = np.zeros((x_train.shape[1], 1))\n",
    "weights,_,_ = reg_logistic_regression(y_train, x_train, w_initial, max_iters, gamma, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81084"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = relabel_y_negative(y_val)\n",
    "y_pred = predict_labels(weights, x_val)\n",
    "accuracy_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 110903.5488895897\n",
      "#Iteration: 250, Loss: 68376.50218850648\n",
      "#Iteration: 500, Loss: 67007.34552271449\n",
      "#Iteration: 750, Loss: 66502.40935577865\n",
      "#Iteration: 1000, Loss: 66226.20247440969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\EPFL\\Machine-Learning\\2019-2020\\ML_2019_EPFL\\projects\\project1\\scripts\\proj1_cross_validation.py:78: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Iteration: 0, Loss: 110903.5488895897\n",
      "#Iteration: 250, Loss: 68157.55667564325\n",
      "#Iteration: 500, Loss: 66787.44746189806\n",
      "#Iteration: 750, Loss: 66287.0267579032\n",
      "#Iteration: 1000, Loss: 66014.99700464892\n",
      "#Iteration: 0, Loss: 110903.54888958971\n",
      "#Iteration: 250, Loss: 68334.05624165178\n",
      "#Iteration: 500, Loss: 66972.92801224273\n",
      "#Iteration: 750, Loss: 66475.3421855915\n",
      "#Iteration: 1000, Loss: 66204.75499245182\n",
      "#Iteration: 0, Loss: 110903.54888958971\n",
      "#Iteration: 250, Loss: 68459.77208337637\n",
      "#Iteration: 500, Loss: 67110.57056169314\n",
      "#Iteration: 750, Loss: 66612.7682498139\n",
      "#Iteration: 1000, Loss: 66340.26743276972\n",
      "#Iteration: 0, Loss: 110903.54888958971\n",
      "#Iteration: 250, Loss: 68208.93549907033\n",
      "#Iteration: 500, Loss: 66834.76146407175\n",
      "#Iteration: 750, Loss: 66330.25956338288\n",
      "#Iteration: 1000, Loss: 66054.89953819114\n"
     ]
    }
   ],
   "source": [
    "_, loss_val, _, accuracy_val = cross_validation_log(x_train, y_train, 0.1, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115349999999999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../results/reg_log_reg.csv' \n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to delete empty rows\n",
    "with open('../results/reg_log_reg.csv') as input, open('../results/reg_log_reg_cleaned.csv', 'w', newline='') as output:\n",
    "    writer = csv.writer(output)\n",
    "    for row in csv.reader(input):\n",
    "        if any(field.strip() for field in row):\n",
    "            writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
