{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cnnDataAugV9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5UtF5J4gPg3",
        "colab_type": "code",
        "outputId": "60da9536-5992-455d-a5fd-e9c10e8d7b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Vr6E4PsBtV",
        "colab_type": "text"
      },
      "source": [
        "Here write the path where you cloned the repository + ML_2019_EPFL/projects/project2/project_road_segmentation/\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0fQ0i96gQJh",
        "colab_type": "code",
        "outputId": "a67434e5-60d0-494e-f1b2-ca3189770e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/ML_2019_EPFL/projects/project2/project_road_segmentation/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML_2019_EPFL/projects/project2/project_road_segmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwdRfM46pgqS",
        "colab_type": "code",
        "outputId": "27929cd5-f5ed-460d-e477-bcf45b682032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxsNkqH6qCds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as keras\n",
        "from helpers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqTSu2KEqEiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdkOOsqaWgjE",
        "colab_type": "code",
        "outputId": "5153f2a2-8ebc-475f-ae9c-045b1a9602ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeVK37FkqHG4",
        "colab_type": "code",
        "outputId": "6c27e7cc-e884-4a76-ae27-f3dc8a9186bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load a set of images\n",
        "root_dir = \"data/training/\"\n",
        "\n",
        "# Select the directory for the images and load them\n",
        "image_dir = root_dir + \"images/\"\n",
        "files = os.listdir(image_dir)\n",
        "n = len(files) \n",
        "\n",
        "print(\"Loading \" + str(n) + \" images\")\n",
        "imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
        "\n",
        "# Select the directory for groundtruth images and load them\n",
        "gt_dir = root_dir + \"groundtruth/\"\n",
        "print(\"Loading \" + str(n) + \" groundtruth images\")\n",
        "gt_imgs = np.asarray([load_image(gt_dir + files[i]) for i in range(n)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading 100 images\n",
            "Loading 100 groundtruth images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFeFaQaEqwDn",
        "colab_type": "text"
      },
      "source": [
        "# Generating mini-batch and running data augmentationÂ¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgmw9xk47eW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_matrix(mat,h_pad,w_pad,val=0):\n",
        "  h_pad = int(h_pad)\n",
        "  w_pad = int(w_pad)\n",
        "  if len(mat.shape)==3:\n",
        "    padded_mat = np.pad(mat,((h_pad,h_pad),(w_pad,w_pad),(0,0)),mode='constant',constant_values=((val,val),(val,val),(0,0)))\n",
        "  elif len(mat.shape)==2:\n",
        "    padded_mat = np.pad(mat,((h_pad,h_pad),(w_pad,w_pad)),mode='constant',constant_values=((val,val),(val,val)))\n",
        "  else:\n",
        "    raise ValueError(\"This method can only handle 2d or 3d arrays\")\n",
        "  return padded_mat\n",
        "\n",
        "def imag_rotation(X,Y,number_rotations = 8): \n",
        "  \n",
        "  w = X.shape[1]\n",
        "  w_2 = w//2 # half of the width\n",
        "  padding = 82\n",
        "  padding2 = 24\n",
        "  Xrs = X\n",
        "  Yrs = Y\n",
        "  \n",
        "  ### Add padding2\n",
        "  Xrs = pad_matrix(Xrs,padding2,padding2) \n",
        "  Yrs = pad_matrix(Yrs,padding2,padding2) \n",
        "    ###\n",
        "\n",
        "  Xrs = np.expand_dims(Xrs, 0)\n",
        "  Yrs = np.expand_dims(Yrs, 0)\n",
        "\n",
        "  thetas = np.random.randint(0,high = 360,size = number_rotations)\n",
        "  for theta in thetas:\n",
        "    Xr = pad_matrix(X,padding,padding) # Selected for the specific case of images of (400,400) \n",
        "    Yr = pad_matrix(Y,padding,padding) # Selected for the specific case of images of (400,400) \n",
        "    Xr = scipy.ndimage.rotate(Xr, theta , reshape = False) \n",
        "    Yr = scipy.ndimage.rotate(Yr, theta , reshape = False) \n",
        "    theta = theta*np.pi/180\n",
        "    a = int(w_2/(np.sqrt(2)*np.cos(np.pi/4-np.mod(theta,np.pi/2)))) # width and height of the biggest square inside the rotated square \n",
        "    w_p = w_2+padding\n",
        "    Xr = Xr[w_p-a:w_p+a,w_p-a:w_p+a,:]\n",
        "    Yr = Yr[w_p-a:w_p+a,w_p-a:w_p+a]\n",
        "\n",
        "    Xr = cv2.resize(Xr, dsize=(w_2*2, w_2*2), interpolation=cv2.INTER_CUBIC)\n",
        "    Yr = cv2.resize(Yr, dsize=(w_2*2, w_2*2), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    if np.random.choice(2) == 1:\n",
        "      Xr = np.flipud(Xr)\n",
        "      Yr = np.flipud(Yr)\n",
        "            \n",
        "    if np.random.choice(2) == 1:\n",
        "      Xr = np.fliplr(Xr)\n",
        "      Yr = np.fliplr(Yr)\n",
        "    \n",
        "    ### Add padding2\n",
        "    Xr = pad_matrix(Xr,padding2,padding2) \n",
        "    Yr = pad_matrix(Yr,padding2,padding2) \n",
        "    ###\n",
        "\n",
        "    Xr = np.expand_dims(Xr,0)\n",
        "    Yr = np.expand_dims(Yr,0)\n",
        "    Xrs = np.append(Xrs,Xr,axis = 0)\n",
        "    Yrs = np.append(Yrs,Yr,axis = 0)\n",
        "\n",
        "  return Xrs, Yrs\n",
        "\n",
        "def imag_rotation_aug(Xr,Yr,number_rotations = 8):\n",
        "  \n",
        "  Xrs,Yrs = imag_rotation(Xr[0],Yr[0])\n",
        "  for i in range(1,len(Xr)):\n",
        "    Xrr,Yrr = imag_rotation(Xr[i],Yr[i])\n",
        "    Xrs = np.append(Xrs,Xrr,axis = 0)\n",
        "    Yrs = np.append(Yrs,Yrr,axis = 0)\n",
        "\n",
        "  Xrs_shuf = []\n",
        "  Yrs_shuf = []\n",
        "  index_shuf = list(range(len(Xrs)))\n",
        "  np.random.shuffle(index_shuf)\n",
        "  for i in index_shuf:\n",
        "    Xrs_shuf.append(Xrs[i])\n",
        "    Yrs_shuf.append(Yrs[i])\n",
        "\n",
        "  return Xrs_shuf, Yrs_shuf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYL_mkx48j5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,Y = imag_rotation_aug(imgs,gt_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh07sjGhR80-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c4cEYweR-rN",
        "colab_type": "code",
        "outputId": "f4ccb949-9026-453f-c7bd-f80125fee11f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(900, 448, 448, 3)\n",
            "(900, 448, 448)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BPs26G0qTTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_minibatch():\n",
        "    \n",
        "    # Fix the seed\n",
        "    #np.random.seed(1)\n",
        "    \n",
        "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
        "    # and patch size should correspond to 16\n",
        "    w_size = 64\n",
        "    batch_size = 1200\n",
        "    patch_size = 16\n",
        "    num_images = 900\n",
        "    \n",
        "    while True:\n",
        "        # Generate one minibatch\n",
        "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
        "        batch_label = np.empty((batch_size, 2))\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            \n",
        "            # Select a random index representing an image\n",
        "            random_index = np.random.choice(num_images)\n",
        "            \n",
        "            # Width of original image\n",
        "            width = 448\n",
        "            \n",
        "            # Sample a random window from the image\n",
        "            random_sample = np.random.randint(w_size//2, width - w_size//2, 2)\n",
        "            \n",
        "            # Create a sub image of size 72x72\n",
        "            sampled_image = X[random_index][random_sample[0] - w_size // 2 : random_sample[0] + w_size//2,\n",
        "                                            random_sample[1] - w_size//2 : random_sample[1] + w_size//2]\n",
        "                \n",
        "            # Take its corresponding ground-truth image\n",
        "            correspond_ground_truth = Y[random_index][random_sample[0] - patch_size//2:random_sample[0] + patch_size//2,\n",
        "                                                      random_sample[1]-patch_size//2:random_sample[1] + patch_size//2]\n",
        "            \n",
        "            # Additional flip \n",
        "            if np.random.choice(2) == 1:\n",
        "                sampled_image = np.flipud(sampled_image)\n",
        "                correspond_ground_truth = np.flipud(correspond_ground_truth)\n",
        "            if np.random.choice(2) == 1:\n",
        "                sampled_image = np.fliplr(sampled_image)\n",
        "                correspond_ground_truth = np.fliplr(correspond_ground_truth)\n",
        "    \n",
        "\n",
        "\n",
        "            # We set in the label depending on the threshold of 0.25\n",
        "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
        "\n",
        "            label = to_categorical((np.array([np.mean(correspond_ground_truth)]) > 0.25) * 1,2)\n",
        "                        \n",
        "            # We put in the sub image and its corresponding label before yielding it\n",
        "            batch_image[i] = sampled_image\n",
        "            batch_label[i] = label\n",
        "\n",
        "            i+=0\n",
        "\n",
        "        # Yield the mini_batch to the model\n",
        "        yield(batch_image, batch_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCTyqK1Uq91U",
        "colab_type": "text"
      },
      "source": [
        "# Creating the class (Same as in cnn_model.py, but provided here for better readability)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM1d--Muq_ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cnn_model:\n",
        "    \n",
        "    # Initialize the class\n",
        "    def __init__(self, shape):\n",
        "        self.shape = shape\n",
        "        self.model = self.initialize_cnn_model(shape)\n",
        "    \n",
        "    def initialize_cnn_model(self, shape):\n",
        "        \n",
        "        # INPUT\n",
        "        # shape     - Size of the input images\n",
        "        # OUTPUT\n",
        "        # model    - Compiled CNN\n",
        "        \n",
        "        # Define hyperparamters\n",
        "        KERNEL3 = (3, 3)\n",
        "        KERNEL5 = (5, 5)\n",
        "        \n",
        "        # Define a model\n",
        "        model = Sequential()\n",
        "        \n",
        "        # Add the layers\n",
        "        # Selection of the model is described in the report\n",
        "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
        "        model.add(Conv2D(64, KERNEL5, input_shape = shape, padding='same'))\n",
        "        model.add(LeakyReLU(alpha=0.1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(128, KERNEL3, padding='same'))\n",
        "        model.add(LeakyReLU(alpha=0.1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(256, KERNEL3, padding='same'))\n",
        "        model.add(LeakyReLU(alpha=0.1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(512, KERNEL3, padding='same'))\n",
        "        model.add(LeakyReLU(alpha=0.1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        # Flatten it and use regularizers to avoid overfitting\n",
        "        # The parameters have been chosen empirically\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)))\n",
        "        model.add(LeakyReLU(alpha=0.1))\n",
        "        model.add(Dropout(0.5))\n",
        "        \n",
        "        # Add output layer\n",
        "        model.add(Dense(2, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)))\n",
        "        model.add(Activation('sigmoid'))\n",
        "        \n",
        "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
        "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
        "        model.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(lr=0.001),\n",
        "                      metrics=['accuracy'])\n",
        "            \n",
        "        # Print a summary of the model to see what has been generated\n",
        "        model.summary()\n",
        "                      \n",
        "        return model\n",
        "    \n",
        "    def train(self):\n",
        "        \n",
        "        # We define the number of epochs and steps per epochs\n",
        "        EPOCHS = 50\n",
        "        STEPS_PER_EPOCH = 300\n",
        "        \n",
        "        # Early stopping callback after 10 steps\n",
        "        early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "        \n",
        "        # Reduce learning rate on plateau after 4 steps\n",
        "        lr_callback = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=4, verbose=1, mode='auto')\n",
        "        \n",
        "        # Place the callbacks in a list to be used when training\n",
        "        callbacks = [early_stopping]\n",
        "        \n",
        "        # Train the model using the previously defined functions and callbacks\n",
        "        history = self.model.fit_generator(create_minibatch(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, workers=1, callbacks=callbacks, verbose=1)\n",
        "        return history\n",
        "\n",
        "    def classify(self, X):\n",
        "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
        "        img_patches = create_patches(X, 16, 16, padding=24)\n",
        "        \n",
        "        # Predict\n",
        "        predictions = self.model.predict(img_patches)\n",
        "        predictions = (predictions[:,0] < predictions[:,1]) * 1\n",
        "        \n",
        "        # Regroup patches into images\n",
        "        return group_patches(predictions, X.shape[0])\n",
        "    \n",
        "    def load(self, filename):\n",
        "        # Load the model (used for submission)\n",
        "        self.model = load_model(filename)\n",
        "    \n",
        "    def save(self, filename):\n",
        "        # Save the model (used to then load to submit)\n",
        "        self.model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyJY1TFFrEgu",
        "colab_type": "code",
        "outputId": "06802c77-b6b9-473e-bd92-fb2d10ddebda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
        "model = cnn_model(shape = (64, 64, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 64)        4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1048704   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 2,603,010\n",
            "Trainable params: 2,603,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMfK1WTVrG3V",
        "colab_type": "code",
        "outputId": "b43a0e54-2887-41bc-b4d3-ac819b23310e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# Train the model\n",
        "history = model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "300/300 [==============================] - 327s 1s/step - loss: 0.4598 - acc: 0.7826\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 316s 1s/step - loss: 0.3018 - acc: 0.8632\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 316s 1s/step - loss: 0.2378 - acc: 0.8965\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 315s 1s/step - loss: 0.2077 - acc: 0.9125\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 315s 1s/step - loss: 0.1921 - acc: 0.9199\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 315s 1s/step - loss: 0.1819 - acc: 0.9249\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 318s 1s/step - loss: 0.1716 - acc: 0.9298\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 318s 1s/step - loss: 0.1668 - acc: 0.9322\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 318s 1s/step - loss: 0.1592 - acc: 0.9355\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 318s 1s/step - loss: 0.1543 - acc: 0.9375\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 318s 1s/step - loss: 0.1484 - acc: 0.9401\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 317s 1s/step - loss: 0.1471 - acc: 0.9408\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 317s 1s/step - loss: 0.1433 - acc: 0.9426\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 317s 1s/step - loss: 0.1405 - acc: 0.9437\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 316s 1s/step - loss: 0.1396 - acc: 0.9447\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 317s 1s/step - loss: 0.1372 - acc: 0.9452\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 314s 1s/step - loss: 0.1345 - acc: 0.9469\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 313s 1s/step - loss: 0.1331 - acc: 0.9472\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 314s 1s/step - loss: 0.1322 - acc: 0.9479\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 315s 1s/step - loss: 0.1287 - acc: 0.9494\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 314s 1s/step - loss: 0.1280 - acc: 0.9496\n",
            "Epoch 22/50\n",
            "138/300 [============>.................] - ETA: 2:50 - loss: 0.1276 - acc: 0.9496"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAuvo7Ba_AVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.save(\"AugV10-1.h5\")\n",
        "\n",
        "print(history.history.keys())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uts-_f08rJfl",
        "colab_type": "code",
        "outputId": "717d23ab-805d-4f94-da0b-b0332ec5d179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "#plt.plot(history.history['1r'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['1r'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-54b846fa58fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.plot(history.history['1r'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ruD2oXW-WPg",
        "colab_type": "code",
        "outputId": "d7bda246-4424-44d3-943b-7106ded2e614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "model.load(\"AugV9-6.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HmU_gp3--zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.classify()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKr3WJvhoghD",
        "colab_type": "code",
        "outputId": "d9aea685-d086-44e0-850b-9f065987c138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from helpers import *\n",
        "\n",
        "# from cnn_model import cnn_model\n",
        "\n",
        "# Instantiate the model\n",
        "batch_normalization = True\n",
        "activation = \"LeakyReLU\"\n",
        "#model = cnn_model(\n",
        "#    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
        "#)\n",
        "\n",
        "# Load the model\n",
        "#model.load(\"AugV8.h5\") # cargar tu modelo con los mejores weights\n",
        "\n",
        "# Print a summary to make sure the correct model is used\n",
        "model.model.summary()\n",
        "\n",
        "# We add all test images to an array, used later for generating a submission\n",
        "image_filenames = []\n",
        "for i in range(1, 51):\n",
        "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
        "    image_filenames.append(image_filename)\n",
        "\n",
        "# Set-up submission filename\n",
        "submission_filename = \"blablabla7.csv\"\n",
        "\n",
        "# Generates the submission\n",
        "generate_submission(model, submission_filename, *image_filenames)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 72, 72, 64)        4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 72, 72, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 36, 36, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 36, 36, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 18, 18, 256)       295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1638528   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 3,192,834\n",
            "Trainable params: 3,192,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Processing image => data/test_set_images/test_1/test_1.png\n",
            "Processing image => data/test_set_images/test_2/test_2.png\n",
            "Processing image => data/test_set_images/test_3/test_3.png\n",
            "Processing image => data/test_set_images/test_4/test_4.png\n",
            "Processing image => data/test_set_images/test_5/test_5.png\n",
            "Processing image => data/test_set_images/test_6/test_6.png\n",
            "Processing image => data/test_set_images/test_7/test_7.png\n",
            "Processing image => data/test_set_images/test_8/test_8.png\n",
            "Processing image => data/test_set_images/test_9/test_9.png\n",
            "Processing image => data/test_set_images/test_10/test_10.png\n",
            "Processing image => data/test_set_images/test_11/test_11.png\n",
            "Processing image => data/test_set_images/test_12/test_12.png\n",
            "Processing image => data/test_set_images/test_13/test_13.png\n",
            "Processing image => data/test_set_images/test_14/test_14.png\n",
            "Processing image => data/test_set_images/test_15/test_15.png\n",
            "Processing image => data/test_set_images/test_16/test_16.png\n",
            "Processing image => data/test_set_images/test_17/test_17.png\n",
            "Processing image => data/test_set_images/test_18/test_18.png\n",
            "Processing image => data/test_set_images/test_19/test_19.png\n",
            "Processing image => data/test_set_images/test_20/test_20.png\n",
            "Processing image => data/test_set_images/test_21/test_21.png\n",
            "Processing image => data/test_set_images/test_22/test_22.png\n",
            "Processing image => data/test_set_images/test_23/test_23.png\n",
            "Processing image => data/test_set_images/test_24/test_24.png\n",
            "Processing image => data/test_set_images/test_25/test_25.png\n",
            "Processing image => data/test_set_images/test_26/test_26.png\n",
            "Processing image => data/test_set_images/test_27/test_27.png\n",
            "Processing image => data/test_set_images/test_28/test_28.png\n",
            "Processing image => data/test_set_images/test_29/test_29.png\n",
            "Processing image => data/test_set_images/test_30/test_30.png\n",
            "Processing image => data/test_set_images/test_31/test_31.png\n",
            "Processing image => data/test_set_images/test_32/test_32.png\n",
            "Processing image => data/test_set_images/test_33/test_33.png\n",
            "Processing image => data/test_set_images/test_34/test_34.png\n",
            "Processing image => data/test_set_images/test_35/test_35.png\n",
            "Processing image => data/test_set_images/test_36/test_36.png\n",
            "Processing image => data/test_set_images/test_37/test_37.png\n",
            "Processing image => data/test_set_images/test_38/test_38.png\n",
            "Processing image => data/test_set_images/test_39/test_39.png\n",
            "Processing image => data/test_set_images/test_40/test_40.png\n",
            "Processing image => data/test_set_images/test_41/test_41.png\n",
            "Processing image => data/test_set_images/test_42/test_42.png\n",
            "Processing image => data/test_set_images/test_43/test_43.png\n",
            "Processing image => data/test_set_images/test_44/test_44.png\n",
            "Processing image => data/test_set_images/test_45/test_45.png\n",
            "Processing image => data/test_set_images/test_46/test_46.png\n",
            "Processing image => data/test_set_images/test_47/test_47.png\n",
            "Processing image => data/test_set_images/test_48/test_48.png\n",
            "Processing image => data/test_set_images/test_49/test_49.png\n",
            "Processing image => data/test_set_images/test_50/test_50.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buGfiboa6SS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}