{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from utils import *\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.compat.v2.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2588520503679708072\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4937233203\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2336674795719986523\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(8)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images, images loaded: 100 \n",
      "Loading groundtruth images, images loaded: 100 \n"
     ]
    }
   ],
   "source": [
    "image_dir_train = \"data/training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "print(f\"Loading training images, images loaded: {n_train} \")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "gt_dir_train = \"data/training/groundtruth/\"\n",
    "print(f\"Loading groundtruth images, images loaded: {n_train} \")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "# Patches for training\n",
    "img_patches_train = [\n",
    "    crop_image(imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "gt_patches_train = [\n",
    "    crop_image(gt_imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = np.asarray(\n",
    "    [\n",
    "        img_patches_train[i][j]\n",
    "        for i in range(len(img_patches_train))\n",
    "        for j in range(len(img_patches_train[i]))\n",
    "    ]\n",
    ")\n",
    "Y_train = np.asarray(\n",
    "    [\n",
    "        gt_patches_train[i][j]\n",
    "        for i in range(len(gt_patches_train))\n",
    "        for j in range(len(gt_patches_train[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dir_val = \"data/validating/images/\"\n",
    "# files = os.listdir(image_dir_val)\n",
    "# n_val = len(files)\n",
    "# print(f\"Loading validating images, images loaded: {n_val} \")\n",
    "# imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "# gt_dir_val = \"data/validating/groundtruth/\"\n",
    "# print(f\"Loading validating groundtruth, images loaded: {n_val} \")\n",
    "# gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 400\n",
    "# # Patches for validating\n",
    "# img_patches_val = [\n",
    "#     crop_image(imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "# ]\n",
    "# gt_patches_val = [\n",
    "#     crop_image(gt_imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "# ]\n",
    "\n",
    "# # Separate features and labels\n",
    "# X_val = np.asarray(\n",
    "#     [\n",
    "#         img_patches_val[i][j]\n",
    "#         for i in range(len(img_patches_val))\n",
    "#         for j in range(len(img_patches_val[i]))\n",
    "#     ]\n",
    "# )\n",
    "# Y_val = np.asarray(\n",
    "#     [\n",
    "#         gt_patches_val[i][j]\n",
    "#         for i in range(len(gt_patches_val))\n",
    "#         for j in range(len(gt_patches_val[i]))\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = imag_rotation_aug(imgs_train, gt_imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 456, 456, 3)\n",
      "(900, 456, 456)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "n_train = Y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val, Y_val = imag_rotation_aug(imgs_val, gt_imgs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val = np.asarray(X_val)\n",
    "# Y_val = np.asarray(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_val.shape)\n",
    "# print(Y_val.shape)\n",
    "# n_val = Y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions to calcualte precision, recall and F-1 in the training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Compute the Precision for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "        Precision (numpy.float64): the Precision of the batch \n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Compute the Recall for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "       Recall (numpy.float64): the Recal of the batch \n",
    "    \"\"\"\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Compute the F-1 for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "       F-1 (numpy.float64): the F-1 of the batch \n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erick architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.model = self.initialize_U_NET(shape)\n",
    "\n",
    "    def initialize_U_NET(self, shape):\n",
    "        \"\"\"Create Network Architecture.\n",
    "        Args:\n",
    "            shape (triplet): Size of the input layer height x width x colors (64 x 64 x 3)\n",
    "        Returns:\n",
    "            model (Neural Network): Architecture of the model\n",
    "        \"\"\"\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Conv2D(512, KERNEL3, padding=\"same\"))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                128, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)\n",
    "            )\n",
    "        )\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the Model.\n",
    "\n",
    "        Returns:\n",
    "            History (History_Keras): History of the training\n",
    "        \"\"\"\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"loss\", patience=10, verbose=1, restore_best_weights=True,\n",
    "        )\n",
    "        # Reduce learning rate on plateau after 5 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"loss\", factor=0.8, patience=4, verbose=1, cooldown=1,\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"Erick_dropout-{epoch:03d}-{f1:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"loss\",\n",
    "            verbose=1,\n",
    "        )\n",
    "        callbacks = [lr_callback, save_best, early_stopping]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(\n",
    "                X_train, Y_train, n_train, WINDOW_SIZE, BATCH_SIZE, PATCH_SIZE, WIDTH\n",
    "            ),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            #             validation_data=create_minibatch(\n",
    "            #                 X_val, Y_val, n_val, WINDOW_SIZE, BATCH_SIZE, PATCH_SIZE, WIDTH\n",
    "            #             ),\n",
    "            #             validation_steps=STEPS_PER_EPOCH / 3,\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        \"\"\"Classify Image as either road or not.\n",
    "        Args:\n",
    "            X (image): part of the image to classify\n",
    "        Returns:\n",
    "            Predictions : Predictions for each patch\n",
    "        \"\"\"\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return predictions.reshape(X.shape[0], -1)\n",
    "\n",
    "    #         return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"Loads Saved Model.\n",
    "        Args:\n",
    "           filename (string): name of the model\n",
    "           \n",
    "        \"\"\"\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"Saves trained model.\n",
    "        Args:\n",
    "           filename (string): name of the model\n",
    "           \n",
    "        \"\"\"\n",
    "        self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,603,010\n",
      "Trainable params: 2,603,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We define parameters of the model\n",
    "BATCH_SIZE = 300\n",
    "WINDOW_SIZE = 64\n",
    "PATCH_SIZE = 16\n",
    "EPOCHS = 300\n",
    "STEPS_PER_EPOCH = 100\n",
    "WIDTH = 448\n",
    "model = CNN(shape=(WINDOW_SIZE, WINDOW_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.5494 - accuracy: 0.7576 - recall: 0.7588 - f1: 0.7580\n",
      "Epoch 00001: loss improved from inf to 0.54927, saving model to Erick_dropout-001-0.757924.h5\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.5493 - accuracy: 0.7575 - recall: 0.7587 - f1: 0.7579\n",
      "Epoch 2/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.7499 - recall: 0.7492 - f1: 0.7498\n",
      "Epoch 00002: loss improved from 0.54927 to 0.50086, saving model to Erick_dropout-002-0.749423.h5\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.5009 - accuracy: 0.7496 - recall: 0.7489 - f1: 0.7494\n",
      "Epoch 3/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4731 - accuracy: 0.7609 - recall: 0.7594 - f1: 0.7605\n",
      "Epoch 00003: loss improved from 0.50086 to 0.47233, saving model to Erick_dropout-003-0.761112.h5\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.4723 - accuracy: 0.7614 - recall: 0.7603 - f1: 0.7611\n",
      "Epoch 4/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7740 - recall: 0.7745 - f1: 0.7741\n",
      "Epoch 00004: loss improved from 0.47233 to 0.46972, saving model to Erick_dropout-004-0.774242.h5\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.4697 - accuracy: 0.7742 - recall: 0.7746 - f1: 0.7742\n",
      "Epoch 5/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4323 - accuracy: 0.7952 - recall: 0.7974 - f1: 0.7956\n",
      "Epoch 00005: loss improved from 0.46972 to 0.43184, saving model to Erick_dropout-005-0.795921.h5\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.4318 - accuracy: 0.7955 - recall: 0.7978 - f1: 0.7959\n",
      "Epoch 6/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8190 - recall: 0.8202 - f1: 0.8192\n",
      "Epoch 00006: loss improved from 0.43184 to 0.38892, saving model to Erick_dropout-006-0.819471.h5\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 0.3889 - accuracy: 0.8193 - recall: 0.8204 - f1: 0.8195\n",
      "Epoch 7/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3449 - accuracy: 0.8430 - recall: 0.8424 - f1: 0.8429\n",
      "Epoch 00007: loss improved from 0.38892 to 0.34476, saving model to Erick_dropout-007-0.843140.h5\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.3448 - accuracy: 0.8432 - recall: 0.8426 - f1: 0.8431\n",
      "Epoch 8/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3314 - accuracy: 0.8520 - recall: 0.8524 - f1: 0.8520\n",
      "Epoch 00008: loss improved from 0.34476 to 0.33059, saving model to Erick_dropout-008-0.852497.h5\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.3306 - accuracy: 0.8524 - recall: 0.8529 - f1: 0.8525\n",
      "Epoch 9/300\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.3014 - accuracy: 0.8655 - recall: 0.8655 - f1: 0.8655\n",
      "Epoch 00009: loss improved from 0.33059 to 0.30175, saving model to Erick_dropout-009-0.865496.h5\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 0.3017 - accuracy: 0.8655 - recall: 0.8655 - f1: 0.8655\n",
      "Epoch 10/300\n",
      " 17/100 [====>.........................] - ETA: 26s - loss: 0.3065 - accuracy: 0.8708 - recall: 0.8710 - f1: 0.8707"
     ]
    }
   ],
   "source": [
    "history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"][1:], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"][1:], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"][1:], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"][1:], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plots/Erick_dropout.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model\n",
    "# model = U_NET(shape=(WINDOW_SIZE, WINDOW_SIZE, 3))\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\"Erick_batchnorm_validation-037-0.911644.h5\")\n",
    "\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = \"Erick_batchnorm_validation-037-0.911644.csv\"\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
