{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "Use tensorflow.keras or Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from datetime import datetime\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary for our model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    LeakyReLU,\n",
    "    GaussianNoise,\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "from kerassurgeon.operations import delete_layer, insert_layer, replace_layer\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from tensorflow.compat.v2.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = 0\n",
    "best = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = \"data/training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "print(f\"Loading training images, images loaded: {n_train} \")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "gt_dir_train = \"data/training/groundtruth/\"\n",
    "print(f\"Loading groundtruth images, images loaded: {n_train} \")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "# Patches for training\n",
    "img_patches_train = [\n",
    "    crop_image(imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "gt_patches_train = [\n",
    "    crop_image(gt_imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = np.asarray(\n",
    "    [\n",
    "        img_patches_train[i][j]\n",
    "        for i in range(len(img_patches_train))\n",
    "        for j in range(len(img_patches_train[i]))\n",
    "    ]\n",
    ")\n",
    "Y_train = np.asarray(\n",
    "    [\n",
    "        gt_patches_train[i][j]\n",
    "        for i in range(len(gt_patches_train))\n",
    "        for j in range(len(gt_patches_train[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dir_val = \"data/validating/images/\"\n",
    "files = os.listdir(image_dir_val)\n",
    "n_val = len(files)\n",
    "print(f\"Loading validating images, images loaded: {n_val} \")\n",
    "imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "gt_dir_val = \"data/validating/groundtruth/\"\n",
    "print(f\"Loading validating groundtruth, images loaded: {n_val} \")\n",
    "gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "# Patches for validating\n",
    "img_patches_val = [\n",
    "    crop_image(imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "]\n",
    "gt_patches_val = [\n",
    "    crop_image(gt_imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "]\n",
    "\n",
    "# Separate features and labels\n",
    "X_val = np.asarray(\n",
    "    [\n",
    "        img_patches_val[i][j]\n",
    "        for i in range(len(img_patches_val))\n",
    "        for j in range(len(img_patches_val[i]))\n",
    "    ]\n",
    ")\n",
    "Y_val = np.asarray(\n",
    "    [\n",
    "        gt_patches_val[i][j]\n",
    "        for i in range(len(gt_patches_val))\n",
    "        for j in range(len(gt_patches_val[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data augmentation\n",
    "Method 1 or 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 1\n",
    "data_aug_factor = 1\n",
    "if method == 2:\n",
    "    data_aug_factor = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 2:\n",
    "\n",
    "    def pad_matrix(mat, h_pad, w_pad, val=0):\n",
    "        h_pad = int(h_pad)\n",
    "        w_pad = int(w_pad)\n",
    "        if len(mat.shape) == 3:\n",
    "            padded_mat = np.pad(\n",
    "                mat,\n",
    "                ((h_pad, h_pad), (w_pad, w_pad), (0, 0)),\n",
    "                mode=\"constant\",\n",
    "                constant_values=((val, val), (val, val), (0, 0)),\n",
    "            )\n",
    "        elif len(mat.shape) == 2:\n",
    "            padded_mat = np.pad(\n",
    "                mat,\n",
    "                ((h_pad, h_pad), (w_pad, w_pad)),\n",
    "                mode=\"constant\",\n",
    "                constant_values=((val, val), (val, val)),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"This method can only handle 2d or 3d arrays\")\n",
    "        return padded_mat\n",
    "\n",
    "    def imag_rotation(X, Y, number_rotations=8):\n",
    "\n",
    "        w = X.shape[1]\n",
    "        w_2 = w // 2  # half of the width\n",
    "        padding = 82\n",
    "        Xrs = X\n",
    "        Yrs = Y\n",
    "\n",
    "        Xrs = np.expand_dims(Xrs, 0)\n",
    "        Yrs = np.expand_dims(Yrs, 0)\n",
    "\n",
    "        thetas = np.random.randint(0, high=360, size=number_rotations)\n",
    "        for theta in thetas:\n",
    "            Xr = pad_matrix(\n",
    "                X, padding, padding\n",
    "            )  # Selected for the specific case of images of (400,400)\n",
    "            Yr = pad_matrix(\n",
    "                Y, padding, padding\n",
    "            )  # Selected for the specific case of images of (400,400)\n",
    "            Xr = scipy.ndimage.rotate(Xr, theta, reshape=False)\n",
    "            Yr = scipy.ndimage.rotate(Yr, theta, reshape=False)\n",
    "            theta = theta * np.pi / 180\n",
    "            a = int(\n",
    "                w_2 / (np.sqrt(2) * np.cos(np.pi / 4 - np.mod(theta, np.pi / 2)))\n",
    "            )  # width and height of the biggest square inside the rotated square\n",
    "            w_p = w_2 + padding\n",
    "            Xr = Xr[w_p - a : w_p + a, w_p - a : w_p + a, :]\n",
    "            Yr = Yr[w_p - a : w_p + a, w_p - a : w_p + a]\n",
    "\n",
    "            Xr = cv2.resize(Xr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "            Yr = cv2.resize(Yr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                Xr = np.flipud(Xr)\n",
    "                Yr = np.flipud(Yr)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                Xr = np.fliplr(Xr)\n",
    "                Yr = np.fliplr(Yr)\n",
    "\n",
    "            Xr = np.expand_dims(Xr, 0)\n",
    "            Yr = np.expand_dims(Yr, 0)\n",
    "            Xrs = np.append(Xrs, Xr, axis=0)\n",
    "            Yrs = np.append(Yrs, Yr, axis=0)\n",
    "\n",
    "        return Xrs, Yrs\n",
    "\n",
    "    def imag_rotation_aug(Xr, Yr, number_rotations=8):\n",
    "\n",
    "        Xrs, Yrs = imag_rotation(Xr[0], Yr[0])\n",
    "        for i in range(1, len(Xr)):\n",
    "            Xrr, Yrr = imag_rotation(Xr[i], Yr[i])\n",
    "            Xrs = np.append(Xrs, Xrr, axis=0)\n",
    "            Yrs = np.append(Yrs, Yrr, axis=0)\n",
    "\n",
    "        Xrs_shuf = []\n",
    "        Yrs_shuf = []\n",
    "        index_shuf = list(range(len(Xrs)))\n",
    "        np.random.shuffle(index_shuf)\n",
    "        for i in index_shuf:\n",
    "            Xrs_shuf.append(Xrs[i])\n",
    "            Yrs_shuf.append(Yrs[i])\n",
    "\n",
    "        return Xrs_shuf, Yrs_shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 2:\n",
    "    X_train, Y_train = imag_rotation_aug(imgs_train, gt_imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 2:\n",
    "    X_val, Y_val = imag_rotation_aug(imgs_val, gt_imgs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating mini-batch and running data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 2:\n",
    "\n",
    "    def create_minibatch(X, Y, n):\n",
    "\n",
    "        # Fix the seed\n",
    "        # np.random.seed(1)\n",
    "\n",
    "        # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "        # and patch size should correspond to 16\n",
    "        w_size = 64\n",
    "        batch_size = 100\n",
    "        patch_size = 16\n",
    "        num_images = n\n",
    "\n",
    "        while True:\n",
    "            # Generate one minibatch\n",
    "            batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "            batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "            for i in range(batch_size):\n",
    "\n",
    "                # Select a random index representing an image\n",
    "                random_index = np.random.choice(num_images)\n",
    "\n",
    "                # Width of original image\n",
    "                width = 400\n",
    "\n",
    "                # Sample a random window from the image\n",
    "                random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "                # Create a sub image of size 72x72\n",
    "                sampled_image = X[random_index][\n",
    "                    random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                    random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "                ]\n",
    "\n",
    "                # Take its corresponding ground-truth image\n",
    "                correspond_ground_truth = Y[random_index][\n",
    "                    random_sample[0]\n",
    "                    - patch_size // 2 : random_sample[0]\n",
    "                    + patch_size // 2,\n",
    "                    random_sample[1]\n",
    "                    - patch_size // 2 : random_sample[1]\n",
    "                    + patch_size // 2,\n",
    "                ]\n",
    "\n",
    "                # We set in the label depending on the threshold of 0.25\n",
    "                # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "                label = to_categorical(\n",
    "                    (np.array([np.mean(correspond_ground_truth)]) > 0.25) * 1, 2\n",
    "                )\n",
    "\n",
    "                # We put in the sub image and its corresponding label before yielding it\n",
    "                batch_image[i] = sampled_image\n",
    "                batch_label[i] = label\n",
    "\n",
    "            # Yield the mini_batch to the model\n",
    "            yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 1:\n",
    "\n",
    "    def create_minibatch(X, Y, n, batch_size=100):\n",
    "\n",
    "        # Fix the seed\n",
    "        np.random.seed(1)\n",
    "\n",
    "        # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "        # and patch size should correspond to 16\n",
    "        w_size = 64\n",
    "        batch_size = batch_size\n",
    "        patch_size = 16\n",
    "        num_images = n\n",
    "\n",
    "        while True:\n",
    "            # Generate one minibatch\n",
    "            batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "            batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "            for i in range(batch_size):\n",
    "\n",
    "                # Select a random index represnting an image\n",
    "                random_index = np.random.choice(num_images)\n",
    "\n",
    "                # Width of original image\n",
    "                width = 400\n",
    "\n",
    "                # Sample a random window from the image\n",
    "                random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "                # Create a sub image of size 72x72\n",
    "                sampled_image = X[random_index][\n",
    "                    random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                    random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "                ]\n",
    "\n",
    "                # Take its corresponding ground-truth image\n",
    "                correspond_ground_truth = Y[random_index][\n",
    "                    random_sample[0]\n",
    "                    - patch_size // 2 : random_sample[0]\n",
    "                    + patch_size // 2,\n",
    "                    random_sample[1]\n",
    "                    - patch_size // 2 : random_sample[1]\n",
    "                    + patch_size // 2,\n",
    "                ]\n",
    "\n",
    "                # We set in the label depending on the threshold of 0.25\n",
    "                # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "                label = to_categorical(\n",
    "                    (np.array([np.mean(correspond_ground_truth)]) > 0.25) * 1, 2\n",
    "                )\n",
    "\n",
    "                # The image augmentation is based on both flipping and rotating (randomly in steps of 45°)\n",
    "                # Random vertical and horizontal flip\n",
    "                if np.random.choice(2) == 1:\n",
    "                    sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "                if np.random.choice(2) == 1:\n",
    "                    sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "                # Random rotation in steps of 45°\n",
    "                rotations = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "                # We select a rotation degree randomly\n",
    "                rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "                # Rotate it using the random value (uses the scipy library)\n",
    "                sampled_image = scipy.ndimage.rotate(\n",
    "                    sampled_image,\n",
    "                    rotations[rotation_choice],\n",
    "                    order=1,\n",
    "                    reshape=False,\n",
    "                    mode=\"reflect\",\n",
    "                )\n",
    "\n",
    "                # We put in the sub image and its corresponding label before yielding it\n",
    "                batch_image[i] = sampled_image\n",
    "                batch_label[i] = label\n",
    "\n",
    "            # Yield the mini_batch to the model\n",
    "            yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * ((prec * rec) / (prec + rec + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet-Unet model Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best:\n",
    "\n",
    "    class resnet_unet_model:\n",
    "\n",
    "        # Initialize the class\n",
    "        def __init__(\n",
    "            self,\n",
    "            shape,\n",
    "            batch_normalization,\n",
    "            activation,\n",
    "            dropout,\n",
    "            amsgrad=False,\n",
    "            lr=1e-4,\n",
    "            noise=0.0,\n",
    "        ):\n",
    "            self.shape = shape\n",
    "            self.batch_normalization = batch_normalization\n",
    "            self.activation = activation\n",
    "            self.dropout = dropout\n",
    "            self.amsgrad = amsgrad\n",
    "            self.lr = lr\n",
    "            self.noise = noise\n",
    "            self.model = self.initialize_resnet_unet_model()\n",
    "\n",
    "        def conv_act(self, inputs, out_filters, activation=\"relu\"):\n",
    "            return Conv2D(\n",
    "                filters=out_filters,\n",
    "                activation=activation,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "            )(inputs)\n",
    "\n",
    "        def decoder(\n",
    "            self,\n",
    "            inputs,\n",
    "            mid_filters=512,\n",
    "            out_filters=256,\n",
    "            activation=\"relu\",\n",
    "            block_name=\"decoder\",\n",
    "        ):\n",
    "            with K.name_scope(block_name):\n",
    "                if activation == \"leaky_relu\":\n",
    "                    activation = None\n",
    "                    conv = LeakyReLU(alpha=0.3)(\n",
    "                        self.conv_act(inputs, mid_filters, activation)\n",
    "                    )\n",
    "                else:\n",
    "                    conv = self.conv_act(inputs, mid_filters, activation)\n",
    "                conv_tr = Conv2DTranspose(\n",
    "                    filters=out_filters,\n",
    "                    activation=activation,\n",
    "                    kernel_size=4,\n",
    "                    strides=2,\n",
    "                    padding=\"same\",\n",
    "                )(conv)\n",
    "            return conv_tr\n",
    "\n",
    "        def initialize_resnet_unet_model(self):\n",
    "            #         print(activation)\n",
    "\n",
    "            # INPUT\n",
    "            # shape     - Size of the input images\n",
    "            # OUTPUT\n",
    "            # model    - Compiled CNN\n",
    "\n",
    "            # Define parameters\n",
    "            max_pooling_size = 2\n",
    "            max_pooling_strd = 2\n",
    "\n",
    "            # Load a pretrained ResNet\n",
    "            num_classes = 2\n",
    "            resnet50 = ResNet50(\n",
    "                include_top=False,\n",
    "                weights=\"imagenet\",\n",
    "                classes=num_classes,\n",
    "                input_shape=self.shape,\n",
    "            )\n",
    "            resnet50.compile(\n",
    "                optimizer=Adam(lr=self.lr, amsgrad=self.amsgrad),\n",
    "                loss=\"binary_crossentropy\",\n",
    "            )\n",
    "\n",
    "            # ResNet convolution outputs\n",
    "            conv5_out = resnet50.get_layer(\"conv5_block3_out\").output\n",
    "            conv4_out = resnet50.get_layer(\"conv4_block6_out\").output\n",
    "            conv3_out = resnet50.get_layer(\"conv3_block4_out\").output\n",
    "            conv2_out = resnet50.get_layer(\"conv2_block3_out\").output\n",
    "\n",
    "            pool = MaxPooling2D(\n",
    "                max_pooling_size, strides=max_pooling_strd, padding=\"same\"\n",
    "            )(resnet50.get_output_at(0))\n",
    "            dec_center = self.decoder(\n",
    "                pool,\n",
    "                mid_filters=self.shape[0] * 2,\n",
    "                out_filters=self.shape[0],\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder_center\",\n",
    "            )\n",
    "\n",
    "            if self.batch_normalization:\n",
    "                dec_center = BatchNormalization()(dec_center)\n",
    "            if self.dropout > 0:\n",
    "                dec_center = Dropout(dropout)(dec_center)\n",
    "\n",
    "            cat1 = Concatenate()([dec_center, conv5_out])\n",
    "            dec5 = self.decoder(\n",
    "                cat1,\n",
    "                mid_filters=int(self.shape[0] * 2),\n",
    "                out_filters=int(self.shape[0]),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder5\",\n",
    "            )\n",
    "            if self.batch_normalization:\n",
    "                dec5 = BatchNormalization()(dec5)\n",
    "            if self.dropout > 0:\n",
    "                dec5 = Dropout(self.dropout)(dec5)\n",
    "\n",
    "            cat2 = Concatenate()([dec5, conv4_out])\n",
    "            dec4 = self.decoder(\n",
    "                cat2,\n",
    "                mid_filters=int(self.shape[0] * 2),\n",
    "                out_filters=int(self.shape[0]),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder4\",\n",
    "            )\n",
    "            if self.batch_normalization:\n",
    "                dec4 = BatchNormalization()(dec4)\n",
    "            if self.dropout > 0:\n",
    "                dec4 = Dropout(self.dropout)(dec4)\n",
    "\n",
    "            cat3 = Concatenate()([dec4, conv3_out])\n",
    "            dec3 = self.decoder(\n",
    "                cat3,\n",
    "                mid_filters=int(self.shape[0]),\n",
    "                out_filters=int(self.shape[0] // 4),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder3\",\n",
    "            )\n",
    "            if self.batch_normalization:\n",
    "                dec3 = BatchNormalization()(dec3)\n",
    "            if self.dropout > 0:\n",
    "                dec3 = Dropout(self.dropout)(dec3)\n",
    "\n",
    "            cat2 = Concatenate()([dec3, conv2_out])\n",
    "            dec2 = self.decoder(\n",
    "                cat2,\n",
    "                mid_filters=int(self.shape[0] // 2),\n",
    "                out_filters=int(self.shape[0] // 2),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder2\",\n",
    "            )\n",
    "            if self.batch_normalization:\n",
    "                dec2 = BatchNormalization()(dec2)\n",
    "            if dropout > 0:\n",
    "                dec2 = Dropout(self.dropout)(dec2)\n",
    "\n",
    "            dec1 = self.decoder(\n",
    "                dec2,\n",
    "                mid_filters=int(self.shape[0] // 2),\n",
    "                out_filters=int(self.shape[0] // 8),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder1\",\n",
    "            )\n",
    "            if self.batch_normalization:\n",
    "                dec1 = BatchNormalization()(dec1)\n",
    "            if self.dropout > 0:\n",
    "                dec1 = Dropout(self.dropout)(dec1)\n",
    "\n",
    "            dec0 = self.conv_act(dec1, out_filters=int(self.shape[0] // 8))\n",
    "            conv_f = Conv2D(1, 1, activation=\"sigmoid\", padding=\"same\")(dec0)\n",
    "            flatten_0 = Flatten()(conv_f)\n",
    "            dense_0 = Dense(\n",
    "                self.shape[0] / 2,\n",
    "                kernel_regularizer=l2(1e-6),\n",
    "                activity_regularizer=l2(1e-6),\n",
    "            )(flatten_0)\n",
    "            dropout_0 = Dropout(0.5)(dense_0)\n",
    "            lk_relu_0 = LeakyReLU(alpha=0.1)(dropout_0)\n",
    "            dense_1 = Dense(\n",
    "                2, kernel_regularizer=l2(1e-6), activity_regularizer=l2(1e-6)\n",
    "            )(lk_relu_0)\n",
    "            dropout_1 = Dropout(0.2)(dense_1)\n",
    "            output = Activation(\"sigmoid\")(dropout_1)\n",
    "            model = Model(inputs=resnet50.get_input_at(0), outputs=output)\n",
    "\n",
    "            #           Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "            #           We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "            model.compile(\n",
    "                loss=\"binary_crossentropy\",\n",
    "                optimizer=Adam(lr=lr, amsgrad=self.amsgrad),\n",
    "                metrics=[\"accuracy\", recall, f1],\n",
    "            )\n",
    "\n",
    "            # Print a summary of the model to see what has been generated\n",
    "            model.summary()\n",
    "\n",
    "            return model\n",
    "\n",
    "        def train(\n",
    "            self,\n",
    "            epochs,\n",
    "            steps_per_epoch,\n",
    "            n_train=85,\n",
    "            n_val=15,\n",
    "            batch_size=100,\n",
    "            data_aug_factor=1,\n",
    "        ):\n",
    "\n",
    "            # Early stopping callback after 10 steps\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", min_delta=0, patience=10, verbose=1, mode=\"auto\"\n",
    "            )\n",
    "\n",
    "            # Reduce learning rate on plateau after 4 steps\n",
    "            lr_callback = ReduceLROnPlateau(\n",
    "                monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "            )\n",
    "\n",
    "            # Save best model\n",
    "            weights_filename = \"model_\"\n",
    "            if self.batch_normalization:\n",
    "                weights_filename = weights_filename + \"batch_\"\n",
    "            weights_filename = (\n",
    "                weights_filename\n",
    "                + self.activation\n",
    "                + \"_\"\n",
    "                + str(epochs)\n",
    "                + \"_\"\n",
    "                + \"dropout_\"\n",
    "                + str(self.dropout)\n",
    "                + \"_\"\n",
    "                + \"{epoch:03d}_\"\n",
    "                + \"{f1:03f}_\"\n",
    "                + \"{val_accuracy:03f}.h5\"\n",
    "            )\n",
    "            save_best = ModelCheckpoint(\n",
    "                weights_filename,\n",
    "                save_best_only=True,\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"auto\",\n",
    "                verbose=1,\n",
    "            )\n",
    "\n",
    "            # Place the callbacks in a list to be used when training\n",
    "            #         callbacks = [cb, early_stopping, lr_callback]\n",
    "            callbacks = [save_best, lr_callback]\n",
    "\n",
    "            # Train the model using the previously defined functions and callbacks\n",
    "            history = self.model.fit_generator(\n",
    "                create_minibatch(\n",
    "                    X_train, Y_train, data_aug_factor * n_train, batch_size=batch_size\n",
    "                ),\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=epochs,\n",
    "                use_multiprocessing=False,\n",
    "                workers=1,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1,\n",
    "                validation_data=create_minibatch(\n",
    "                    X_val, Y_val, data_aug_factor * n_val, batch_size=batch_size\n",
    "                ),\n",
    "                validation_steps=steps_per_epoch,\n",
    "            )\n",
    "\n",
    "            return history\n",
    "\n",
    "        def classify(self, X):\n",
    "            # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "            img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "            # Predict\n",
    "            predictions = self.model.predict(img_patches)\n",
    "            predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "            # Regroup patches into images\n",
    "            #         return group_patches(predictions, X.self.shape[0])\n",
    "            return group_patches(predictions, X.shape[0])\n",
    "\n",
    "        def load(self, filename):\n",
    "            # Load the model (used for submission)\n",
    "            dependencies = {\"recall\": recall, \"f1\": f1}\n",
    "            self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "        def save(self, filename):\n",
    "            # Save the model (used to then load to submit)\n",
    "            self.model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet-Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not baseline:\n",
    "if not best:\n",
    "\n",
    "    class resnet_unet_model:\n",
    "\n",
    "        # Initialize the class\n",
    "        def __init__(\n",
    "            self,\n",
    "            shape,\n",
    "            batch_normalization,\n",
    "            activation,\n",
    "            dropout,\n",
    "            amsgrad=False,\n",
    "            lr=1e-4,\n",
    "            noise=0.0,\n",
    "        ):\n",
    "            self.shape = shape\n",
    "            self.batch_normalization = batch_normalization\n",
    "            self.activation = activation\n",
    "            self.dropout = dropout\n",
    "            self.amsgrad = amsgrad\n",
    "            self.lr = lr\n",
    "            self.noise = noise\n",
    "            self.model = self.initialize_resnet_unet_model()\n",
    "\n",
    "        def conv_act(\n",
    "            self, inputs, out_filters, activation=\"relu\", batch_normalization=False\n",
    "        ):\n",
    "            conv = Conv2D(\n",
    "                filters=out_filters, kernel_size=3, strides=1, padding=\"same\"\n",
    "            )(inputs)\n",
    "            if batch_normalization:\n",
    "                conv = BatchNormalization()(conv)\n",
    "            return Activation(activation)(conv)\n",
    "\n",
    "        def decoder(\n",
    "            self,\n",
    "            inputs,\n",
    "            mid_filters=512,\n",
    "            out_filters=256,\n",
    "            activation=\"relu\",\n",
    "            block_name=\"decoder\",\n",
    "            batch_normalization=False,\n",
    "        ):\n",
    "            with K.name_scope(block_name):\n",
    "                if activation == \"leaky_relu\":\n",
    "                    activation = None\n",
    "                    conv = LeakyReLU(alpha=0.3)(\n",
    "                        self.conv_act(\n",
    "                            inputs, mid_filters, activation, batch_normalization\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    conv = self.conv_act(\n",
    "                        inputs, mid_filters, activation, batch_normalization\n",
    "                    )\n",
    "                conv_tr = Conv2DTranspose(\n",
    "                    filters=out_filters,\n",
    "                    activation=None,\n",
    "                    kernel_size=4,\n",
    "                    strides=2,\n",
    "                    padding=\"same\",\n",
    "                )(conv)\n",
    "                if batch_normalization:\n",
    "                    conv_tr = BatchNormalization()(conv_tr)\n",
    "                conv_tr_act = Activation(activation)(conv_tr)\n",
    "            return conv_tr_act\n",
    "\n",
    "        def initialize_resnet_unet_model(self):\n",
    "            #         print(activation)\n",
    "\n",
    "            # INPUT\n",
    "            # shape     - Size of the input images\n",
    "            # OUTPUT\n",
    "            # model    - Compiled CNN\n",
    "\n",
    "            # Define parameters\n",
    "            max_pooling_size = 2\n",
    "            max_pooling_strd = 2\n",
    "\n",
    "            # Load a pretrained ResNet\n",
    "            num_classes = 2\n",
    "            resnet50 = ResNet50(\n",
    "                include_top=False,\n",
    "                weights=\"imagenet\",\n",
    "                classes=num_classes,\n",
    "                input_shape=self.shape,\n",
    "            )\n",
    "            resnet50.compile(\n",
    "                optimizer=Adam(lr=self.lr, amsgrad=self.amsgrad),\n",
    "                loss=\"binary_crossentropy\",\n",
    "            )\n",
    "\n",
    "            # ResNet convolution outputs\n",
    "            conv5_out = resnet50.get_layer(\"conv5_block3_out\").output\n",
    "            conv4_out = resnet50.get_layer(\"conv4_block6_out\").output\n",
    "            conv3_out = resnet50.get_layer(\"conv3_block4_out\").output\n",
    "            conv2_out = resnet50.get_layer(\"conv2_block3_out\").output\n",
    "\n",
    "            pool = MaxPooling2D(\n",
    "                max_pooling_size, strides=max_pooling_strd, padding=\"same\"\n",
    "            )(resnet50.get_output_at(0))\n",
    "            dec_center = self.decoder(\n",
    "                pool,\n",
    "                mid_filters=self.shape[0] * 2,\n",
    "                out_filters=self.shape[0],\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder_center\",\n",
    "            )\n",
    "\n",
    "            if self.dropout > 0:\n",
    "                dec_center = Dropout(dropout)(dec_center)\n",
    "\n",
    "            cat1 = Concatenate()([dec_center, conv5_out])\n",
    "            dec5 = self.decoder(\n",
    "                cat1,\n",
    "                mid_filters=int(self.shape[0] * 2),\n",
    "                out_filters=int(self.shape[0]),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder5\",\n",
    "            )\n",
    "\n",
    "            if self.dropout > 0:\n",
    "                dec5 = Dropout(self.dropout)(dec5)\n",
    "\n",
    "            cat2 = Concatenate()([dec5, conv4_out])\n",
    "            dec4 = self.decoder(\n",
    "                cat2,\n",
    "                mid_filters=int(self.shape[0] * 2),\n",
    "                out_filters=int(self.shape[0]),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder4\",\n",
    "            )\n",
    "\n",
    "            if self.dropout > 0:\n",
    "                dec4 = Dropout(self.dropout)(dec4)\n",
    "\n",
    "            cat3 = Concatenate()([dec4, conv3_out])\n",
    "            dec3 = self.decoder(\n",
    "                cat3,\n",
    "                mid_filters=int(self.shape[0]),\n",
    "                out_filters=int(self.shape[0] // 4),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder3\",\n",
    "            )\n",
    "\n",
    "            if self.dropout > 0:\n",
    "                dec3 = Dropout(self.dropout)(dec3)\n",
    "\n",
    "            cat2 = Concatenate()([dec3, conv2_out])\n",
    "            dec2 = self.decoder(\n",
    "                cat2,\n",
    "                mid_filters=int(self.shape[0] // 2),\n",
    "                out_filters=int(self.shape[0] // 2),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder2\",\n",
    "            )\n",
    "\n",
    "            if dropout > 0:\n",
    "                dec2 = Dropout(self.dropout)(dec2)\n",
    "\n",
    "            dec1 = self.decoder(\n",
    "                dec2,\n",
    "                mid_filters=int(self.shape[0] // 2),\n",
    "                out_filters=int(self.shape[0] // 8),\n",
    "                activation=self.activation,\n",
    "                block_name=\"decoder1\",\n",
    "            )\n",
    "\n",
    "            if self.dropout > 0:\n",
    "                dec1 = Dropout(self.dropout)(dec1)\n",
    "\n",
    "            dec0 = self.conv_act(dec1, out_filters=int(self.shape[0] // 8))\n",
    "            conv_f = Conv2D(1, 1, activation=\"sigmoid\", padding=\"same\")(dec0)\n",
    "            flatten_0 = Flatten()(conv_f)\n",
    "            dense_0 = Dense(\n",
    "                self.shape[0] / 2,\n",
    "                kernel_regularizer=l2(1e-6),\n",
    "                activity_regularizer=l2(1e-6),\n",
    "            )(flatten_0)\n",
    "            dropout_0 = Dropout(0.5)(dense_0)\n",
    "            lk_relu_0 = LeakyReLU(alpha=0.1)(dropout_0)\n",
    "            dense_1 = Dense(\n",
    "                2, kernel_regularizer=l2(1e-6), activity_regularizer=l2(1e-6)\n",
    "            )(lk_relu_0)\n",
    "            dropout_1 = Dropout(0.5)(dense_1)\n",
    "            output = Activation(\"sigmoid\")(dropout_1)\n",
    "            model = Model(inputs=resnet50.get_input_at(0), outputs=output)\n",
    "\n",
    "            # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "            # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "            #             model.compile(\n",
    "            #                 loss=\"binary_crossentropy\",\n",
    "            #                 optimizer=Adam(lr=lr, amsgrad=self.amsgrad),\n",
    "            #                 metrics=[\"accuracy\", recall, f1],\n",
    "            #             )\n",
    "            model.compile(\n",
    "                loss=\"binary_crossentropy\",\n",
    "                optimizer=Adam(lr=self.lr, amsgrad=self.amsgrad),\n",
    "                metrics=[\"accuracy\", recall, f1],\n",
    "            )\n",
    "            # Print a summary of the model to see what has been generated\n",
    "            model.summary()\n",
    "\n",
    "            return model\n",
    "\n",
    "        def train(\n",
    "            self,\n",
    "            epochs,\n",
    "            steps_per_epoch,\n",
    "            n_train=85,\n",
    "            n_val=15,\n",
    "            batch_size=100,\n",
    "            data_aug_factor=1,\n",
    "        ):\n",
    "\n",
    "            # Early stopping callback after 10 steps\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", min_delta=0, patience=10, verbose=1, mode=\"auto\"\n",
    "            )\n",
    "\n",
    "            # Reduce learning rate on plateau after 4 steps\n",
    "            lr_callback = ReduceLROnPlateau(\n",
    "                monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "            )\n",
    "\n",
    "            # Save best model\n",
    "            weights_filename = \"model_\"\n",
    "            if self.batch_normalization:\n",
    "                weights_filename = weights_filename + \"batch_\"\n",
    "            weights_filename = (\n",
    "                weights_filename\n",
    "                + self.activation\n",
    "                + \"_\"\n",
    "                + str(epochs)\n",
    "                + \"_\"\n",
    "                + \"dropout_\"\n",
    "                + str(self.dropout)\n",
    "                + \"_\"\n",
    "                + \"{epoch:03d}_\"\n",
    "                + \"{f1:03f}_\"\n",
    "                + \"{val_accuracy:03f}.h5\"\n",
    "            )\n",
    "            save_best = ModelCheckpoint(\n",
    "                weights_filename,\n",
    "                save_best_only=True,\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"auto\",\n",
    "                verbose=1,\n",
    "            )\n",
    "\n",
    "            # Place the callbacks in a list to be used when training\n",
    "            #         callbacks = [cb, early_stopping, lr_callback]\n",
    "            callbacks = [save_best, lr_callback]\n",
    "\n",
    "            # Train the model using the previously defined functions and callbacks\n",
    "            history = self.model.fit_generator(\n",
    "                create_minibatch(\n",
    "                    X_train, Y_train, data_aug_factor * n_train, batch_size=batch_size\n",
    "                ),\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=epochs,\n",
    "                use_multiprocessing=False,\n",
    "                workers=1,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1,\n",
    "                validation_data=create_minibatch(\n",
    "                    X_val, Y_val, data_aug_factor * n_val, batch_size=batch_size\n",
    "                ),\n",
    "                validation_steps=int(steps_per_epoch / 4),\n",
    "            )\n",
    "\n",
    "            return history\n",
    "\n",
    "        def classify(self, X):\n",
    "            # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "            img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "            # Predict\n",
    "            predictions = self.model.predict(img_patches)\n",
    "            predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "            # Predict\n",
    "            predictions = self.model.predict(img_patches)\n",
    "            predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "            # Regroup patches into images\n",
    "            return predictions.reshape(X.shape[0], -1)\n",
    "\n",
    "        def load(self, filename):\n",
    "            # Load the model (used for submission)\n",
    "            dependencies = {\"recall\": recall, \"f1\": f1}\n",
    "            self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "        def save(self, filename):\n",
    "            # Save the model (used to then load to submit)\n",
    "            self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not baseline:\n",
    "if best:\n",
    "    batch_normalization = True\n",
    "    activation = \"relu\"\n",
    "    dropout = 0\n",
    "    amsgrad = False\n",
    "    lr = 1e-4\n",
    "    noise = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not baseline:\n",
    "if best:\n",
    "    EPOCHS = 80\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    batch_size = 100\n",
    "\n",
    "    model = resnet_unet_model(\n",
    "        shape=(64, 64, 3),\n",
    "        batch_normalization=batch_normalization,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        amsgrad=amsgrad,\n",
    "        lr=lr,\n",
    "        noise=noise,\n",
    "    )\n",
    "    # Train the model\n",
    "    history = model.train(\n",
    "        EPOCHS, STEPS_PER_EPOCH, n_train, n_val, batch_size, data_aug_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/trainHistoryDict_best_model', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not best:\n",
    "    now_str = str(datetime.now()).replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "    if batch_normalization:\n",
    "        specific_name = now_str + \"_batchnorm\" + \"_dropout{:2.2f}\".format(dropout)\n",
    "    else:\n",
    "        specific_name = now_str + \"_dropout{:2.2f}\".format(dropout)\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history.history[\"f1\"])\n",
    "    plt.plot(history.history[\"val_f1\"])\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"ResNet-UNet: training vs validation f1 and loss\")\n",
    "    plt.ylabel(\"value\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(\n",
    "        [\"train_f1\", \"val_f1\", \"loss\", \"val_loss\"],\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.0, -0.07),\n",
    "        ncol=4,\n",
    "        borderaxespad=0,\n",
    "        frameon=False,\n",
    "    )\n",
    "    plt.savefig(specific_name + \"_resnet_unet_metrics_f1.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best:\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history.history[\"loss\"][1:], label=\"train_loss\")\n",
    "    plt.plot(history.history[\"val_loss\"][1:], label=\"val_loss\")\n",
    "    plt.plot(history.history[\"accuracy\"][1:], label=\"train_acc\")\n",
    "    plt.plot(history.history[\"val_accuracy\"][1:], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"Unet_batchnorm.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best:\n",
    "    from helpers import *\n",
    "\n",
    "    # from resnet_unet_model import resnet_unet_model\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = resnet_unet_model(\n",
    "        shape=(64, 64, 3),\n",
    "        batch_normalization=batch_normalization,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        amsgrad=amsgrad,\n",
    "        lr=lr,\n",
    "    )\n",
    "\n",
    "    # Load the model\n",
    "    model.load(\"model_batch_relu_80_dropout_0_052_0.849586_0.933300.h5\")\n",
    "\n",
    "    # Print a summary to make sure the correct model is used\n",
    "    model.model.summary()\n",
    "\n",
    "    # We add all test images to an array, used later for generating a submission\n",
    "    image_filenames = []\n",
    "    for i in range(1, 51):\n",
    "        image_filename = (\n",
    "            \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "        )\n",
    "        image_filenames.append(image_filename)\n",
    "\n",
    "    # Set-up submission filename\n",
    "    submission_filename = \"resnet_unet.csv\"\n",
    "    # Generates the submission\n",
    "    generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
