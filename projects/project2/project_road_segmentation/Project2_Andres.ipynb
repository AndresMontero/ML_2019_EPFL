{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7107854718093345343\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4937233203\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16004987595414529313\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "    \n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.image as mpimg\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os,sys\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper functions\n",
    "\n",
    "# def load_image(infilename):\n",
    "#     data = mpimg.imread(infilename)\n",
    "#     return data\n",
    "\n",
    "# def img_float_to_uint8(img):\n",
    "#     rimg = img - np.min(img)\n",
    "#     rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "#     return rimg\n",
    "\n",
    "# # Concatenate an image and its groundtruth\n",
    "# def concatenate_images(img, gt_img):\n",
    "#     nChannels = len(gt_img.shape)\n",
    "#     w = gt_img.shape[0]\n",
    "#     h = gt_img.shape[1]\n",
    "#     if nChannels == 3:\n",
    "#         cimg = np.concatenate((img, gt_img), axis=1)\n",
    "#     else:\n",
    "#         gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "#         gt_img8 = img_float_to_uint8(gt_img)          \n",
    "#         gt_img_3c[:,:,0] = gt_img8\n",
    "#         gt_img_3c[:,:,1] = gt_img8\n",
    "#         gt_img_3c[:,:,2] = gt_img8\n",
    "#         img8 = img_float_to_uint8(img)\n",
    "#         cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "#     return cimg\n",
    "\n",
    "# def img_crop(im, w, h):\n",
    "#     list_patches = []\n",
    "#     imgwidth = im.shape[0]\n",
    "#     imgheight = im.shape[1]\n",
    "#     is_2d = len(im.shape) < 3\n",
    "#     for i in range(0,imgheight,h):\n",
    "#         for j in range(0,imgwidth,w):\n",
    "#             if is_2d:\n",
    "#                 im_patch = im[j:j+w, i:i+h]\n",
    "#             else:\n",
    "#                 im_patch = im[j:j+w, i:i+h, :]\n",
    "#             list_patches.append(im_patch)\n",
    "#     return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loaded a set of images\n",
    "# root_dir = \"data/training/\"\n",
    "\n",
    "# image_dir = root_dir + \"images/\"\n",
    "# files = os.listdir(image_dir)\n",
    "# n = min(20, len(files)) # Load maximum 20 images\n",
    "# print(\"Loading \" + str(n) + \" images\")\n",
    "# imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "# print(files[0])\n",
    "\n",
    "# gt_dir = root_dir + \"groundtruth/\"\n",
    "# print(\"Loading \" + str(n) + \" images\")\n",
    "# gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "# print(files[0])\n",
    "\n",
    "# n = 10 # Only use 10 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Image size = ' + str(imgs[0].shape[0]) + ',' + str(imgs[0].shape[1]))\n",
    "\n",
    "# # Show first image and its groundtruth image\n",
    "# cimg = concatenate_images(imgs[0], gt_imgs[0])\n",
    "# fig1 = plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(cimg, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract patches from input images\n",
    "# patch_size = 16 # each patch is 16*16 pixels\n",
    "\n",
    "# img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "# gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# # Linearize list of patches\n",
    "# img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "# gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract 6-dimensional features consisting of average RGB color as well as variance\n",
    "# def extract_features(img):\n",
    "#     feat_m = np.mean(img, axis=(0,1))\n",
    "#     feat_v = np.var(img, axis=(0,1))\n",
    "#     feat = np.append(feat_m, feat_v)\n",
    "#     return feat\n",
    "\n",
    "# # Extract 2-dimensional features consisting of average gray color as well as variance\n",
    "# def extract_features_2d(img):\n",
    "#     feat_m = np.mean(img)\n",
    "#     feat_v = np.var(img)\n",
    "#     feat = np.append(feat_m, feat_v)\n",
    "#     return feat\n",
    "\n",
    "# # Extract features for a given image\n",
    "# def extract_img_features(filename):\n",
    "#     img = load_image(filename)\n",
    "#     img_patches = img_crop(img, patch_size, patch_size)\n",
    "#     X = np.asarray([ extract_features_2d(img_patches[i]) for i in range(len(img_patches))])\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute features for each image patch\n",
    "# foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# def value_to_class(v):\n",
    "#     df = np.sum(v)\n",
    "#     if df > foreground_threshold:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# X = np.asarray([ extract_features_2d(img_patches[i]) for i in range(len(img_patches))])\n",
    "# Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print feature statistics\n",
    "\n",
    "# print('Computed ' + str(X.shape[0]) + ' features')\n",
    "# print('Feature dimension = ' + str(X.shape[1]))\n",
    "# print('Number of classes = ' + str(np.max(Y)))  #TODO: fix, length(unique(Y)) \n",
    "\n",
    "# Y0 = [i for i, j in enumerate(Y) if j == 0]\n",
    "# Y1 = [i for i, j in enumerate(Y) if j == 1]\n",
    "# print('Class 0: ' + str(len(Y0)) + ' samples')\n",
    "# print('Class 1: ' + str(len(Y1)) + ' samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display a patch that belongs to the foreground class\n",
    "# plt.imshow(gt_patches[Y1[3]], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot 2d features using groundtruth to color the datapoints\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train a logistic regression classifier\n",
    "\n",
    "# from sklearn import linear_model\n",
    "\n",
    "# # we create an instance of the classifier and fit the data\n",
    "# logreg = linear_model.LogisticRegression(C=1e5, class_weight=\"balanced\")\n",
    "# logreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the training set\n",
    "# Z = logreg.predict(X)\n",
    "\n",
    "# # Get non-zeros in prediction and grountruth arrays\n",
    "# Zn = np.nonzero(Z)[0]\n",
    "# Yn = np.nonzero(Y)[0]\n",
    "\n",
    "# TPR = len(list(set(Yn) & set(Zn))) / float(len(Z))\n",
    "# print('True positive rate = ' + str(TPR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot features using predictions to color datapoints\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=Z, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert array of labels to an image\n",
    "\n",
    "# def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "#     im = np.zeros([imgwidth, imgheight])\n",
    "#     idx = 0\n",
    "#     for i in range(0,imgheight,h):\n",
    "#         for j in range(0,imgwidth,w):\n",
    "#             im[j:j+w, i:i+h] = labels[idx]\n",
    "#             idx = idx + 1\n",
    "#     return im\n",
    "\n",
    "# def make_img_overlay(img, predicted_img):\n",
    "#     w = img.shape[0]\n",
    "#     h = img.shape[1]\n",
    "#     color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "#     color_mask[:,:,0] = predicted_img*255\n",
    "\n",
    "#     img8 = img_float_to_uint8(img)\n",
    "#     background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "#     overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "#     new_img = Image.blend(background, overlay, 0.2)\n",
    "#     return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run prediction on the img_idx-th image\n",
    "# img_idx = 12\n",
    "\n",
    "# Xi = extract_img_features(image_dir + files[img_idx])\n",
    "# Zi = logreg.predict(Xi)\n",
    "# plt.scatter(Xi[:, 0], Xi[:, 1], c=Zi, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display prediction as an image\n",
    "\n",
    "# w = gt_imgs[img_idx].shape[0]\n",
    "# h = gt_imgs[img_idx].shape[1]\n",
    "# predicted_im = label_to_img(w, h, patch_size, patch_size, Zi)\n",
    "# cimg = concatenate_images(imgs[img_idx], predicted_im)\n",
    "# fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "# plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "# new_img = make_img_overlay(imgs[img_idx], predicted_im)\n",
    "\n",
    "# plt.imshow(new_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #threshold function is disabled when resizing input images\n",
    "# path = \"data/training/groundtruth/satImage_\"\n",
    "# dim = (256, 256) #(w,h)\n",
    "\n",
    "# for i in range(1,101):\n",
    "#     if i < 10: \n",
    "#         image = cv2.imread(path + \"00\" + str(i) + \".png\", 0)\n",
    "#     elif i>=10 and i<100:\n",
    "#         image = cv2.imread(path + \"0\" + str(i) + \".png\", 0)\n",
    "#     else:\n",
    "#         image = cv2.imread(path + str(i) + \".png\", 0)\n",
    "        \n",
    "        \n",
    "#     resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "#     (thresh, im_bw) = cv2.threshold(resized, 128, 255, cv2.THRESH_BINARY)\n",
    "#     cv2.imwrite('mask_train/' + str(i) + '.png', im_bw)\n",
    "# #     print('mask_train/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"data/training/images/satImage_\"\n",
    "# dim = (256, 256) #(w,h)\n",
    "\n",
    "# for i in range(1,101):\n",
    "#     if i < 10: \n",
    "#         image = cv2.imread(path + \"00\" + str(i) + \".png\")\n",
    "#     elif i>=10 and i<100:\n",
    "#         image = cv2.imread(path + \"0\" + str(i) + \".png\")\n",
    "#     else:\n",
    "#         image = cv2.imread(path + str(i) + \".png\")\n",
    "        \n",
    "#     img = cv2.resize(image,dim,interpolation=cv2.INTER_AREA)\n",
    "#     cv2.imwrite('images_train/' + str(i) + '.png', img)\n",
    "\n",
    "# #     print('images_train/' + str(i) + '.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# masks = []\n",
    "# for i in range(1, 101):\n",
    "#     if i < 10: \n",
    "#         img = Image.open(\"data/training/images/satImage_\" + \"00\" + str(i) + \".png\")\n",
    "#     elif i>=10 and i<100:\n",
    "#         img = Image.open(\"data/training/images/satImage_\" + \"0\" + str(i) + \".png\")\n",
    "#     else:\n",
    "#         img = Image.open(\"data/training/images/satImage_\"  + str(i) + \".png\")\n",
    "\n",
    "#     print('Original Dimensions : ',image.shape)\n",
    "#     arr = np.array(img)\n",
    "#     images.append(arr)\n",
    "    \n",
    "# images = np.array(images)\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# masks = []\n",
    "# for i in range(1, 101):\n",
    "#     img = Image.open(\"images_train/\" + str(i) + \".png\")\n",
    "#     arr = np.array(img)\n",
    "#     images.append(arr)\n",
    "#     img = Image.open(\"mask_train/\" + str(i) + \".png\")\n",
    "#     arr = np.array(img)\n",
    "#     arr = np.expand_dims(arr, -1)\n",
    "#     masks.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = np.array(images)\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 101):\n",
    "#     if i < 10: \n",
    "#         img = Image.open(\"data/training/groundtruth/satImage_\" + \"00\" + str(i) + \".png\")\n",
    "#     elif i>=10 and i<100:\n",
    "#         img = Image.open(\"data/training/groundtruth/satImage_\" + \"0\" + str(i) + \".png\")\n",
    "#     else:\n",
    "#         img = Image.open(\"data/training/groundtruth/satImage_\"  + str(i) + \".png\")\n",
    "\n",
    "#     arr = np.array(img)\n",
    "#     arr = np.expand_dims(arr, -1)\n",
    "#     masks.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks = np.array(masks)\n",
    "# masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(\"Dataset_train.h5\", 'w') as hdf:\n",
    "#     hdf.create_dataset('images', data=images, compression='gzip', compression_opts=9)\n",
    "#     hdf.create_dataset('masks', data=masks, compression='gzip', compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np \n",
    "# import os\n",
    "# import cv2\n",
    "\n",
    "# from tensorflow.keras.models import *\n",
    "# from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.optimizers import *\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "# from tensorflow.keras import backend as keras\n",
    "\n",
    "# import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unet(input_size = (256, 256, 3)):\n",
    "#     inputs = Input(input_size)\n",
    "#     conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', \n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(inputs)\n",
    "    \n",
    "#     conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', \n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(conv1)\n",
    "    \n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "#     conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(pool1)\n",
    "    \n",
    "#     conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv2)\n",
    "    \n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "#     conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(pool2)\n",
    "    \n",
    "#     conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv3)\n",
    "    \n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "#     conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(pool3)\n",
    "    \n",
    "#     conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv4)\n",
    "    \n",
    "#     drop4 = Dropout(0.5)(conv4)\n",
    "    \n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "#     conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', \n",
    "#                                                  kernel_initializer = 'he_normal'\n",
    "#                                                  )(pool4)\n",
    "    \n",
    "#     conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', \n",
    "#                                                  kernel_initializer = 'he_normal'\n",
    "#                                                  )(conv5)\n",
    "    \n",
    "#     drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "#     up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', \n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(UpSampling2D(size = (2,2))(drop5))\n",
    "    \n",
    "#     merge6 = concatenate([drop4,up6])\n",
    "    \n",
    "#     conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(merge6)\n",
    "    \n",
    "#     conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv6)\n",
    "\n",
    "#     up7 = Conv2D(256, 2, activation = 'relu', padding = 'same',\n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(UpSampling2D(size = (2,2))(conv6))\n",
    "    \n",
    "#     merge7 = concatenate([conv3,up7])\n",
    "    \n",
    "#     conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(merge7)\n",
    "    \n",
    "#     conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv7)\n",
    "\n",
    "    \n",
    "#     up8 = Conv2D(128, 2, activation = 'relu', padding = 'same',\n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(UpSampling2D(size = (2,2))(conv7))\n",
    "    \n",
    "#     merge8 = concatenate([conv2,up8])\n",
    "    \n",
    "#     conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(merge8)\n",
    "    \n",
    "#     conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv8)\n",
    "\n",
    "#     up9 = Conv2D(64, 2, activation = 'relu', padding = 'same',\n",
    "#                                              kernel_initializer = 'he_normal'\n",
    "#                                              )(UpSampling2D(size = (2,2))(conv8))\n",
    "    \n",
    "#     merge9 = concatenate([conv1,up9])\n",
    "    \n",
    "#     conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',\n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(merge9)\n",
    "    \n",
    "#     conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',\n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(conv9)\n",
    "    \n",
    "#     conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same',\n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(conv9)\n",
    "    \n",
    "#     conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "#     model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "#     model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print('*'*30)\n",
    "# print('Loading and preprocessing train data...')\n",
    "# print('*'*30)\n",
    "# file = h5py.File('Dataset_train.h5', 'r')\n",
    "# imgs_train = file.get('images')\n",
    "# imgs_mask_train = file.get('masks')\n",
    "# imgs_train = np.array(imgs_train)\n",
    "# imgs_mask_train = np.array(imgs_mask_train)\n",
    "\n",
    "# imgs_train = imgs_train.astype('float32')\n",
    "# mean = np.mean(imgs_train)  # mean for data centering\n",
    "# std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "# imgs_train -= mean\n",
    "# imgs_train /= std\n",
    "\n",
    "# imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "# imgs_mask_train /= 255  # scale masks to [0, 1]\n",
    "\n",
    "# print('*'*30)\n",
    "# print('Creating and compiling model...')\n",
    "# print('*'*30)\n",
    "# model = unet()\n",
    "# model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "# tensorboard = TensorBoard(log_dir='tensorboard/', write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_mask_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('*'*30)\n",
    "# print('Fitting model...')\n",
    "# print('*'*30)\n",
    "# with tf.device('/gpu:0'):\n",
    "#     history =  model.fit(imgs_train, imgs_mask_train, batch_size=10, verbose=1, epochs=10, shuffle=True,\n",
    "#               validation_split=0.2)\n",
    "# #               callbacks=[ModelCheckpoint, TensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = h5py.File('Dataset_test.h5', 'r')\n",
    "# imgs_test = file.get('images')\n",
    "# #imgs_mask_test = file.get('masks')\n",
    "# imgs_test = np.array(imgs_test)\n",
    "# #imgs_mask_test = np.array(imgs_mask_test)\n",
    "# imgs_test = imgs_test.astype('float32')\n",
    "# imgs_test -= mean\n",
    "# imgs_test /= std\n",
    "\n",
    "# print('*'*30)\n",
    "# print('Loading saved weights...')\n",
    "# print('*'*30)\n",
    "# model.load_weights('weights.h5')\n",
    "\n",
    "# print('*'*30)\n",
    "# print('Predicting masks on test data...')\n",
    "# print('*'*30)\n",
    "# imgs_mask_test = model.predict(imgs_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('*' * 30)\n",
    "# print('Saving predicted masks to files...')\n",
    "# print('*' * 30)\n",
    "# pred_dir = 'Preds2'\n",
    "# if not os.path.exists(pred_dir):\n",
    "#     os.mkdir(pred_dir)\n",
    "# for i, image in enumerate(imgs_mask_test):\n",
    "#     image = (image * 255).astype(np.uint8)\n",
    "#     cv2.imwrite(os.path.join(pred_dir, str(i + 1) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(60, 30))\n",
    "# plt.plot(history.history['loss'], linewidth=8, color='r')                   #visualising training and validation loss curves\n",
    "# plt.plot(history.history['val_loss'], linewidth=8, color='b')\n",
    "# plt.title('Model train vs Validation Loss', fontsize=100, fontweight=\"bold\")\n",
    "# plt.ylabel('Loss', fontsize=80)\n",
    "# plt.xlabel('Epoch', fontsize=80)\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right', fontsize=50)\n",
    "# plt.xticks(fontsize=60)\n",
    "# plt.yticks(fontsize=60)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "#     model = Model()\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "\n",
    "def adjustData(img,gt):\n",
    "    #make sure img value is between 0 and 1, and that mask is either 1 or 0\n",
    "    if(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        gt = gt /255\n",
    "        gt[gt > 0.5] = 1\n",
    "        gt[gt <= 0.5] = 0\n",
    "    return (img,gt)\n",
    "\n",
    "def trainGenerator(batch_size,path,image_folder,gt_folder,augmentation_variables,save_to_dir = None,\n",
    "                    target_size = (256,256),seed = 1):\n",
    "\n",
    "    #create generators generating coresponding images using same seed, that will yield coresponding images\n",
    "    image_generator = ImageDataGenerator(**augmentation_variables)\n",
    "    gt_generator = ImageDataGenerator(**augmentation_variables)\n",
    "    \n",
    "#     print(path)\n",
    "#     print([image_folder])\n",
    "#     print(gt_folder)\n",
    "    image_generator = image_generator.flow_from_directory(\n",
    "        path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = \"rgb\",\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        seed = seed)\n",
    "    \n",
    "    gt_generator = gt_generator.flow_from_directory(\n",
    "        path,\n",
    "        classes = [gt_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = \"grayscale\",\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        seed = seed)\n",
    "    \n",
    "    #zip both generators into a shared generator\n",
    "    train_generator = zip(image_generator, gt_generator)\n",
    "    #adjust image values to be between 0 and 1, and gt images to be 0 or 1\n",
    "    for (image,gt) in train_generator:\n",
    "        image,gt = adjustData(image,gt)\n",
    "        yield (image,gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    " \n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "\n",
    "# Extract 2-dimensional features consisting of average gray color as well as variance\n",
    "def extract_features_2d(img):\n",
    "    feat_m = np.mean(img)\n",
    "    feat_v = np.var(img)\n",
    "    feat = np.append(feat_m, feat_v)\n",
    "    return feat\n",
    "\n",
    "# Extract features for a given image\n",
    "def extract_img_features(filename):\n",
    "    img = load_image(filename)\n",
    "    img_patches = img_crop(img, patch_size, patch_size)\n",
    "    X = np.asarray([ extract_features_2d(img_patches[i]) for i in range(len(img_patches))])\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def value_to_class(v, foreground_threshold):\n",
    "    df = np.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# Convert array of labels to an image\n",
    "\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    im = np.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            im[j:j+w, i:i+h] = labels[idx]\n",
    "            idx = idx + 1\n",
    "    return im\n",
    "\n",
    "def make_img_overlay(img, predicted_img):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "    color_mask[:,:,0] = predicted_img*255\n",
    "\n",
    "    img8 = img_float_to_uint8(img)\n",
    "    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "    new_img = Image.blend(background, overlay, 0.2)\n",
    "    return new_img\n",
    "\n",
    "#crop images into patches\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "def make_patches(imgs, w, h):\n",
    "    # Extract patches from input images\n",
    "    img_patches = [img_crop(imgs[i], w, h,) for i in range(len(imgs))]\n",
    "    # Linearize list of patches\n",
    "    #shape is 10*625 (10 images, cut up into 625 images with 16*16)\n",
    "    img_patches=np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])    \n",
    "    return img_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#this method is used in method beneath\n",
    "def load_image(infilename):\n",
    "    return mpimg.imread(infilename)\n",
    "\n",
    "#method to load testing images\n",
    "def load_test_images():\n",
    "    root_dir = \"data/test_set_images/\"\n",
    "    directory = root_dir\n",
    "    # Get filenames and images for all the 50 submission images\n",
    "    image_dir = [directory + \"test_{}/\".format(i) for i in range(1, 51)]\n",
    "    filenames = [fn for imdir in image_dir for fn in os.listdir(imdir)]\n",
    "    test_images = [load_image(image_dir[i] + filenames[i]) for i in range(0,50)]\n",
    "    return test_images\n",
    "\n",
    "#method to save predicted images\n",
    "def save_result(save_path,npyfile):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "\n",
    "#method used to make a deliverable csv file\n",
    "def save_submission(final_pred, submission_filename, patch_size = 16):\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for i in range(final_pred.shape[0]):\n",
    "            for j in range(final_pred.shape[1]):\n",
    "                for k in range(final_pred.shape[2]):\n",
    "                    name = '{:03d}_{}_{},{}'.format(i+1, j * patch_size, k * patch_size, int(final_pred[i,j,k]))\n",
    "                    f.write(name + '\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "\n",
    "# from unet_model import *\n",
    "# from image_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"data/training/groundtruth/satImage_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using google drive to fetch images\n",
    "# drive_dir = \"drive/My Drive/\"\n",
    "train_dir = \"data/training/\"\n",
    "weights_dir = \"data/weights/\"\n",
    "image_folder = 'images'\n",
    "gt_folder = 'groundtruth'\n",
    "weights_filename ='weights.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_variables = dict(rotation_range=90,\n",
    "                           width_shift_range=0.4,\n",
    "                           height_shift_range=0.4,\n",
    "                           zoom_range=0.5,\n",
    "                           horizontal_flip=True,\n",
    "                           vertical_flip = True,\n",
    "                           fill_mode='reflect')\n",
    "batch_size = 2\n",
    "steps_per_epoch = 10\n",
    "epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 1024) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 1)  3           conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,837\n",
      "Trainable params: 31,032,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/weights/weights.hdf5'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_dir + weights_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Found 100 images belonging to 1 classes.\n",
      "Found 100 images belonging to 1 classes.\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2D in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BiasAdd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Relu in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MaxPool in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GreaterEqual in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ResizeNearestNeighbor in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2D in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sigmoid in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Minimum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Maximum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Log in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Neg in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op NoOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BroadcastGradientArgs in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Tile in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Maximum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op FloorDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reciprocal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ZerosLike in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Select in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LessEqual in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op SigmoidGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BiasAddGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ShapeN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropInput in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropFilter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReluGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropInput in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropFilter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op SplitV in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ResizeNearestNeighborGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MaxPoolGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Pow in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sqrt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ResourceApplyAdam in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Greater in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.6945 - accuracy: 0.7764\n",
      "Epoch 00001: loss improved from inf to 0.69437, saving model to data/weights/weights.hdf5\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6944 - accuracy: 0.7853\n",
      "Epoch 2/2\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6927 - accuracy: 0.8018\n",
      "Epoch 00002: loss improved from 0.69437 to 0.69272, saving model to data/weights/weights.hdf5\n",
      "10/10 [==============================] - 7s 722ms/step - loss: 0.6927 - accuracy: 0.7985\n"
     ]
    }
   ],
   "source": [
    "pending_train = True\n",
    "if pending_train:\n",
    "    train_generator = trainGenerator(batch_size,train_dir,image_folder,gt_folder,generator_variables)\n",
    "    #add checkpoint to save \n",
    "    checkpoint = ModelCheckpoint(weights_dir + weights_filename, monitor='loss', verbose=1, save_best_only=True)\n",
    "    model.fit_generator(train_generator,steps_per_epoch=steps_per_epoch,epochs=epochs,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#treshold for setting a patch value to 1\n",
    "foreground_treshold = 0.25\n",
    "weights = 'weights.hdf5'\n",
    "filename = \"predictions.csv\"\n",
    "#Set to true if you want to save road predictions as image files\n",
    "save_predicted_images = True\n",
    "predict_path = \"prediction/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = unet()\n",
    "model.load_weights(weights_dir + weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test images\n",
    "test_imgs = load_test_images()\n",
    "#make patches with the same size as original images\n",
    "test_imgs = make_patches(test_imgs, 256, 256)\n",
    "# test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_imgs.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (450, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-c92f6c6a39aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#You may need to change this slice.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     return self._model_iteration(\n\u001b[0;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    563\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (450, 1)"
     ]
    }
   ],
   "source": [
    "#You may need to change this slice.\n",
    "prediction = model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(save_predicted_images):\n",
    "    save_result(predict_path,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
