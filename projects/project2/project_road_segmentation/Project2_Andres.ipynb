{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17189003894020873683\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4937233203\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15160021089410029526\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import os\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary for our model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    LeakyReLU,\n",
    ")\n",
    "from tensorflow.compat.v2.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# keras, model definition...\n",
    "cb = TQDMNotebookCallback()\n",
    "setattr(cb, \"on_train_batch_begin\", lambda x, y: None)\n",
    "setattr(cb, \"on_train_batch_end\", lambda x, y: None)\n",
    "\n",
    "# model.fit(X_train, Y_train, verbose=0, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "Loading 100 groundtruth images\n"
     ]
    }
   ],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/training/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" groundtruth images\")\n",
    "gt_imgs = np.asarray([load_image(gt_dir + files[i]) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "\n",
    "# We separate the images from the groundtruth images\n",
    "img_patches = [img_crop(imgs[i], image_size, image_size) for i in range(n)]\n",
    "gt_patches = [img_crop(gt_imgs[i], image_size, image_size) for i in range(n)]\n",
    "\n",
    "# Linearize the list and labeling them X and Y\n",
    "X = np.asarray(\n",
    "    [\n",
    "        img_patches[i][j]\n",
    "        for i in range(len(img_patches))\n",
    "        for j in range(len(img_patches[i]))\n",
    "    ]\n",
    ")\n",
    "Y = np.asarray(\n",
    "    [\n",
    "        gt_patches[i][j]\n",
    "        for i in range(len(gt_patches))\n",
    "        for j in range(len(gt_patches[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating mini-batch and running data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch():\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 72\n",
    "    batch_size = 100\n",
    "    patch_size = 16\n",
    "    num_images = 100\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index represnting an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.25\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.25) * 1, 2\n",
    "            )\n",
    "\n",
    "            # The image augmentation is based on both flipping and rotating (randomly in steps of 45°)\n",
    "            # Random vertical and horizontal flip\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "            # Random rotation in steps of 45°\n",
    "            rotations = [0, 45, 90, 135, 180, 225, 270, 315, 350]\n",
    "\n",
    "            # We select a rotation degree randomly\n",
    "            rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "            # Rotate it using the random value (uses the scipy library)\n",
    "            sampled_image = scipy.ndimage.rotate(\n",
    "                sampled_image,\n",
    "                rotations[rotation_choice],\n",
    "                order=1,\n",
    "                reshape=False,\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the class (Same as in cnn_model.py, but provided here for better readability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                128, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)\n",
    "            )\n",
    "        )\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.001),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"loss\", min_delta=0, patience=10, verbose=1, mode=\"auto\"\n",
    "        )\n",
    "\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [early_stopping, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        self.model.fit_generator(\n",
    "            create_minibatch(),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "    def save(self, filename):\n",
    "        # Save the model (used to then load to submit)\n",
    "        self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,275,586\n",
      "Trainable params: 2,275,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      " 29/150 [====>.........................] - ETA: 24s - loss: 0.6191 - accuracy: 0.7295 - recall: 0.7286 - f1: 0.7291"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-a197a61c41f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no_batch_LeakyRelu.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-100-312359ac28d6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         )\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m           \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[0;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     if skip_input_indices is not None and 1 in skip_input_indices and _IsScalar(\n\u001b[0;32m   1168\u001b[0m         y):\n\u001b[1;32m-> 1169\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6683\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   6684\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6685\u001b[1;33m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m   6686\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6687\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# We define the number of epochs and steps per epochs\n",
    "EPOCHS = 1500\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = False\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model\n",
    "model.train()\n",
    "model.save(\"no_batch_LeakyRelu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,275,586\n",
      "Trainable params: 2,275,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "Executing op Relu in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReluGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 0.5745 - accuracy: 0.7389 - recall: 0.7379 - f1: 0.7383\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 0.5275 - accuracy: 0.7398 - recall: 0.7398 - f1: 0.7398\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.5086 - accuracy: 0.7441 - recall: 0.7437 - f1: 0.7440\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 0.4906 - accuracy: 0.7493 - recall: 0.7496 - f1: 0.7494\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 0.4791 - accuracy: 0.7553 - recall: 0.7543 - f1: 0.7551\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 0.4774 - accuracy: 0.7573 - recall: 0.7595 - f1: 0.7578\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.4688 - accuracy: 0.7634 - recall: 0.7605 - f1: 0.7627\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.4564 - accuracy: 0.7780 - recall: 0.7777 - f1: 0.7779\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.4333 - accuracy: 0.7931 - recall: 0.7925 - f1: 0.7930\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 0.4089 - accuracy: 0.8105 - recall: 0.8107 - f1: 0.8105\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 0.3869 - accuracy: 0.8218 - recall: 0.8212 - f1: 0.8217\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 0.3362 - accuracy: 0.8477 - recall: 0.8468 - f1: 0.8475\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 28s 183ms/step - loss: 0.3228 - accuracy: 0.8522 - recall: 0.8518 - f1: 0.8521\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 0.3138 - accuracy: 0.8633 - recall: 0.8634 - f1: 0.8633\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 0.2864 - accuracy: 0.8758 - recall: 0.8739 - f1: 0.8755 13s - loss: 0.2885 - accuracy: 0.8744 - reca - ETA: 2s - loss: 0.2861 - accuracy: 0.8759 - r\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 0.2941 - accuracy: 0.8683 - recall: 0.8680 - f1: 0.8683\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 0.2802 - accuracy: 0.8767 - recall: 0.8772 - f1: 0.8767s - loss: 0.2813 - accu\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 0.2863 - accuracy: 0.8760 - recall: 0.8763 - f1: 0.8760\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.2770 - accuracy: 0.8805 - recall: 0.8801 - f1: 0.8804\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 0.2523 - accuracy: 0.8894 - recall: 0.8904 - f1: 0.8895\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "EPOCHS = 1500\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = False\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "model.train()\n",
    "model.save(\"no_batch_relu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeakyReLU\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,280,450\n",
      "Trainable params: 2,278,018\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op FusedBatchNormV3 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignSubVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op FusedBatchNormGradV3 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.5475 - accuracy: 0.7335 - recall: 0.7379 - f1: 0.7342\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.4416 - accuracy: 0.7982 - recall: 0.7995 - f1: 0.7985\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.3820 - accuracy: 0.8261 - recall: 0.8269 - f1: 0.8262\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.3624 - accuracy: 0.8353 - recall: 0.8368 - f1: 0.8355\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.3209 - accuracy: 0.8530 - recall: 0.8523 - f1: 0.8529\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.3041 - accuracy: 0.8652 - recall: 0.8646 - f1: 0.8651\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.2889 - accuracy: 0.8756 - recall: 0.8761 - f1: 0.8757\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.2684 - accuracy: 0.8833 - recall: 0.8834 - f1: 0.8833\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 39s 258ms/step - loss: 0.2545 - accuracy: 0.8925 - recall: 0.8937 - f1: 0.8926\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2517 - accuracy: 0.8942 - recall: 0.8937 - f1: 0.8942\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2431 - accuracy: 0.8972 - recall: 0.8969 - f1: 0.8972\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.2221 - accuracy: 0.9085 - recall: 0.9084 - f1: 0.9085\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.2237 - accuracy: 0.9077 - recall: 0.9079 - f1: 0.9077\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.2165 - accuracy: 0.9122 - recall: 0.9120 - f1: 0.9121\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 40s 268ms/step - loss: 0.2076 - accuracy: 0.9152 - recall: 0.9152 - f1: 0.9152\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 38s 250ms/step - loss: 0.2147 - accuracy: 0.9095 - recall: 0.9091 - f1: 0.9094\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.2082 - accuracy: 0.9153 - recall: 0.9151 - f1: 0.9153\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.2030 - accuracy: 0.9159 - recall: 0.9155 - f1: 0.9159\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.2068 - accuracy: 0.9172 - recall: 0.9171 - f1: 0.9172\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 37s 245ms/step - loss: 0.2038 - accuracy: 0.9161 - recall: 0.9161 - f1: 0.9161\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "EPOCHS = 1500\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "model.train()\n",
    "model.save(\"batch_LeakyReLU.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,280,450\n",
      "Trainable params: 2,278,018\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.5937 - accuracy: 0.7339 - recall: 0.7353 - f1: 0.7343\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 38s 256ms/step - loss: 0.4899 - accuracy: 0.7633 - recall: 0.7578 - f1: 0.7619\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 37s 248ms/step - loss: 0.4034 - accuracy: 0.8116 - recall: 0.8087 - f1: 0.8110\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 37s 244ms/step - loss: 0.3815 - accuracy: 0.8254 - recall: 0.8226 - f1: 0.8249\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3425 - accuracy: 0.8445 - recall: 0.8425 - f1: 0.8442\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 37s 245ms/step - loss: 0.3353 - accuracy: 0.8495 - recall: 0.8493 - f1: 0.8495\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3209 - accuracy: 0.8578 - recall: 0.8571 - f1: 0.8577\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 38s 250ms/step - loss: 0.2914 - accuracy: 0.8735 - recall: 0.8725 - f1: 0.8734\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 37s 249ms/step - loss: 0.2722 - accuracy: 0.8839 - recall: 0.8839 - f1: 0.8839\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.2720 - accuracy: 0.8812 - recall: 0.8813 - f1: 0.8812\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.2605 - accuracy: 0.8864 - recall: 0.8880 - f1: 0.8866\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.2402 - accuracy: 0.8993 - recall: 0.8997 - f1: 0.8994\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2420 - accuracy: 0.8993 - recall: 0.8997 - f1: 0.8993\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2325 - accuracy: 0.9022 - recall: 0.9017 - f1: 0.9021\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2255 - accuracy: 0.9078 - recall: 0.9085 - f1: 0.9079\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2259 - accuracy: 0.9014 - recall: 0.9017 - f1: 0.9014\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2281 - accuracy: 0.9039 - recall: 0.9037 - f1: 0.9039\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2127 - accuracy: 0.9102 - recall: 0.9101 - f1: 0.9102\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2144 - accuracy: 0.9102 - recall: 0.9102 - f1: 0.9102\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2067 - accuracy: 0.9139 - recall: 0.9145 - f1: 0.9140\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2061 - accuracy: 0.9157 - recall: 0.9166 - f1: 0.9158\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.2060 - accuracy: 0.9144 - recall: 0.9135 - f1: 0.9143\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1998 - accuracy: 0.9172 - recall: 0.9168 - f1: 0.9172\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1975 - accuracy: 0.9158 - recall: 0.9158 - f1: 0.9158\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1940 - accuracy: 0.9199 - recall: 0.9197 - f1: 0.9198\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1931 - accuracy: 0.9178 - recall: 0.9175 - f1: 0.9178\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1870 - accuracy: 0.9248 - recall: 0.9246 - f1: 0.9248\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1800 - accuracy: 0.9276 - recall: 0.9272 - f1: 0.9276\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1858 - accuracy: 0.9265 - recall: 0.9265 - f1: 0.9265\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1754 - accuracy: 0.9292 - recall: 0.9287 - f1: 0.9291\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1744 - accuracy: 0.9311 - recall: 0.9311 - f1: 0.9311\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1801 - accuracy: 0.9240 - recall: 0.9243 - f1: 0.9240\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1738 - accuracy: 0.9279 - recall: 0.9279 - f1: 0.9279\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1721 - accuracy: 0.9305 - recall: 0.9305 - f1: 0.9305\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1737 - accuracy: 0.9286 - recall: 0.9285 - f1: 0.9286\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1734 - accuracy: 0.9286 - recall: 0.9291 - f1: 0.9286\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1704 - accuracy: 0.9307 - recall: 0.9308 - f1: 0.9307\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1637 - accuracy: 0.9337 - recall: 0.9338 - f1: 0.9337\n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1641 - accuracy: 0.9343 - recall: 0.9345 - f1: 0.9343\n",
      "Epoch 40/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1691 - accuracy: 0.9304 - recall: 0.9305 - f1: 0.9304\n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1641 - accuracy: 0.9318 - recall: 0.9315 - f1: 0.9317\n",
      "Epoch 42/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1647 - accuracy: 0.9334 - recall: 0.9331 - f1: 0.9333\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1648 - accuracy: 0.9335 - recall: 0.9332 - f1: 0.9335\n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 37s 248ms/step - loss: 0.1530 - accuracy: 0.9372 - recall: 0.9373 - f1: 0.9372\n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1487 - accuracy: 0.9414 - recall: 0.9415 - f1: 0.9414\n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1397 - accuracy: 0.9444 - recall: 0.9444 - f1: 0.9444\n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1442 - accuracy: 0.9409 - recall: 0.9409 - f1: 0.9409\n",
      "Epoch 47/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1423 - accuracy: 0.9424 - recall: 0.9425 - f1: 0.9424\n",
      "Epoch 48/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1470 - accuracy: 0.9399 - recall: 0.9401 - f1: 0.9399\n",
      "Epoch 49/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 0.9398 - recall: 0.9400 - f1: 0.9398\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1433 - accuracy: 0.9397 - recall: 0.9399 - f1: 0.9397\n",
      "Epoch 50/500\n",
      "150/150 [==============================] - 36s 238ms/step - loss: 0.1445 - accuracy: 0.9421 - recall: 0.9420 - f1: 0.9421\n",
      "Epoch 51/500\n",
      "150/150 [==============================] - 35s 236ms/step - loss: 0.1306 - accuracy: 0.9474 - recall: 0.9474 - f1: 0.9474\n",
      "Epoch 52/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1306 - accuracy: 0.9480 - recall: 0.9482 - f1: 0.9480\n",
      "Epoch 53/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1359 - accuracy: 0.9440 - recall: 0.9440 - f1: 0.9440\n",
      "Epoch 54/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1239 - accuracy: 0.9498 - recall: 0.9499 - f1: 0.9498\n",
      "Epoch 55/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1332 - accuracy: 0.9455 - recall: 0.9455 - f1: 0.9455\n",
      "Epoch 56/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1312 - accuracy: 0.9485 - recall: 0.9487 - f1: 0.9485\n",
      "Epoch 57/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1299 - accuracy: 0.9492 - recall: 0.9493 - f1: 0.9492\n",
      "Epoch 58/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9449 - recall: 0.9450 - f1: 0.9449\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1328 - accuracy: 0.9449 - recall: 0.9450 - f1: 0.9449\n",
      "Epoch 59/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1267 - accuracy: 0.9493 - recall: 0.9494 - f1: 0.9493\n",
      "Epoch 60/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1248 - accuracy: 0.9498 - recall: 0.9499 - f1: 0.9498\n",
      "Epoch 61/500\n",
      "150/150 [==============================] - 36s 239ms/step - loss: 0.1233 - accuracy: 0.9489 - recall: 0.9490 - f1: 0.9489\n",
      "Epoch 62/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1286 - accuracy: 0.9473 - recall: 0.9473 - f1: 0.9473\n",
      "Epoch 63/500\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.1258 - accuracy: 0.9491 - recall: 0.9491 - f1: 0.9491\n",
      "Epoch 64/500\n",
      "150/150 [==============================] - 36s 243ms/step - loss: 0.1298 - accuracy: 0.9457 - recall: 0.9456 - f1: 0.9457\n",
      "Epoch 65/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9480 - recall: 0.9481 - f1: 0.9480\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.1267 - accuracy: 0.9481 - recall: 0.9482 - f1: 0.9481\n",
      "Epoch 66/500\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.1262 - accuracy: 0.9499 - recall: 0.9499 - f1: 0.9499\n",
      "Epoch 67/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1263 - accuracy: 0.9480 - recall: 0.9479 - f1: 0.9480\n",
      "Epoch 68/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1219 - accuracy: 0.9493 - recall: 0.9493 - f1: 0.9493\n",
      "Epoch 69/500\n",
      "150/150 [==============================] - 36s 238ms/step - loss: 0.1237 - accuracy: 0.9510 - recall: 0.9509 - f1: 0.9510\n",
      "Epoch 70/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1212 - accuracy: 0.9519 - recall: 0.9520 - f1: 0.9519\n",
      "Epoch 71/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1267 - accuracy: 0.9462 - recall: 0.9465 - f1: 0.9462\n",
      "Epoch 72/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1202 - accuracy: 0.9500 - recall: 0.9499 - f1: 0.9500\n",
      "Epoch 73/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1182 - accuracy: 0.9508 - recall: 0.9510 - f1: 0.9508\n",
      "Epoch 74/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1214 - accuracy: 0.9490 - recall: 0.9490 - f1: 0.9490\n",
      "Epoch 75/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1244 - accuracy: 0.9486 - recall: 0.9487 - f1: 0.9486\n",
      "Epoch 76/500\n",
      "150/150 [==============================] - 36s 239ms/step - loss: 0.1186 - accuracy: 0.9488 - recall: 0.9490 - f1: 0.9488\n",
      "Epoch 77/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9482 - recall: 0.9484 - f1: 0.9482\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1227 - accuracy: 0.9480 - recall: 0.9483 - f1: 0.9480\n",
      "Epoch 78/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1215 - accuracy: 0.9490 - recall: 0.9491 - f1: 0.9490\n",
      "Epoch 79/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1201 - accuracy: 0.9509 - recall: 0.9511 - f1: 0.9509\n",
      "Epoch 80/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1178 - accuracy: 0.9529 - recall: 0.9531 - f1: 0.9529\n",
      "Epoch 81/500\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.1188 - accuracy: 0.9476 - recall: 0.9477 - f1: 0.9476\n",
      "Epoch 82/500\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.1162 - accuracy: 0.9518 - recall: 0.9518 - f1: 0.9518\n",
      "Epoch 83/500\n",
      "150/150 [==============================] - 36s 238ms/step - loss: 0.1213 - accuracy: 0.9505 - recall: 0.9506 - f1: 0.9505\n",
      "Epoch 84/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1176 - accuracy: 0.9506 - recall: 0.9505 - f1: 0.9506\n",
      "Epoch 85/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1180 - accuracy: 0.9517 - recall: 0.9520 - f1: 0.9517\n",
      "Epoch 86/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9532 - recall: 0.9532 - f1: 0.9532\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.1172 - accuracy: 0.9533 - recall: 0.9533 - f1: 0.9533\n",
      "Epoch 87/500\n",
      "150/150 [==============================] - 36s 242ms/step - loss: 0.1148 - accuracy: 0.9515 - recall: 0.9516 - f1: 0.9515\n",
      "Epoch 88/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1144 - accuracy: 0.9536 - recall: 0.9537 - f1: 0.9536\n",
      "Epoch 89/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1160 - accuracy: 0.9528 - recall: 0.9529 - f1: 0.9528\n",
      "Epoch 90/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1165 - accuracy: 0.9503 - recall: 0.9505 - f1: 0.9503\n",
      "Epoch 91/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1294 - accuracy: 0.9487 - recall: 0.9485 - f1: 0.9487\n",
      "Epoch 92/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1112 - accuracy: 0.9545 - recall: 0.9545 - f1: 0.9545\n",
      "Epoch 93/500\n",
      "150/150 [==============================] - 37s 250ms/step - loss: 0.1188 - accuracy: 0.9512 - recall: 0.9513 - f1: 0.9512\n",
      "Epoch 94/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1243 - accuracy: 0.9476 - recall: 0.9477 - f1: 0.9476\n",
      "Epoch 95/500\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1175 - accuracy: 0.9517 - recall: 0.9519 - f1: 0.9517\n",
      "Epoch 96/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 0.9500 - recall: 0.9499 - f1: 0.9500\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1214 - accuracy: 0.9501 - recall: 0.9501 - f1: 0.9501\n",
      "Epoch 97/500\n",
      "150/150 [==============================] - 36s 239ms/step - loss: 0.1191 - accuracy: 0.9528 - recall: 0.9529 - f1: 0.9528\n",
      "Epoch 98/500\n",
      "150/150 [==============================] - 36s 239ms/step - loss: 0.1210 - accuracy: 0.9493 - recall: 0.9494 - f1: 0.9493\n",
      "Epoch 99/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1178 - accuracy: 0.9533 - recall: 0.9533 - f1: 0.9533\n",
      "Epoch 100/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9493 - recall: 0.9493 - f1: 0.9493\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.1213 - accuracy: 0.9494 - recall: 0.9495 - f1: 0.9494\n",
      "Epoch 101/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1191 - accuracy: 0.9516 - recall: 0.9517 - f1: 0.9516\n",
      "Epoch 102/500\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 0.1172 - accuracy: 0.9522 - recall: 0.9523 - f1: 0.9522\n",
      "Epoch 00102: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "EPOCHS = 500\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "model.train()\n",
    "model.save(\"batch_relu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_66 (Conv2D)           (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,280,450\n",
      "Trainable params: 2,278,018\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,280,450\n",
      "Trainable params: 2,278,018\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_distributed_function_18802745 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Processing image => data/test_set_images/test_1/test_1.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_2/test_2.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_3/test_3.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_4/test_4.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_5/test_5.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_6/test_6.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_7/test_7.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_8/test_8.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_9/test_9.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_10/test_10.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_11/test_11.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_12/test_12.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_13/test_13.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_14/test_14.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_15/test_15.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_16/test_16.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_17/test_17.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_18/test_18.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_19/test_19.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_20/test_20.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_21/test_21.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_22/test_22.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_23/test_23.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_24/test_24.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_25/test_25.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_26/test_26.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_27/test_27.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_28/test_28.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_29/test_29.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_30/test_30.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_31/test_31.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_32/test_32.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_33/test_33.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_34/test_34.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_35/test_35.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_36/test_36.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_37/test_37.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_38/test_38.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_39/test_39.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_40/test_40.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_41/test_41.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_42/test_42.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_43/test_43.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_44/test_44.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_45/test_45.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_46/test_46.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_47/test_47.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_48/test_48.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_49/test_49.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_50/test_50.png\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"batch_relu.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
