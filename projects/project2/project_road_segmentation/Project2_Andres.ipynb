{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12560828584358284416\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4937233203\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 440309693219896134\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import os\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from helpers import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary for our model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# from tensorflow.keras.models import Sequential, load_model\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     LeakyReLU,\n",
    "# )\n",
    "from tensorflow.compat.v2.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# keras, model definition...\n",
    "cb = TQDMNotebookCallback()\n",
    "setattr(cb, \"on_train_batch_begin\", lambda x, y: None)\n",
    "setattr(cb, \"on_train_batch_end\", lambda x, y: None)\n",
    "\n",
    "# model.fit(X_train, Y_train, verbose=0, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "Loading 100 groundtruth images\n"
     ]
    }
   ],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir_train = root_dir + \"training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n_train) + \" images\")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir_train = root_dir + \"training/groundtruth/\"\n",
    "print(\"Loading \" + str(n_train) + \" groundtruth images\")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "\n",
    "# We separate the images from the groundtruth images\n",
    "img_patches_train = [\n",
    "    img_crop(imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "gt_patches_train = [\n",
    "    img_crop(gt_imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "\n",
    "# Linearize the list and labeling them X and Y\n",
    "X_train = np.asarray(\n",
    "    [\n",
    "        img_patches_train[i][j]\n",
    "        for i in range(len(img_patches_train))\n",
    "        for j in range(len(img_patches_train[i]))\n",
    "    ]\n",
    ")\n",
    "Y_train = np.asarray(\n",
    "    [\n",
    "        gt_patches_train[i][j]\n",
    "        for i in range(len(gt_patches_train))\n",
    "        for j in range(len(gt_patches_train[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the directory for the images and load them\n",
    "image_dir_val = root_dir + \"validating/images/\"\n",
    "files = os.listdir(image_dir_val)\n",
    "n_val = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n_val) + \" images\")\n",
    "imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir_val = root_dir + \"validating/groundtruth/\"\n",
    "print(\"Loading \" + str(n_val) + \" groundtruth images\")\n",
    "gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "\n",
    "# We separate the images from the groundtruth images\n",
    "img_patches_val = [img_crop(imgs_val[i], image_size, image_size) for i in range(n_val)]\n",
    "gt_patches_val = [\n",
    "    img_crop(gt_imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "]\n",
    "\n",
    "# Linearize the list and labeling them X and Y\n",
    "X_val = np.asarray(\n",
    "    [\n",
    "        img_patches_val[i][j]\n",
    "        for i in range(len(img_patches_val))\n",
    "        for j in range(len(img_patches_val[i]))\n",
    "    ]\n",
    ")\n",
    "Y_val = np.asarray(\n",
    "    [\n",
    "        gt_patches_val[i][j]\n",
    "        for i in range(len(gt_patches_val))\n",
    "        for j in range(len(gt_patches_val[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating mini-batch and running data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch(X, Y, n):\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 72\n",
    "    batch_size = 100\n",
    "    patch_size = 16\n",
    "    num_images = n\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index represnting an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.2\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "            )\n",
    "\n",
    "            # The image augmentation is based on both flipping and rotating (randomly in steps of 45째)\n",
    "            # Random vertical and horizontal flip\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "            # Random rotation in steps of 45째\n",
    "            rotations = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "            # We select a rotation degree randomly\n",
    "            rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "            # Rotate it using the random value (uses the scipy library)\n",
    "            sampled_image = scipy.ndimage.rotate(\n",
    "                sampled_image,\n",
    "                rotations[rotation_choice],\n",
    "                order=1,\n",
    "                reshape=False,\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL3, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        #         model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        #         model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        #         model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        #         model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        #         model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        #         model.add(Dropout(0.2))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                128, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)\n",
    "            )\n",
    "        )\n",
    "        #         if batch_normalization:\n",
    "        #             model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.005, amsgrad=True),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_f1\",\n",
    "            min_delta=0.5,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"val_f1\", factor=0.5, patience=4, verbose=1, mode=\"max\", cooldown=1\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"batch_relu_amsgrad_Earlystop_validation_kernel3_nodropout-{epoch:03d}-{f1:03f}-{val_f1:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_f1\",\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [save_best, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(X_train, Y_train, n_train),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "            validation_steps=STEPS_PER_EPOCH,\n",
    "        )\n",
    "        #         to_plot = self.model.fit_generator(\n",
    "        #             create_minibatch(X_train, Y_train, n_train),\n",
    "        #             steps_per_epoch=100,\n",
    "        #             epochs=EPOCHS,\n",
    "        #             use_multiprocessing=False,\n",
    "        #             workers=1,\n",
    "        #             callbacks=callbacks,\n",
    "        #             verbose=1,\n",
    "        #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "        #             validation_steps=100,\n",
    "        #         )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# We define the number of epochs and steps per epochs\n",
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model\n",
    "history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_relu_amsgrad_Earlystop_validation_kernel3_nodropout.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = False\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\n",
    "    \"batch_relu_amsgrad_Earlystop_validation_kernel5_nodropout-040-0.954435-0.924519.h5\"\n",
    ")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu_amsgrad_Earlystop_validation_kernel5_nodropout-040-0.954435-0.924519.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch(X, Y, n):\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 64\n",
    "    batch_size = 100\n",
    "    patch_size = 16\n",
    "    num_images = n\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index represnting an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.2\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "            )\n",
    "\n",
    "            # The image augmentation is based on both flipping and rotating (randomly in steps of 45째)\n",
    "            # Random vertical and horizontal flip\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "            # Random rotation in steps of 45째\n",
    "            rotations = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "            # We select a rotation degree randomly\n",
    "            rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "            # Rotate it using the random value (uses the scipy library)\n",
    "            sampled_image = scipy.ndimage.rotate(\n",
    "                sampled_image,\n",
    "                rotations[rotation_choice],\n",
    "                order=1,\n",
    "                reshape=False,\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        # Layer 1\n",
    "        model.add(Conv2D(64, KERNEL3, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(512, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(1024, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(512, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(UpSampling2D())\n",
    "        #         model.add(concatenate([drop4, up6], axis=3))\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(UpSampling2D())\n",
    "        #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(UpSampling2D())\n",
    "        #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(64, KERNEL3, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(UpSampling2D())\n",
    "        #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                64, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)\n",
    "            )\n",
    "        )\n",
    "        #         if batch_normalization:\n",
    "        #             model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.00001), activity_regularizer=l2(0.00001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.001, amsgrad=True),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"accuracy\",\n",
    "            min_delta=0.5,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"accuracy\",\n",
    "            factor=0.5,\n",
    "            patience=4,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "            cooldown=1,\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"Unet64_batch_relu_dropout_noVal-{epoch:03d}-{f1:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"accuracy\",\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [save_best, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(X_train, Y_train, n_train),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "            #             validation_steps=STEPS_PER_EPOCH,\n",
    "        )\n",
    "        #         to_plot = self.model.fit_generator(\n",
    "        #             create_minibatch(X_train, Y_train, n_train),\n",
    "        #             steps_per_epoch=100,\n",
    "        #             epochs=EPOCHS,\n",
    "        #             use_multiprocessing=False,\n",
    "        #             workers=1,\n",
    "        #             callbacks=callbacks,\n",
    "        #             verbose=1,\n",
    "        #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "        #             validation_steps=100,\n",
    "        #         )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4194368   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 16,744,706\n",
      "Trainable params: 16,738,818\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2D in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BiasAdd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op FusedBatchNormV3 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignSubVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LeakyRelu in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MaxPool in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GreaterEqual in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ResizeNearestNeighbor in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Square in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sigmoid in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Minimum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Maximum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Log in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Neg in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op NoOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BroadcastGradientArgs in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Tile in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Maximum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op FloorDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reciprocal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ZerosLike in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Select in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LessEqual in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op SigmoidGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BiasAddGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LeakyReluGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ResizeNearestNeighborGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op FusedBatchNormGradV3 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ShapeN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropInput in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropFilter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MaxPoolGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Pow in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sqrt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ResourceApplyAdamWithAmsgrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Greater in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Round in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.1544 - accuracy: 0.6839 - recall: 0.6778 - f1: 0.6808\n",
      "Epoch 00001: accuracy improved from -inf to 0.68373, saving model to Unet64_batch_relu_dropout_noVal-001-0.680679.h5\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 1.1524 - accuracy: 0.6837 - recall: 0.6778 - f1: 0.6807\n",
      "Epoch 2/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.7002 - accuracy: 0.7001 - recall: 0.6919 - f1: 0.6969\n",
      "Epoch 00002: accuracy improved from 0.68373 to 0.69987, saving model to Unet64_batch_relu_dropout_noVal-002-0.696657.h5\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.6997 - accuracy: 0.6999 - recall: 0.6916 - f1: 0.6967\n",
      "Epoch 3/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.5647 - accuracy: 0.7392 - recall: 0.7252 - f1: 0.7348\n",
      "Epoch 00003: accuracy improved from 0.69987 to 0.73927, saving model to Unet64_batch_relu_dropout_noVal-003-0.734925.h5\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.5648 - accuracy: 0.7393 - recall: 0.7254 - f1: 0.7349\n",
      "Epoch 4/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.4711 - accuracy: 0.7936 - recall: 0.7952 - f1: 0.7939\n",
      "Epoch 00004: accuracy improved from 0.73927 to 0.79387, saving model to Unet64_batch_relu_dropout_noVal-004-0.794105.h5\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.4707 - accuracy: 0.7939 - recall: 0.7953 - f1: 0.7941\n",
      "Epoch 5/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8104 - recall: 0.8111 - f1: 0.8105\n",
      "Epoch 00005: accuracy improved from 0.79387 to 0.81083, saving model to Unet64_batch_relu_dropout_noVal-005-0.810885.h5\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.4183 - accuracy: 0.8108 - recall: 0.8115 - f1: 0.8109\n",
      "Epoch 6/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3935 - accuracy: 0.8188 - recall: 0.8191 - f1: 0.8188\n",
      "Epoch 00006: accuracy improved from 0.81083 to 0.81917, saving model to Unet64_batch_relu_dropout_noVal-006-0.819214.h5\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.3927 - accuracy: 0.8192 - recall: 0.8195 - f1: 0.8192\n",
      "Epoch 7/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.8335 - recall: 0.8297 - f1: 0.8328\n",
      "Epoch 00007: accuracy improved from 0.81917 to 0.83350, saving model to Unet64_batch_relu_dropout_noVal-007-0.832889.h5\n",
      "150/150 [==============================] - 48s 321ms/step - loss: 0.3652 - accuracy: 0.8335 - recall: 0.8299 - f1: 0.8329\n",
      "Epoch 8/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.8444 - recall: 0.8429 - f1: 0.8441\n",
      "Epoch 00008: accuracy improved from 0.83350 to 0.84437, saving model to Unet64_batch_relu_dropout_noVal-008-0.844110.h5\n",
      "150/150 [==============================] - 48s 317ms/step - loss: 0.3452 - accuracy: 0.8444 - recall: 0.8428 - f1: 0.8441\n",
      "Epoch 9/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.8515 - recall: 0.8512 - f1: 0.8514\n",
      "Epoch 00009: accuracy improved from 0.84437 to 0.85147, saving model to Unet64_batch_relu_dropout_noVal-009-0.851414.h5\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.3346 - accuracy: 0.8515 - recall: 0.8512 - f1: 0.8514\n",
      "Epoch 10/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.8558 - recall: 0.8550 - f1: 0.8557\n",
      "Epoch 00010: accuracy improved from 0.85147 to 0.85573, saving model to Unet64_batch_relu_dropout_noVal-010-0.855628.h5\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 0.3234 - accuracy: 0.8557 - recall: 0.8549 - f1: 0.8556\n",
      "Epoch 11/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8681 - recall: 0.8674 - f1: 0.8680\n",
      "Epoch 00011: accuracy improved from 0.85573 to 0.86830, saving model to Unet64_batch_relu_dropout_noVal-011-0.868205.h5\n",
      "150/150 [==============================] - 49s 324ms/step - loss: 0.3048 - accuracy: 0.8683 - recall: 0.8676 - f1: 0.8682\n",
      "Epoch 12/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8679 - recall: 0.8674 - f1: 0.8678\n",
      "Epoch 00012: accuracy did not improve from 0.86830\n",
      "150/150 [==============================] - 46s 304ms/step - loss: 0.2988 - accuracy: 0.8677 - recall: 0.8673 - f1: 0.8677\n",
      "Epoch 13/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.8798 - recall: 0.8799 - f1: 0.8798\n",
      "Epoch 00013: accuracy improved from 0.86830 to 0.87967, saving model to Unet64_batch_relu_dropout_noVal-013-0.879652.h5\n",
      "150/150 [==============================] - 47s 314ms/step - loss: 0.2843 - accuracy: 0.8797 - recall: 0.8797 - f1: 0.8797\n",
      "Epoch 14/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.8811 - recall: 0.8800 - f1: 0.8810\n",
      "Epoch 00014: accuracy improved from 0.87967 to 0.88117, saving model to Unet64_batch_relu_dropout_noVal-014-0.881028.h5\n",
      "150/150 [==============================] - 48s 317ms/step - loss: 0.2784 - accuracy: 0.8812 - recall: 0.8801 - f1: 0.8810\n",
      "Epoch 15/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2690 - accuracy: 0.8855 - recall: 0.8850 - f1: 0.8855\n",
      "Epoch 00015: accuracy improved from 0.88117 to 0.88567, saving model to Unet64_batch_relu_dropout_noVal-015-0.885626.h5\n",
      "150/150 [==============================] - 47s 312ms/step - loss: 0.2689 - accuracy: 0.8857 - recall: 0.8852 - f1: 0.8856\n",
      "Epoch 16/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.8907 - recall: 0.8913 - f1: 0.8908\n",
      "Epoch 00016: accuracy improved from 0.88567 to 0.89117, saving model to Unet64_batch_relu_dropout_noVal-016-0.891234.h5\n",
      "150/150 [==============================] - 47s 314ms/step - loss: 0.2602 - accuracy: 0.8912 - recall: 0.8918 - f1: 0.8912\n",
      "Epoch 17/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.8948 - recall: 0.8952 - f1: 0.8948\n",
      "Epoch 00017: accuracy improved from 0.89117 to 0.89477, saving model to Unet64_batch_relu_dropout_noVal-017-0.894812.h5\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 0.2534 - accuracy: 0.8948 - recall: 0.8952 - f1: 0.8948\n",
      "Epoch 18/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.8974 - recall: 0.8974 - f1: 0.8974\n",
      "Epoch 00018: accuracy improved from 0.89477 to 0.89733, saving model to Unet64_batch_relu_dropout_noVal-018-0.897357.h5\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 0.2465 - accuracy: 0.8973 - recall: 0.8974 - f1: 0.8974\n",
      "Epoch 19/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.8969 - recall: 0.8972 - f1: 0.8969\n",
      "Epoch 00019: accuracy did not improve from 0.89733\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 0.2460 - accuracy: 0.8972 - recall: 0.8975 - f1: 0.8972\n",
      "Epoch 20/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2394 - accuracy: 0.8997 - recall: 0.8979 - f1: 0.8995\n",
      "Epoch 00020: accuracy improved from 0.89733 to 0.89997, saving model to Unet64_batch_relu_dropout_noVal-020-0.899798.h5\n",
      "150/150 [==============================] - 47s 312ms/step - loss: 0.2389 - accuracy: 0.9000 - recall: 0.8982 - f1: 0.8998\n",
      "Epoch 21/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2329 - accuracy: 0.9046 - recall: 0.9036 - f1: 0.9045\n",
      "Epoch 00021: accuracy improved from 0.89997 to 0.90427, saving model to Unet64_batch_relu_dropout_noVal-021-0.904179.h5\n",
      "150/150 [==============================] - 47s 315ms/step - loss: 0.2339 - accuracy: 0.9043 - recall: 0.9033 - f1: 0.9042\n",
      "Epoch 22/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9050 - recall: 0.9038 - f1: 0.9049\n",
      "Epoch 00022: accuracy improved from 0.90427 to 0.90510, saving model to Unet64_batch_relu_dropout_noVal-022-0.904967.h5\n",
      "150/150 [==============================] - 47s 312ms/step - loss: 0.2375 - accuracy: 0.9051 - recall: 0.9038 - f1: 0.9050\n",
      "Epoch 23/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2324 - accuracy: 0.9049 - recall: 0.9044 - f1: 0.9048\n",
      "Epoch 00023: accuracy did not improve from 0.90510\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 0.2325 - accuracy: 0.9048 - recall: 0.9043 - f1: 0.9047\n",
      "Epoch 24/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9082 - recall: 0.9077 - f1: 0.9081\n",
      "Epoch 00024: accuracy improved from 0.90510 to 0.90827, saving model to Unet64_batch_relu_dropout_noVal-024-0.908206.h5\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 0.2193 - accuracy: 0.9083 - recall: 0.9078 - f1: 0.9082\n",
      "Epoch 25/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9101 - recall: 0.9103 - f1: 0.9101\n",
      "Epoch 00025: accuracy improved from 0.90827 to 0.91007, saving model to Unet64_batch_relu_dropout_noVal-025-0.910057.h5\n",
      "150/150 [==============================] - 48s 320ms/step - loss: 0.2206 - accuracy: 0.9101 - recall: 0.9101 - f1: 0.9101\n",
      "Epoch 26/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9079 - recall: 0.9086 - f1: 0.9080\n",
      "Epoch 00026: accuracy did not improve from 0.91007\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 0.2193 - accuracy: 0.9078 - recall: 0.9085 - f1: 0.9079\n",
      "Epoch 27/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9069 - recall: 0.9072 - f1: 0.9069\n",
      "Epoch 00027: accuracy did not improve from 0.91007\n",
      "150/150 [==============================] - 45s 303ms/step - loss: 0.2247 - accuracy: 0.9068 - recall: 0.9071 - f1: 0.9069\n",
      "Epoch 28/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9105 - recall: 0.9115 - f1: 0.9106\n",
      "Epoch 00028: accuracy improved from 0.91007 to 0.91067, saving model to Unet64_batch_relu_dropout_noVal-028-0.910758.h5\n",
      "150/150 [==============================] - 47s 312ms/step - loss: 0.2138 - accuracy: 0.9107 - recall: 0.9117 - f1: 0.9108\n",
      "Epoch 29/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9148 - recall: 0.9154 - f1: 0.9148\n",
      "Epoch 00029: accuracy improved from 0.91067 to 0.91473, saving model to Unet64_batch_relu_dropout_noVal-029-0.914789.h5\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 0.2099 - accuracy: 0.9147 - recall: 0.9153 - f1: 0.9148\n",
      "Epoch 30/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2056 - accuracy: 0.9144 - recall: 0.9148 - f1: 0.9144\n",
      "Epoch 00030: accuracy did not improve from 0.91473\n",
      "150/150 [==============================] - 46s 305ms/step - loss: 0.2062 - accuracy: 0.9139 - recall: 0.9143 - f1: 0.9139\n",
      "Epoch 31/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2137 - accuracy: 0.9144 - recall: 0.9142 - f1: 0.9144\n",
      "Epoch 00031: accuracy did not improve from 0.91473\n",
      "150/150 [==============================] - 46s 304ms/step - loss: 0.2142 - accuracy: 0.9142 - recall: 0.9140 - f1: 0.9142\n",
      "Epoch 32/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9154 - recall: 0.9150 - f1: 0.9154\n",
      "Epoch 00032: accuracy improved from 0.91473 to 0.91547, saving model to Unet64_batch_relu_dropout_noVal-032-0.915423.h5\n",
      "150/150 [==============================] - 47s 315ms/step - loss: 0.2070 - accuracy: 0.9155 - recall: 0.9150 - f1: 0.9154\n",
      "Epoch 33/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9196 - recall: 0.9197 - f1: 0.9196\n",
      "Epoch 00033: accuracy improved from 0.91547 to 0.91970, saving model to Unet64_batch_relu_dropout_noVal-033-0.919709.h5\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 0.1991 - accuracy: 0.9197 - recall: 0.9197 - f1: 0.9197\n",
      "Epoch 34/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2040 - accuracy: 0.9198 - recall: 0.9200 - f1: 0.9198\n",
      "Epoch 00034: accuracy improved from 0.91970 to 0.91983, saving model to Unet64_batch_relu_dropout_noVal-034-0.919850.h5\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 0.2040 - accuracy: 0.9198 - recall: 0.9201 - f1: 0.9199\n",
      "Epoch 35/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9201 - recall: 0.9201 - f1: 0.9201\n",
      "Epoch 00035: accuracy did not improve from 0.91983\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 0.2002 - accuracy: 0.9197 - recall: 0.9197 - f1: 0.9197\n",
      "Epoch 36/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9220 - recall: 0.9223 - f1: 0.9221\n",
      "Epoch 00036: accuracy improved from 0.91983 to 0.92217, saving model to Unet64_batch_relu_dropout_noVal-036-0.922181.h5\n",
      "150/150 [==============================] - 47s 316ms/step - loss: 0.1903 - accuracy: 0.9222 - recall: 0.9224 - f1: 0.9222\n",
      "Epoch 37/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1931 - accuracy: 0.9228 - recall: 0.9232 - f1: 0.9228\n",
      "Epoch 00037: accuracy improved from 0.92217 to 0.92287, saving model to Unet64_batch_relu_dropout_noVal-037-0.922896.h5\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 0.1929 - accuracy: 0.9229 - recall: 0.9232 - f1: 0.9229\n",
      "Epoch 38/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1954 - accuracy: 0.9211 - recall: 0.9216 - f1: 0.9212\n",
      "Epoch 00038: accuracy did not improve from 0.92287\n",
      "150/150 [==============================] - 46s 307ms/step - loss: 0.1951 - accuracy: 0.9213 - recall: 0.9218 - f1: 0.9214\n",
      "Epoch 39/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9226 - recall: 0.9228 - f1: 0.9226\n",
      "Epoch 00039: accuracy did not improve from 0.92287\n",
      "150/150 [==============================] - 48s 317ms/step - loss: 0.1890 - accuracy: 0.9227 - recall: 0.9230 - f1: 0.9227\n",
      "Epoch 40/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.9203 - recall: 0.9210 - f1: 0.9204\n",
      "Epoch 00040: accuracy did not improve from 0.92287\n",
      "150/150 [==============================] - 46s 310ms/step - loss: 0.1897 - accuracy: 0.9205 - recall: 0.9211 - f1: 0.9205\n",
      "Epoch 41/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9212 - recall: 0.9207 - f1: 0.9212\n",
      "Epoch 00041: accuracy did not improve from 0.92287\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "150/150 [==============================] - 48s 318ms/step - loss: 0.1966 - accuracy: 0.9214 - recall: 0.9209 - f1: 0.9213\n",
      "Epoch 42/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1759 - accuracy: 0.9288 - recall: 0.9284 - f1: 0.9287\n",
      "Epoch 00042: accuracy improved from 0.92287 to 0.92883, saving model to Unet64_batch_relu_dropout_noVal-042-0.928805.h5\n",
      "150/150 [==============================] - 47s 313ms/step - loss: 0.1758 - accuracy: 0.9288 - recall: 0.9285 - f1: 0.9288\n",
      "Epoch 43/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9288 - recall: 0.9287 - f1: 0.9288\n",
      "Epoch 00043: accuracy did not improve from 0.92883\n",
      "150/150 [==============================] - 50s 332ms/step - loss: 0.1742 - accuracy: 0.9287 - recall: 0.9285 - f1: 0.9286\n",
      "Epoch 44/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9305 - recall: 0.9305 - f1: 0.9305\n",
      "Epoch 00044: accuracy improved from 0.92883 to 0.93063, saving model to Unet64_batch_relu_dropout_noVal-044-0.930631.h5\n",
      "150/150 [==============================] - 53s 356ms/step - loss: 0.1699 - accuracy: 0.9306 - recall: 0.9306 - f1: 0.9306\n",
      "Epoch 45/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9298 - recall: 0.9298 - f1: 0.9298\n",
      "Epoch 00045: accuracy did not improve from 0.93063\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.1744 - accuracy: 0.9299 - recall: 0.9299 - f1: 0.9299\n",
      "Epoch 46/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9351 - recall: 0.9352 - f1: 0.9351\n",
      "Epoch 00046: accuracy improved from 0.93063 to 0.93490, saving model to Unet64_batch_relu_dropout_noVal-046-0.934908.h5\n",
      "150/150 [==============================] - 58s 385ms/step - loss: 0.1660 - accuracy: 0.9349 - recall: 0.9350 - f1: 0.9349\n",
      "Epoch 47/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9315 - recall: 0.9317 - f1: 0.9316\n",
      "Epoch 00047: accuracy did not improve from 0.93490\n",
      "150/150 [==============================] - 58s 389ms/step - loss: 0.1692 - accuracy: 0.9313 - recall: 0.9315 - f1: 0.9313\n",
      "Epoch 48/200\n",
      " 12/150 [=>............................] - ETA: 44s - loss: 0.1669 - accuracy: 0.9321 - recall: 0.9325 - f1: 0.9321Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1629 - accuracy: 0.9327 - recall: 0.9329 - f1: 0.9327\n",
      "Epoch 00048: accuracy did not improve from 0.93490\n",
      "150/150 [==============================] - 56s 372ms/step - loss: 0.1626 - accuracy: 0.9328 - recall: 0.9330 - f1: 0.9328\n",
      "Epoch 49/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9346 - recall: 0.9345 - f1: 0.9346\n",
      "Epoch 00049: accuracy did not improve from 0.93490\n",
      "150/150 [==============================] - 46s 308ms/step - loss: 0.1646 - accuracy: 0.9347 - recall: 0.9347 - f1: 0.9347\n",
      "Epoch 50/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9344 - recall: 0.9342 - f1: 0.9343\n",
      "Epoch 00050: accuracy did not improve from 0.93490\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1626 - accuracy: 0.9345 - recall: 0.9344 - f1: 0.9345\n",
      "Epoch 51/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9331 - recall: 0.9326 - f1: 0.9331\n",
      "Epoch 00051: accuracy did not improve from 0.93490\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1618 - accuracy: 0.9329 - recall: 0.9325 - f1: 0.9329\n",
      "Epoch 52/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 0.9326 - recall: 0.9323 - f1: 0.9325\n",
      "Epoch 00052: accuracy did not improve from 0.93490\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1636 - accuracy: 0.9325 - recall: 0.9322 - f1: 0.9325\n",
      "Epoch 53/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9386 - recall: 0.9381 - f1: 0.9386\n",
      "Epoch 00053: accuracy improved from 0.93490 to 0.93843, saving model to Unet64_batch_relu_dropout_noVal-053-0.938398.h5\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1517 - accuracy: 0.9384 - recall: 0.9379 - f1: 0.9384\n",
      "Epoch 54/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9387 - recall: 0.9383 - f1: 0.9387\n",
      "Epoch 00054: accuracy improved from 0.93843 to 0.93870, saving model to Unet64_batch_relu_dropout_noVal-054-0.938677.h5\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.1528 - accuracy: 0.9387 - recall: 0.9383 - f1: 0.9387\n",
      "Epoch 55/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9384 - recall: 0.9381 - f1: 0.9383\n",
      "Epoch 00055: accuracy did not improve from 0.93870\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1500 - accuracy: 0.9386 - recall: 0.9384 - f1: 0.9386\n",
      "Epoch 56/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9386 - recall: 0.9386 - f1: 0.9386\n",
      "Epoch 00056: accuracy did not improve from 0.93870\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1539 - accuracy: 0.9382 - recall: 0.9382 - f1: 0.9382\n",
      "Epoch 57/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9398 - recall: 0.9400 - f1: 0.9398\n",
      "Epoch 00057: accuracy improved from 0.93870 to 0.94017, saving model to Unet64_batch_relu_dropout_noVal-057-0.940176.h5\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1492 - accuracy: 0.9402 - recall: 0.9403 - f1: 0.9402\n",
      "Epoch 58/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9367 - recall: 0.9364 - f1: 0.9367\n",
      "Epoch 00058: accuracy did not improve from 0.94017\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1567 - accuracy: 0.9366 - recall: 0.9363 - f1: 0.9366\n",
      "Epoch 59/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1533 - accuracy: 0.9385 - recall: 0.9385 - f1: 0.9385\n",
      "Epoch 00059: accuracy did not improve from 0.94017\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1537 - accuracy: 0.9383 - recall: 0.9383 - f1: 0.9383\n",
      "Epoch 60/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9401 - recall: 0.9400 - f1: 0.9401\n",
      "Epoch 00060: accuracy improved from 0.94017 to 0.94027, saving model to Unet64_batch_relu_dropout_noVal-060-0.940260.h5\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1495 - accuracy: 0.9403 - recall: 0.9401 - f1: 0.9403\n",
      "Epoch 61/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.9362 - recall: 0.9357 - f1: 0.9361\n",
      "Epoch 00061: accuracy did not improve from 0.94027\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1572 - accuracy: 0.9363 - recall: 0.9358 - f1: 0.9362\n",
      "Epoch 62/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9409 - recall: 0.9409 - f1: 0.9409\n",
      "Epoch 00062: accuracy improved from 0.94027 to 0.94113, saving model to Unet64_batch_relu_dropout_noVal-062-0.941129.h5\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.1495 - accuracy: 0.9411 - recall: 0.9411 - f1: 0.9411\n",
      "Epoch 63/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9397 - recall: 0.9395 - f1: 0.9397\n",
      "Epoch 00063: accuracy did not improve from 0.94113\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1506 - accuracy: 0.9395 - recall: 0.9393 - f1: 0.9395\n",
      "Epoch 64/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9433 - recall: 0.9432 - f1: 0.9433\n",
      "Epoch 00064: accuracy improved from 0.94113 to 0.94323, saving model to Unet64_batch_relu_dropout_noVal-064-0.943226.h5\n",
      "150/150 [==============================] - 43s 290ms/step - loss: 0.1434 - accuracy: 0.9432 - recall: 0.9431 - f1: 0.9432\n",
      "Epoch 65/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9407 - recall: 0.9403 - f1: 0.9407\n",
      "Epoch 00065: accuracy did not improve from 0.94323\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1488 - accuracy: 0.9408 - recall: 0.9404 - f1: 0.9408\n",
      "Epoch 66/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9374 - recall: 0.9372 - f1: 0.9374\n",
      "Epoch 00066: accuracy did not improve from 0.94323\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.1512 - accuracy: 0.9371 - recall: 0.9369 - f1: 0.9371\n",
      "Epoch 67/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9419 - recall: 0.9417 - f1: 0.9419\n",
      "Epoch 00067: accuracy did not improve from 0.94323\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1439 - accuracy: 0.9418 - recall: 0.9415 - f1: 0.9418\n",
      "Epoch 68/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9368 - recall: 0.9370 - f1: 0.9368\n",
      "Epoch 00068: accuracy did not improve from 0.94323\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1535 - accuracy: 0.9367 - recall: 0.9369 - f1: 0.9367\n",
      "Epoch 69/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.9440 - recall: 0.9437 - f1: 0.9439\n",
      "Epoch 00069: accuracy improved from 0.94323 to 0.94380, saving model to Unet64_batch_relu_dropout_noVal-069-0.943783.h5\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1432 - accuracy: 0.9438 - recall: 0.9435 - f1: 0.9438\n",
      "Epoch 70/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9434 - recall: 0.9434 - f1: 0.9434\n",
      "Epoch 00070: accuracy did not improve from 0.94380\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1400 - accuracy: 0.9432 - recall: 0.9432 - f1: 0.9432\n",
      "Epoch 71/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9411 - recall: 0.9409 - f1: 0.9411\n",
      "Epoch 00071: accuracy did not improve from 0.94380\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1440 - accuracy: 0.9409 - recall: 0.9408 - f1: 0.9409\n",
      "Epoch 72/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1429 - accuracy: 0.9429 - recall: 0.9426 - f1: 0.9429\n",
      "Epoch 00072: accuracy did not improve from 0.94380\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1426 - accuracy: 0.9429 - recall: 0.9426 - f1: 0.9429\n",
      "Epoch 73/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9446 - recall: 0.9446 - f1: 0.9446\n",
      "Epoch 00073: accuracy improved from 0.94380 to 0.94430, saving model to Unet64_batch_relu_dropout_noVal-073-0.944305.h5\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1406 - accuracy: 0.9443 - recall: 0.9443 - f1: 0.9443\n",
      "Epoch 74/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9387 - recall: 0.9386 - f1: 0.9386\n",
      "Epoch 00074: accuracy did not improve from 0.94430\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1493 - accuracy: 0.9387 - recall: 0.9386 - f1: 0.9387\n",
      "Epoch 75/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9405 - recall: 0.9406 - f1: 0.9405\n",
      "Epoch 00075: accuracy did not improve from 0.94430\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1462 - accuracy: 0.9406 - recall: 0.9407 - f1: 0.9406\n",
      "Epoch 76/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9405 - recall: 0.9404 - f1: 0.9405\n",
      "Epoch 00076: accuracy did not improve from 0.94430\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1436 - accuracy: 0.9406 - recall: 0.9405 - f1: 0.9406\n",
      "Epoch 77/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9435 - recall: 0.9431 - f1: 0.9434\n",
      "Epoch 00077: accuracy did not improve from 0.94430\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1370 - accuracy: 0.9434 - recall: 0.9431 - f1: 0.9434\n",
      "Epoch 78/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 0.9439 - recall: 0.9438 - f1: 0.9439\n",
      "Epoch 00078: accuracy did not improve from 0.94430\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.1396 - accuracy: 0.9439 - recall: 0.9438 - f1: 0.9439\n",
      "Epoch 79/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1381 - accuracy: 0.9436 - recall: 0.9434 - f1: 0.9435\n",
      "Epoch 00079: accuracy did not improve from 0.94430\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1380 - accuracy: 0.9436 - recall: 0.9434 - f1: 0.9436\n",
      "Epoch 80/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1396 - accuracy: 0.9415 - recall: 0.9412 - f1: 0.9415\n",
      "Epoch 00080: accuracy did not improve from 0.94430\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1398 - accuracy: 0.9415 - recall: 0.9411 - f1: 0.9414\n",
      "Epoch 81/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.9437 - recall: 0.9438 - f1: 0.9437\n",
      "Epoch 00081: accuracy did not improve from 0.94430\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1349 - accuracy: 0.9433 - recall: 0.9434 - f1: 0.9433\n",
      "Epoch 82/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9457 - recall: 0.9454 - f1: 0.9457\n",
      "Epoch 00082: accuracy improved from 0.94430 to 0.94590, saving model to Unet64_batch_relu_dropout_noVal-082-0.945882.h5\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1285 - accuracy: 0.9459 - recall: 0.9455 - f1: 0.9459\n",
      "Epoch 83/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.9438 - recall: 0.9437 - f1: 0.9438\n",
      "Epoch 00083: accuracy did not improve from 0.94590\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1386 - accuracy: 0.9440 - recall: 0.9439 - f1: 0.9440\n",
      "Epoch 84/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9436 - recall: 0.9435 - f1: 0.9436\n",
      "Epoch 00084: accuracy did not improve from 0.94590\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1379 - accuracy: 0.9435 - recall: 0.9433 - f1: 0.9435\n",
      "Epoch 85/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.9443 - recall: 0.9442 - f1: 0.9443\n",
      "Epoch 00085: accuracy did not improve from 0.94590\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1337 - accuracy: 0.9446 - recall: 0.9445 - f1: 0.9446\n",
      "Epoch 86/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9443 - recall: 0.9440 - f1: 0.9443\n",
      "Epoch 00086: accuracy did not improve from 0.94590\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.1406 - accuracy: 0.9443 - recall: 0.9441 - f1: 0.9443\n",
      "Epoch 87/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9464 - recall: 0.9466 - f1: 0.9465\n",
      "Epoch 00087: accuracy improved from 0.94590 to 0.94640, saving model to Unet64_batch_relu_dropout_noVal-087-0.946408.h5\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1358 - accuracy: 0.9464 - recall: 0.9466 - f1: 0.9464\n",
      "Epoch 88/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.9461 - recall: 0.9462 - f1: 0.9461\n",
      "Epoch 00088: accuracy did not improve from 0.94640\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1340 - accuracy: 0.9460 - recall: 0.9461 - f1: 0.9460\n",
      "Epoch 89/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9503 - recall: 0.9503 - f1: 0.9503\n",
      "Epoch 00089: accuracy improved from 0.94640 to 0.95027, saving model to Unet64_batch_relu_dropout_noVal-089-0.950261.h5\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1265 - accuracy: 0.9503 - recall: 0.9502 - f1: 0.9503\n",
      "Epoch 90/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 0.9467 - recall: 0.9467 - f1: 0.9467\n",
      "Epoch 00090: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1325 - accuracy: 0.9470 - recall: 0.9470 - f1: 0.9470\n",
      "Epoch 91/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9488 - recall: 0.9488 - f1: 0.9488\n",
      "Epoch 00091: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1280 - accuracy: 0.9487 - recall: 0.9487 - f1: 0.9487\n",
      "Epoch 92/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 0.9459 - recall: 0.9458 - f1: 0.9459\n",
      "Epoch 00092: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1355 - accuracy: 0.9458 - recall: 0.9457 - f1: 0.9458\n",
      "Epoch 93/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9425 - recall: 0.9426 - f1: 0.9425\n",
      "Epoch 00093: accuracy did not improve from 0.95027\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.1393 - accuracy: 0.9427 - recall: 0.9428 - f1: 0.9427\n",
      "Epoch 94/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9474 - recall: 0.9474 - f1: 0.9474\n",
      "Epoch 00094: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1282 - accuracy: 0.9474 - recall: 0.9475 - f1: 0.9474\n",
      "Epoch 95/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1329 - accuracy: 0.9469 - recall: 0.9466 - f1: 0.9469\n",
      "Epoch 00095: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1334 - accuracy: 0.9468 - recall: 0.9465 - f1: 0.9468\n",
      "Epoch 96/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9450 - recall: 0.9450 - f1: 0.9450\n",
      "Epoch 00096: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1328 - accuracy: 0.9450 - recall: 0.9450 - f1: 0.9450\n",
      "Epoch 97/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9447 - recall: 0.9443 - f1: 0.9447\n",
      "Epoch 00097: accuracy did not improve from 0.95027\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1360 - accuracy: 0.9449 - recall: 0.9445 - f1: 0.9449\n",
      "Epoch 98/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9422 - recall: 0.9422 - f1: 0.9422\n",
      "Epoch 00098: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.1382 - accuracy: 0.9421 - recall: 0.9421 - f1: 0.9421\n",
      "Epoch 99/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9462 - recall: 0.9460 - f1: 0.9462\n",
      "Epoch 00099: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1332 - accuracy: 0.9464 - recall: 0.9461 - f1: 0.9463\n",
      "Epoch 100/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1431 - accuracy: 0.9420 - recall: 0.9422 - f1: 0.9421\n",
      "Epoch 00100: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.1436 - accuracy: 0.9419 - recall: 0.9421 - f1: 0.9419\n",
      "Epoch 101/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1365 - accuracy: 0.9431 - recall: 0.9430 - f1: 0.9431\n",
      "Epoch 00101: accuracy did not improve from 0.95027\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1363 - accuracy: 0.9432 - recall: 0.9431 - f1: 0.9432\n",
      "Epoch 102/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.9451 - recall: 0.9449 - f1: 0.9451\n",
      "Epoch 00102: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1358 - accuracy: 0.9449 - recall: 0.9447 - f1: 0.9449\n",
      "Epoch 103/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9480 - recall: 0.9479 - f1: 0.9479\n",
      "Epoch 00103: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1279 - accuracy: 0.9480 - recall: 0.9479 - f1: 0.9480\n",
      "Epoch 104/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.9449 - recall: 0.9448 - f1: 0.9449\n",
      "Epoch 00104: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1347 - accuracy: 0.9447 - recall: 0.9446 - f1: 0.9447\n",
      "Epoch 105/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9453 - recall: 0.9453 - f1: 0.9453\n",
      "Epoch 00105: accuracy did not improve from 0.95027\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1308 - accuracy: 0.9451 - recall: 0.9451 - f1: 0.9451\n",
      "Epoch 106/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9416 - recall: 0.9419 - f1: 0.9417\n",
      "Epoch 00106: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1383 - accuracy: 0.9412 - recall: 0.9415 - f1: 0.9412\n",
      "Epoch 107/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 0.9450 - recall: 0.9450 - f1: 0.9450\n",
      "Epoch 00107: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.1340 - accuracy: 0.9451 - recall: 0.9451 - f1: 0.9451\n",
      "Epoch 108/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9472 - recall: 0.9470 - f1: 0.9472\n",
      "Epoch 00108: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1330 - accuracy: 0.9472 - recall: 0.9470 - f1: 0.9472\n",
      "Epoch 109/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.9453 - recall: 0.9452 - f1: 0.9453\n",
      "Epoch 00109: accuracy did not improve from 0.95027\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1338 - accuracy: 0.9454 - recall: 0.9453 - f1: 0.9454\n",
      "Epoch 110/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9445 - recall: 0.9444 - f1: 0.9445\n",
      "Epoch 00110: accuracy did not improve from 0.95027\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1372 - accuracy: 0.9442 - recall: 0.9442 - f1: 0.9442\n",
      "Epoch 111/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 0.9515 - recall: 0.9516 - f1: 0.9515\n",
      "Epoch 00111: accuracy improved from 0.95027 to 0.95160, saving model to Unet64_batch_relu_dropout_noVal-111-0.951604.h5\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.1250 - accuracy: 0.9516 - recall: 0.9517 - f1: 0.9516\n",
      "Epoch 112/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9449 - recall: 0.9446 - f1: 0.9449\n",
      "Epoch 00112: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.1358 - accuracy: 0.9451 - recall: 0.9449 - f1: 0.9451\n",
      "Epoch 113/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9430 - recall: 0.9430 - f1: 0.9430\n",
      "Epoch 00113: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1380 - accuracy: 0.9431 - recall: 0.9431 - f1: 0.9431\n",
      "Epoch 114/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9458 - recall: 0.9460 - f1: 0.9458\n",
      "Epoch 00114: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1363 - accuracy: 0.9458 - recall: 0.9460 - f1: 0.9458\n",
      "Epoch 115/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9457 - recall: 0.9458 - f1: 0.9457\n",
      "Epoch 00115: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1324 - accuracy: 0.9457 - recall: 0.9459 - f1: 0.9457\n",
      "Epoch 116/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9421 - recall: 0.9421 - f1: 0.9421\n",
      "Epoch 00116: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1374 - accuracy: 0.9422 - recall: 0.9421 - f1: 0.9422\n",
      "Epoch 117/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9439 - recall: 0.9439 - f1: 0.9439\n",
      "Epoch 00117: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1359 - accuracy: 0.9440 - recall: 0.9441 - f1: 0.9440\n",
      "Epoch 118/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9476 - recall: 0.9477 - f1: 0.9476\n",
      "Epoch 00118: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 44s 290ms/step - loss: 0.1305 - accuracy: 0.9477 - recall: 0.9479 - f1: 0.9477\n",
      "Epoch 119/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9452 - recall: 0.9452 - f1: 0.9452\n",
      "Epoch 00119: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1327 - accuracy: 0.9451 - recall: 0.9451 - f1: 0.9451\n",
      "Epoch 120/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9461 - recall: 0.9462 - f1: 0.9461\n",
      "Epoch 00120: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1322 - accuracy: 0.9461 - recall: 0.9461 - f1: 0.9461\n",
      "Epoch 121/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 0.9461 - recall: 0.9462 - f1: 0.9461\n",
      "Epoch 00121: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1313 - accuracy: 0.9462 - recall: 0.9463 - f1: 0.9462\n",
      "Epoch 122/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1344 - accuracy: 0.9451 - recall: 0.9447 - f1: 0.9450\n",
      "Epoch 00122: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1341 - accuracy: 0.9452 - recall: 0.9449 - f1: 0.9452\n",
      "Epoch 123/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9456 - recall: 0.9450 - f1: 0.9456\n",
      "Epoch 00123: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1366 - accuracy: 0.9456 - recall: 0.9451 - f1: 0.9456\n",
      "Epoch 124/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9451 - recall: 0.9450 - f1: 0.9451\n",
      "Epoch 00124: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1326 - accuracy: 0.9452 - recall: 0.9451 - f1: 0.9452\n",
      "Epoch 125/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 0.9419 - recall: 0.9418 - f1: 0.9419\n",
      "Epoch 00125: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1394 - accuracy: 0.9419 - recall: 0.9418 - f1: 0.9419\n",
      "Epoch 126/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1350 - accuracy: 0.9458 - recall: 0.9456 - f1: 0.9458\n",
      "Epoch 00126: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1352 - accuracy: 0.9457 - recall: 0.9455 - f1: 0.9457\n",
      "Epoch 127/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1356 - accuracy: 0.9449 - recall: 0.9449 - f1: 0.9449\n",
      "Epoch 00127: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1356 - accuracy: 0.9449 - recall: 0.9449 - f1: 0.9449\n",
      "Epoch 128/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9485 - recall: 0.9484 - f1: 0.9485\n",
      "Epoch 00128: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1298 - accuracy: 0.9486 - recall: 0.9485 - f1: 0.9486\n",
      "Epoch 129/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.9477 - recall: 0.9479 - f1: 0.9477\n",
      "Epoch 00129: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1300 - accuracy: 0.9474 - recall: 0.9477 - f1: 0.9474\n",
      "Epoch 130/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1316 - accuracy: 0.9481 - recall: 0.9481 - f1: 0.9481\n",
      "Epoch 00130: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1313 - accuracy: 0.9483 - recall: 0.9483 - f1: 0.9483\n",
      "Epoch 131/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9451 - recall: 0.9448 - f1: 0.9450\n",
      "Epoch 00131: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.1301 - accuracy: 0.9452 - recall: 0.9449 - f1: 0.9452\n",
      "Epoch 132/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9411 - recall: 0.9411 - f1: 0.9411\n",
      "Epoch 00132: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1413 - accuracy: 0.9411 - recall: 0.9412 - f1: 0.9411\n",
      "Epoch 133/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9482 - recall: 0.9477 - f1: 0.9481\n",
      "Epoch 00133: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1301 - accuracy: 0.9485 - recall: 0.9479 - f1: 0.9484\n",
      "Epoch 134/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9430 - recall: 0.9428 - f1: 0.9430\n",
      "Epoch 00134: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1374 - accuracy: 0.9429 - recall: 0.9427 - f1: 0.9429\n",
      "Epoch 135/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9455 - recall: 0.9458 - f1: 0.9455\n",
      "Epoch 00135: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1316 - accuracy: 0.9456 - recall: 0.9459 - f1: 0.9456\n",
      "Epoch 136/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1313 - accuracy: 0.9456 - recall: 0.9457 - f1: 0.9456\n",
      "Epoch 00136: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1312 - accuracy: 0.9457 - recall: 0.9458 - f1: 0.9457\n",
      "Epoch 137/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9445 - recall: 0.9446 - f1: 0.9445\n",
      "Epoch 00137: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1369 - accuracy: 0.9444 - recall: 0.9445 - f1: 0.9444\n",
      "Epoch 138/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9439 - recall: 0.9442 - f1: 0.9439\n",
      "Epoch 00138: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1396 - accuracy: 0.9442 - recall: 0.9445 - f1: 0.9442\n",
      "Epoch 139/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1302 - accuracy: 0.9476 - recall: 0.9477 - f1: 0.9476\n",
      "Epoch 00139: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1298 - accuracy: 0.9479 - recall: 0.9479 - f1: 0.9479\n",
      "Epoch 140/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9470 - recall: 0.9468 - f1: 0.9470\n",
      "Epoch 00140: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1320 - accuracy: 0.9468 - recall: 0.9466 - f1: 0.9468\n",
      "Epoch 141/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9463 - recall: 0.9462 - f1: 0.9463\n",
      "Epoch 00141: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1336 - accuracy: 0.9463 - recall: 0.9462 - f1: 0.9463\n",
      "Epoch 142/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.9450 - recall: 0.9452 - f1: 0.9450\n",
      "Epoch 00142: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1359 - accuracy: 0.9451 - recall: 0.9453 - f1: 0.9451\n",
      "Epoch 143/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9471 - recall: 0.9470 - f1: 0.9471\n",
      "Epoch 00143: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1288 - accuracy: 0.9472 - recall: 0.9471 - f1: 0.9472\n",
      "Epoch 144/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1343 - accuracy: 0.9462 - recall: 0.9464 - f1: 0.9463\n",
      "Epoch 00144: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1342 - accuracy: 0.9463 - recall: 0.9465 - f1: 0.9463\n",
      "Epoch 145/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9442 - recall: 0.9440 - f1: 0.9442\n",
      "Epoch 00145: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1359 - accuracy: 0.9442 - recall: 0.9441 - f1: 0.9442\n",
      "Epoch 146/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.9463 - recall: 0.9462 - f1: 0.9463\n",
      "Epoch 00146: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1346 - accuracy: 0.9462 - recall: 0.9462 - f1: 0.9462\n",
      "Epoch 147/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1416 - accuracy: 0.9404 - recall: 0.9401 - f1: 0.9403\n",
      "Epoch 00147: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1414 - accuracy: 0.9404 - recall: 0.9402 - f1: 0.9404\n",
      "Epoch 148/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9465 - recall: 0.9464 - f1: 0.9465\n",
      "Epoch 00148: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1304 - accuracy: 0.9465 - recall: 0.9465 - f1: 0.9465\n",
      "Epoch 149/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9455 - recall: 0.9456 - f1: 0.9455\n",
      "Epoch 00149: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1344 - accuracy: 0.9453 - recall: 0.9455 - f1: 0.9453\n",
      "Epoch 150/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1356 - accuracy: 0.9433 - recall: 0.9431 - f1: 0.9433\n",
      "Epoch 00150: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1358 - accuracy: 0.9431 - recall: 0.9429 - f1: 0.9431\n",
      "Epoch 151/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9466 - recall: 0.9466 - f1: 0.9466\n",
      "Epoch 00151: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1327 - accuracy: 0.9463 - recall: 0.9463 - f1: 0.9463\n",
      "Epoch 152/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 0.9442 - recall: 0.9442 - f1: 0.9442\n",
      "Epoch 00152: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1342 - accuracy: 0.9441 - recall: 0.9442 - f1: 0.9441\n",
      "Epoch 153/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1364 - accuracy: 0.9453 - recall: 0.9454 - f1: 0.9453\n",
      "Epoch 00153: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1362 - accuracy: 0.9454 - recall: 0.9455 - f1: 0.9454\n",
      "Epoch 154/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.9469 - recall: 0.9466 - f1: 0.9469\n",
      "Epoch 00154: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1324 - accuracy: 0.9466 - recall: 0.9464 - f1: 0.9466\n",
      "Epoch 155/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1356 - accuracy: 0.9439 - recall: 0.9440 - f1: 0.9439\n",
      "Epoch 00155: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1359 - accuracy: 0.9437 - recall: 0.9437 - f1: 0.9437\n",
      "Epoch 156/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 0.9456 - recall: 0.9460 - f1: 0.9457\n",
      "Epoch 00156: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1356 - accuracy: 0.9456 - recall: 0.9459 - f1: 0.9456\n",
      "Epoch 157/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9471 - recall: 0.9473 - f1: 0.9471\n",
      "Epoch 00157: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1295 - accuracy: 0.9473 - recall: 0.9475 - f1: 0.9473\n",
      "Epoch 158/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1329 - accuracy: 0.9467 - recall: 0.9466 - f1: 0.9467\n",
      "Epoch 00158: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1325 - accuracy: 0.9468 - recall: 0.9467 - f1: 0.9468\n",
      "Epoch 159/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.9440 - recall: 0.9439 - f1: 0.9440\n",
      "Epoch 00159: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1343 - accuracy: 0.9438 - recall: 0.9437 - f1: 0.9438\n",
      "Epoch 160/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9461 - recall: 0.9464 - f1: 0.9462\n",
      "Epoch 00160: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1362 - accuracy: 0.9457 - recall: 0.9460 - f1: 0.9457\n",
      "Epoch 161/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1288 - accuracy: 0.9467 - recall: 0.9468 - f1: 0.9467\n",
      "Epoch 00161: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.1288 - accuracy: 0.9467 - recall: 0.9468 - f1: 0.9467\n",
      "Epoch 162/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9472 - recall: 0.9471 - f1: 0.9472\n",
      "Epoch 00162: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1332 - accuracy: 0.9473 - recall: 0.9472 - f1: 0.9473\n",
      "Epoch 163/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.9448 - recall: 0.9447 - f1: 0.9448\n",
      "Epoch 00163: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.1354 - accuracy: 0.9446 - recall: 0.9445 - f1: 0.9446\n",
      "Epoch 164/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9458 - recall: 0.9458 - f1: 0.9458\n",
      "Epoch 00164: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1321 - accuracy: 0.9459 - recall: 0.9459 - f1: 0.9459\n",
      "Epoch 165/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9454 - recall: 0.9451 - f1: 0.9454\n",
      "Epoch 00165: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.1364 - accuracy: 0.9457 - recall: 0.9454 - f1: 0.9457\n",
      "Epoch 166/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9450 - recall: 0.9446 - f1: 0.9450\n",
      "Epoch 00166: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.1306 - accuracy: 0.9450 - recall: 0.9445 - f1: 0.9449\n",
      "Epoch 167/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1288 - accuracy: 0.9490 - recall: 0.9486 - f1: 0.9490\n",
      "Epoch 00167: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1294 - accuracy: 0.9488 - recall: 0.9484 - f1: 0.9488\n",
      "Epoch 168/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9466 - recall: 0.9467 - f1: 0.9466\n",
      "Epoch 00168: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1320 - accuracy: 0.9465 - recall: 0.9466 - f1: 0.9465\n",
      "Epoch 169/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1385 - accuracy: 0.9455 - recall: 0.9454 - f1: 0.9455\n",
      "Epoch 00169: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1380 - accuracy: 0.9457 - recall: 0.9457 - f1: 0.9457\n",
      "Epoch 170/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1314 - accuracy: 0.9469 - recall: 0.9470 - f1: 0.9469\n",
      "Epoch 00170: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.1313 - accuracy: 0.9470 - recall: 0.9471 - f1: 0.9470\n",
      "Epoch 171/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9466 - recall: 0.9466 - f1: 0.9466\n",
      "Epoch 00171: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.1310 - accuracy: 0.9468 - recall: 0.9468 - f1: 0.9468\n",
      "Epoch 172/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9469 - recall: 0.9470 - f1: 0.9469\n",
      "Epoch 00172: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.1310 - accuracy: 0.9471 - recall: 0.9472 - f1: 0.9471\n",
      "Epoch 173/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1400 - accuracy: 0.9424 - recall: 0.9426 - f1: 0.9424\n",
      "Epoch 00173: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.1402 - accuracy: 0.9424 - recall: 0.9425 - f1: 0.9424\n",
      "Epoch 174/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9419 - recall: 0.9418 - f1: 0.9419\n",
      "Epoch 00174: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1433 - accuracy: 0.9419 - recall: 0.9418 - f1: 0.9419\n",
      "Epoch 175/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9431 - recall: 0.9430 - f1: 0.9431\n",
      "Epoch 00175: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 7.450580950807417e-12.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1366 - accuracy: 0.9434 - recall: 0.9432 - f1: 0.9434\n",
      "Epoch 176/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9439 - recall: 0.9440 - f1: 0.9439\n",
      "Epoch 00176: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1374 - accuracy: 0.9438 - recall: 0.9438 - f1: 0.9438\n",
      "Epoch 177/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.9446 - recall: 0.9444 - f1: 0.9446\n",
      "Epoch 00177: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1338 - accuracy: 0.9447 - recall: 0.9445 - f1: 0.9447\n",
      "Epoch 178/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9440 - recall: 0.9438 - f1: 0.9440\n",
      "Epoch 00178: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1347 - accuracy: 0.9441 - recall: 0.9439 - f1: 0.9441\n",
      "Epoch 179/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9437 - recall: 0.9440 - f1: 0.9437\n",
      "Epoch 00179: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 3.725290475403709e-12.\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1341 - accuracy: 0.9437 - recall: 0.9439 - f1: 0.9437\n",
      "Epoch 180/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9454 - recall: 0.9454 - f1: 0.9454\n",
      "Epoch 00180: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1316 - accuracy: 0.9456 - recall: 0.9456 - f1: 0.9456\n",
      "Epoch 181/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9448 - recall: 0.9452 - f1: 0.9448\n",
      "Epoch 00181: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1321 - accuracy: 0.9448 - recall: 0.9452 - f1: 0.9448\n",
      "Epoch 182/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9451 - recall: 0.9450 - f1: 0.9451\n",
      "Epoch 00182: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1381 - accuracy: 0.9450 - recall: 0.9450 - f1: 0.9450\n",
      "Epoch 183/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9479 - recall: 0.9478 - f1: 0.9479\n",
      "Epoch 00183: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.8626452377018543e-12.\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1307 - accuracy: 0.9479 - recall: 0.9478 - f1: 0.9479\n",
      "Epoch 184/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 0.9449 - recall: 0.9446 - f1: 0.9449\n",
      "Epoch 00184: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1300 - accuracy: 0.9450 - recall: 0.9448 - f1: 0.9450\n",
      "Epoch 185/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9451 - recall: 0.9451 - f1: 0.9451\n",
      "Epoch 00185: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1307 - accuracy: 0.9451 - recall: 0.9450 - f1: 0.9451\n",
      "Epoch 186/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9467 - recall: 0.9472 - f1: 0.9468\n",
      "Epoch 00186: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1334 - accuracy: 0.9470 - recall: 0.9475 - f1: 0.9471\n",
      "Epoch 187/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9432 - recall: 0.9430 - f1: 0.9432\n",
      "Epoch 00187: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.313226188509272e-13.\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1370 - accuracy: 0.9434 - recall: 0.9432 - f1: 0.9433\n",
      "Epoch 188/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.9439 - recall: 0.9434 - f1: 0.9439\n",
      "Epoch 00188: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1384 - accuracy: 0.9439 - recall: 0.9434 - f1: 0.9439\n",
      "Epoch 189/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9442 - recall: 0.9441 - f1: 0.9442\n",
      "Epoch 00189: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1352 - accuracy: 0.9444 - recall: 0.9443 - f1: 0.9444\n",
      "Epoch 190/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 0.9483 - recall: 0.9483 - f1: 0.9483\n",
      "Epoch 00190: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1280 - accuracy: 0.9485 - recall: 0.9485 - f1: 0.9485\n",
      "Epoch 191/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9454 - recall: 0.9455 - f1: 0.9454\n",
      "Epoch 00191: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 4.656613094254636e-13.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1365 - accuracy: 0.9454 - recall: 0.9455 - f1: 0.9454\n",
      "Epoch 192/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9459 - recall: 0.9459 - f1: 0.9459\n",
      "Epoch 00192: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1286 - accuracy: 0.9459 - recall: 0.9458 - f1: 0.9459\n",
      "Epoch 193/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9440 - recall: 0.9439 - f1: 0.9440\n",
      "Epoch 00193: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1335 - accuracy: 0.9443 - recall: 0.9441 - f1: 0.9443\n",
      "Epoch 194/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9464 - recall: 0.9463 - f1: 0.9464\n",
      "Epoch 00194: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1349 - accuracy: 0.9463 - recall: 0.9463 - f1: 0.9463\n",
      "Epoch 195/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.9486 - recall: 0.9485 - f1: 0.9486\n",
      "Epoch 00195: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 2.328306547127318e-13.\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.1305 - accuracy: 0.9487 - recall: 0.9486 - f1: 0.9487\n",
      "Epoch 196/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 0.9427 - recall: 0.9426 - f1: 0.9427\n",
      "Epoch 00196: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1339 - accuracy: 0.9427 - recall: 0.9427 - f1: 0.9427\n",
      "Epoch 197/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9435 - recall: 0.9437 - f1: 0.9435\n",
      "Epoch 00197: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1359 - accuracy: 0.9437 - recall: 0.9439 - f1: 0.9437\n",
      "Epoch 198/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9463 - recall: 0.9466 - f1: 0.9463\n",
      "Epoch 00198: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1324 - accuracy: 0.9463 - recall: 0.9466 - f1: 0.9463\n",
      "Epoch 199/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9444 - recall: 0.9442 - f1: 0.9444\n",
      "Epoch 00199: accuracy did not improve from 0.95160\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.164153273563659e-13.\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1376 - accuracy: 0.9442 - recall: 0.9440 - f1: 0.9442\n",
      "Epoch 200/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9461 - recall: 0.9462 - f1: 0.9462\n",
      "Epoch 00200: accuracy did not improve from 0.95160\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1303 - accuracy: 0.9462 - recall: 0.9462 - f1: 0.9462\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# We define the number of epochs and steps per epochs\n",
    "EPOCHS = 200\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(64, 64, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model\n",
    "history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"Unet64_batch_relu_dropout_noVal.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4194368   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 16,744,706\n",
      "Trainable params: 16,738,818\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4194368   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 16,744,706\n",
      "Trainable params: 16,738,818\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n",
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_distributed_function_9563 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_1/test_1.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_2/test_2.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_3/test_3.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_4/test_4.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_5/test_5.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_6/test_6.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_7/test_7.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_8/test_8.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_9/test_9.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_10/test_10.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_11/test_11.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_12/test_12.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_13/test_13.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_14/test_14.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_15/test_15.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_16/test_16.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_17/test_17.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_18/test_18.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_19/test_19.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_20/test_20.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_21/test_21.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_22/test_22.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_23/test_23.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_24/test_24.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_25/test_25.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_26/test_26.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_27/test_27.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_28/test_28.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_29/test_29.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_30/test_30.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_31/test_31.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_32/test_32.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_33/test_33.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_34/test_34.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_35/test_35.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_36/test_36.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_37/test_37.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_38/test_38.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_39/test_39.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_40/test_40.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_41/test_41.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_42/test_42.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_43/test_43.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_44/test_44.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_45/test_45.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_46/test_46.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_47/test_47.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_48/test_48.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_49/test_49.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_50/test_50.png\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(64, 64, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"Unet64_batch_relu_dropout_noVal-111-0.951604.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"Unet64_batch_relu_dropout_noVal-111-0.951604.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Increase regulrization parameters\n",
    "2. Increase dropout prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/training/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" groundtruth images\")\n",
    "gt_imgs = np.asarray([load_image(gt_dir + files[i]) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "\n",
    "# We separate the images from the groundtruth images\n",
    "img_patches = [img_crop(imgs[i], image_size, image_size) for i in range(n)]\n",
    "gt_patches = [img_crop(gt_imgs[i], image_size, image_size) for i in range(n)]\n",
    "\n",
    "# Linearize the list and labeling them X and Y\n",
    "X = np.asarray(\n",
    "    [\n",
    "        img_patches[i][j]\n",
    "        for i in range(len(img_patches))\n",
    "        for j in range(len(img_patches[i]))\n",
    "    ]\n",
    ")\n",
    "Y = np.asarray(\n",
    "    [\n",
    "        gt_patches[i][j]\n",
    "        for i in range(len(gt_patches))\n",
    "        for j in range(len(gt_patches[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch():\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 72\n",
    "    batch_size = 100\n",
    "    patch_size = 16\n",
    "    num_images = 100\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index represnting an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.2\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "            )\n",
    "\n",
    "            # The image augmentation is based on both flipping and rotating (randomly in steps of 45째)\n",
    "            # Random vertical and horizontal flip\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "            # Random rotation in steps of 45째\n",
    "            rotations = [0, 45, 90, 135, 180, 225, 270, 315, 350]\n",
    "\n",
    "            # We select a rotation degree randomly\n",
    "            rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "            # Rotate it using the random value (uses the scipy library)\n",
    "            sampled_image = scipy.ndimage.rotate(\n",
    "                sampled_image,\n",
    "                rotations[rotation_choice],\n",
    "                order=1,\n",
    "                reshape=False,\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL3, input_shape=shape, padding=\"same\"))\n",
    "        model.add(GaussianNoise(0.1))\n",
    "\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                128, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)\n",
    "            )\n",
    "        )\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.001, amsgrad=True),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"f1\", min_delta=0.5, patience=20, verbose=0, mode=\"max\"\n",
    "        )\n",
    "\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"f1\", factor=0.5, patience=4, verbose=0, mode=\"max\"\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"batch_relu_OLD_Ali_amsgrad_noise-{epoch:03d}-{f1:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"f1\",\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        callbacks = [lr_callback, save_best]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "    def save(self, filename):\n",
    "        # Save the model (used to then load to submit)\n",
    "        self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "EPOCHS = 120\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "model.save(\"batch_relu_OLD_Ali_amsgrad_noise.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_relu_OLD_Ali_amsgrad_noise.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"batch_relu_OLD_Ali_amsgrad_noise-092-0.952039.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu_OLD_Ali_amsgrad_noise-092-0.952039.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# We define the number of epochs and steps per epochs\n",
    "EPOCHS = 160\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model\n",
    "history = model.train()\n",
    "# model.save(\"no_batch_LeakyRelu_validation_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_160_dropout-0.2.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\n",
    "    \"saved_models/batch_LeakyReLU_validation_160_dropout-0.2-070-0.948567-0.928000.h5\"\n",
    ")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"to_submit_csv/batch_LeakyReLU_validation_160_dropout-0.2-070-0.948567-0.928000.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history.history[\"loss\"]\n",
    "# print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history[\"accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "# plt.title(\"model accuracy\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# N = EPOCHS\n",
    "# print(N)\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.show()\n",
    "# plt.savefig(\"model1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = False\n",
    "# EPOCHS = 200\n",
    "\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# model.train()\n",
    "# model.save(\"no_batch_relu_validation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = True\n",
    "# EPOCHS = 200\n",
    "\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# model.train()\n",
    "# model.save(\"batch_LeakyReLU_validation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 200\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_relu_validation_200.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"batch_relu_validation_200-145-0.951267-0.930033.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu_validation_200-145-0.951267-0.930033.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 160\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_160.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"batch_relu_validation_200-074-0.946167-0.927667.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu_validation_200-074-0.946167-0.927667.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW BATCH ERICK V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as scipy\n",
    "\n",
    "\n",
    "def pad_matrix(mat, h_pad, w_pad, val=0):\n",
    "    h_pad = int(h_pad)\n",
    "    w_pad = int(w_pad)\n",
    "    if len(mat.shape) == 3:\n",
    "        padded_mat = np.pad(\n",
    "            mat,\n",
    "            ((h_pad, h_pad), (w_pad, w_pad), (0, 0)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=((val, val), (val, val), (0, 0)),\n",
    "        )\n",
    "    elif len(mat.shape) == 2:\n",
    "        padded_mat = np.pad(\n",
    "            mat,\n",
    "            ((h_pad, h_pad), (w_pad, w_pad)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=((val, val), (val, val)),\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"This method can only handle 2d or 3d arrays\")\n",
    "    return padded_mat\n",
    "\n",
    "\n",
    "def imag_rotation(X, Y, number_rotations=8):\n",
    "\n",
    "    w = X.shape[1]\n",
    "    w_2 = w // 2  # half of the width\n",
    "    padding = 82\n",
    "    Xrs = X\n",
    "    Yrs = Y\n",
    "    Xrs = np.expand_dims(Xrs, 0)\n",
    "    Yrs = np.expand_dims(Yrs, 0)\n",
    "    thetas = np.random.randint(0, high=360, size=number_rotations)\n",
    "    for theta in thetas:\n",
    "        Xr = pad_matrix(\n",
    "            X, padding, padding\n",
    "        )  # Selected for the specific case of images of (400,400)\n",
    "        Yr = pad_matrix(\n",
    "            Y, padding, padding\n",
    "        )  # Selected for the specific case of images of (400,400)\n",
    "        Xr = scipy.ndimage.rotate(Xr, theta, reshape=False)\n",
    "        Yr = scipy.ndimage.rotate(Yr, theta, reshape=False)\n",
    "        theta = theta * np.pi / 180\n",
    "        a = int(\n",
    "            w_2 / (np.sqrt(2) * np.cos(np.pi / 4 - np.mod(theta, np.pi / 2)))\n",
    "        )  # width and height of the biggest square inside the rotated square\n",
    "        w_p = w_2 + padding\n",
    "        Xr = Xr[w_p - a : w_p + a, w_p - a : w_p + a, :]\n",
    "        Yr = Yr[w_p - a : w_p + a, w_p - a : w_p + a]\n",
    "\n",
    "        Xr = cv2.resize(Xr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "        Yr = cv2.resize(Yr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        if np.random.choice(2) == 1:\n",
    "            Xr = np.flipud(Xr)\n",
    "            Yr = np.flipud(Yr)\n",
    "\n",
    "        if np.random.choice(2) == 1:\n",
    "            Xr = np.fliplr(Xr)\n",
    "            Yr = np.fliplr(Yr)\n",
    "\n",
    "        Xr = np.expand_dims(Xr, 0)\n",
    "        Yr = np.expand_dims(Yr, 0)\n",
    "        Xrs = np.append(Xrs, Xr, axis=0)\n",
    "        Yrs = np.append(Yrs, Yr, axis=0)\n",
    "\n",
    "    return Xrs, Yrs\n",
    "\n",
    "\n",
    "def imag_rotation_aug(Xr, Yr, number_rotations=8):\n",
    "\n",
    "    Xrs, Yrs = imag_rotation(Xr[0], Yr[0])\n",
    "    for i in range(1, len(Xr)):\n",
    "        Xrr, Yrr = imag_rotation(Xr[i], Yr[i])\n",
    "        Xrs = np.append(Xrs, Xrr, axis=0)\n",
    "        Yrs = np.append(Yrs, Yrr, axis=0)\n",
    "\n",
    "    Xrs_shuf = []\n",
    "    Yrs_shuf = []\n",
    "    index_shuf = list(range(len(Xrs)))\n",
    "    np.random.shuffle(index_shuf)\n",
    "    for i in index_shuf:\n",
    "        Xrs_shuf.append(Xrs[i])\n",
    "        Yrs_shuf.append(Yrs[i])\n",
    "\n",
    "    return Xrs_shuf, Yrs_shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir_train = root_dir + \"training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n_train) + \" images\")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir_train = root_dir + \"training/groundtruth/\"\n",
    "print(\"Loading \" + str(n_train) + \" groundtruth images\")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the directory for the images and load them\n",
    "image_dir_val = root_dir + \"validating/images/\"\n",
    "files = os.listdir(image_dir_val)\n",
    "n_val = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n_val) + \" images\")\n",
    "imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir_val = root_dir + \"validating/groundtruth/\"\n",
    "print(\"Loading \" + str(n_val) + \" groundtruth images\")\n",
    "gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = imag_rotation_aug(imgs_train, gt_imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = imag_rotation_aug(imgs_val, gt_imgs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch(X, Y, n):\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 72\n",
    "    batch_size = 80\n",
    "    patch_size = 72\n",
    "    num_images = n\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index representing an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.2\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(128, kernel_regularizer=l2(0.0001), activity_regularizer=l2(0.0001))\n",
    "        )\n",
    "        #         if batch_normalization:\n",
    "        #             model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.0001), activity_regularizer=l2(0.0001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.001),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0,\n",
    "            patience=15,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"auto\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [save_best, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(X_train, Y_train, n_train * 9),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            validation_data=create_minibatch(X_val, Y_val, n_val * 9),\n",
    "            validation_steps=STEPS_PER_EPOCH,\n",
    "        )\n",
    "        #         to_plot = self.model.fit_generator(\n",
    "        #             create_minibatch(X_train, Y_train, n_train),\n",
    "        #             steps_per_epoch=100,\n",
    "        #             epochs=EPOCHS,\n",
    "        #             use_multiprocessing=False,\n",
    "        #             workers=1,\n",
    "        #             callbacks=callbacks,\n",
    "        #             verbose=1,\n",
    "        #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "        #             validation_steps=100,\n",
    "        #         )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 200\n",
    "# EPOCHS = 2\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_erickv7.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\n",
    "    \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-099-0.956417-0.907208.h5\"\n",
    ")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = (\n",
    "    \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-099-0.956417-0.907208.csv\"\n",
    ")\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(128, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001))\n",
    "        )\n",
    "        #         if batch_normalization:\n",
    "        #             model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.0005, amsgrad=True),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0,\n",
    "            patience=15,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_f1\",\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [save_best, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(X_train, Y_train, n_train * 9),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            validation_data=create_minibatch(X_val, Y_val, n_val * 9),\n",
    "            validation_steps=STEPS_PER_EPOCH,\n",
    "        )\n",
    "        #         to_plot = self.model.fit_generator(\n",
    "        #             create_minibatch(X_train, Y_train, n_train),\n",
    "        #             steps_per_epoch=100,\n",
    "        #             epochs=EPOCHS,\n",
    "        #             use_multiprocessing=False,\n",
    "        #             workers=1,\n",
    "        #             callbacks=callbacks,\n",
    "        #             verbose=1,\n",
    "        #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "        #             validation_steps=100,\n",
    "        #         )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 150\n",
    "# EPOCHS = 2\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"f1\"], label=\"train_f1\")\n",
    "plt.plot(history.history[\"val_f1\"], label=\"val_f1\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_erickv7_dropout0.5_adagram.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\n",
    "    \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-074-0.912500-0.858625.h5\"\n",
    ")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = (\n",
    "    \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-074-0.912500-0.858625.csv\"\n",
    ")\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
