{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 754524224365260630\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4937233203\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17516825909444208930\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "    \n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.image as mpimg\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os,sys\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper functions\n",
    "\n",
    "# def load_image(infilename):\n",
    "#     data = mpimg.imread(infilename)\n",
    "#     return data\n",
    "\n",
    "# def img_float_to_uint8(img):\n",
    "#     rimg = img - np.min(img)\n",
    "#     rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "#     return rimg\n",
    "\n",
    "# # Concatenate an image and its groundtruth\n",
    "# def concatenate_images(img, gt_img):\n",
    "#     nChannels = len(gt_img.shape)\n",
    "#     w = gt_img.shape[0]\n",
    "#     h = gt_img.shape[1]\n",
    "#     if nChannels == 3:\n",
    "#         cimg = np.concatenate((img, gt_img), axis=1)\n",
    "#     else:\n",
    "#         gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "#         gt_img8 = img_float_to_uint8(gt_img)          \n",
    "#         gt_img_3c[:,:,0] = gt_img8\n",
    "#         gt_img_3c[:,:,1] = gt_img8\n",
    "#         gt_img_3c[:,:,2] = gt_img8\n",
    "#         img8 = img_float_to_uint8(img)\n",
    "#         cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "#     return cimg\n",
    "\n",
    "# def img_crop(im, w, h):\n",
    "#     list_patches = []\n",
    "#     imgwidth = im.shape[0]\n",
    "#     imgheight = im.shape[1]\n",
    "#     is_2d = len(im.shape) < 3\n",
    "#     for i in range(0,imgheight,h):\n",
    "#         for j in range(0,imgwidth,w):\n",
    "#             if is_2d:\n",
    "#                 im_patch = im[j:j+w, i:i+h]\n",
    "#             else:\n",
    "#                 im_patch = im[j:j+w, i:i+h, :]\n",
    "#             list_patches.append(im_patch)\n",
    "#     return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loaded a set of images\n",
    "# root_dir = \"data/training/\"\n",
    "\n",
    "# image_dir = root_dir + \"images/\"\n",
    "# files = os.listdir(image_dir)\n",
    "# n = min(20, len(files)) # Load maximum 20 images\n",
    "# print(\"Loading \" + str(n) + \" images\")\n",
    "# imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "# print(files[0])\n",
    "\n",
    "# gt_dir = root_dir + \"groundtruth/\"\n",
    "# print(\"Loading \" + str(n) + \" images\")\n",
    "# gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "# print(files[0])\n",
    "\n",
    "# n = 10 # Only use 10 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Image size = ' + str(imgs[0].shape[0]) + ',' + str(imgs[0].shape[1]))\n",
    "\n",
    "# # Show first image and its groundtruth image\n",
    "# cimg = concatenate_images(imgs[0], gt_imgs[0])\n",
    "# fig1 = plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(cimg, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract patches from input images\n",
    "# patch_size = 16 # each patch is 16*16 pixels\n",
    "\n",
    "# img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "# gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# # Linearize list of patches\n",
    "# img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "# gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract 6-dimensional features consisting of average RGB color as well as variance\n",
    "# def extract_features(img):\n",
    "#     feat_m = np.mean(img, axis=(0,1))\n",
    "#     feat_v = np.var(img, axis=(0,1))\n",
    "#     feat = np.append(feat_m, feat_v)\n",
    "#     return feat\n",
    "\n",
    "# # Extract 2-dimensional features consisting of average gray color as well as variance\n",
    "# def extract_features_2d(img):\n",
    "#     feat_m = np.mean(img)\n",
    "#     feat_v = np.var(img)\n",
    "#     feat = np.append(feat_m, feat_v)\n",
    "#     return feat\n",
    "\n",
    "# # Extract features for a given image\n",
    "# def extract_img_features(filename):\n",
    "#     img = load_image(filename)\n",
    "#     img_patches = img_crop(img, patch_size, patch_size)\n",
    "#     X = np.asarray([ extract_features_2d(img_patches[i]) for i in range(len(img_patches))])\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute features for each image patch\n",
    "# foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# def value_to_class(v):\n",
    "#     df = np.sum(v)\n",
    "#     if df > foreground_threshold:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# X = np.asarray([ extract_features_2d(img_patches[i]) for i in range(len(img_patches))])\n",
    "# Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print feature statistics\n",
    "\n",
    "# print('Computed ' + str(X.shape[0]) + ' features')\n",
    "# print('Feature dimension = ' + str(X.shape[1]))\n",
    "# print('Number of classes = ' + str(np.max(Y)))  #TODO: fix, length(unique(Y)) \n",
    "\n",
    "# Y0 = [i for i, j in enumerate(Y) if j == 0]\n",
    "# Y1 = [i for i, j in enumerate(Y) if j == 1]\n",
    "# print('Class 0: ' + str(len(Y0)) + ' samples')\n",
    "# print('Class 1: ' + str(len(Y1)) + ' samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display a patch that belongs to the foreground class\n",
    "# plt.imshow(gt_patches[Y1[3]], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot 2d features using groundtruth to color the datapoints\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train a logistic regression classifier\n",
    "\n",
    "# from sklearn import linear_model\n",
    "\n",
    "# # we create an instance of the classifier and fit the data\n",
    "# logreg = linear_model.LogisticRegression(C=1e5, class_weight=\"balanced\")\n",
    "# logreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the training set\n",
    "# Z = logreg.predict(X)\n",
    "\n",
    "# # Get non-zeros in prediction and grountruth arrays\n",
    "# Zn = np.nonzero(Z)[0]\n",
    "# Yn = np.nonzero(Y)[0]\n",
    "\n",
    "# TPR = len(list(set(Yn) & set(Zn))) / float(len(Z))\n",
    "# print('True positive rate = ' + str(TPR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot features using predictions to color datapoints\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=Z, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert array of labels to an image\n",
    "\n",
    "# def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "#     im = np.zeros([imgwidth, imgheight])\n",
    "#     idx = 0\n",
    "#     for i in range(0,imgheight,h):\n",
    "#         for j in range(0,imgwidth,w):\n",
    "#             im[j:j+w, i:i+h] = labels[idx]\n",
    "#             idx = idx + 1\n",
    "#     return im\n",
    "\n",
    "# def make_img_overlay(img, predicted_img):\n",
    "#     w = img.shape[0]\n",
    "#     h = img.shape[1]\n",
    "#     color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "#     color_mask[:,:,0] = predicted_img*255\n",
    "\n",
    "#     img8 = img_float_to_uint8(img)\n",
    "#     background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "#     overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "#     new_img = Image.blend(background, overlay, 0.2)\n",
    "#     return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run prediction on the img_idx-th image\n",
    "# img_idx = 12\n",
    "\n",
    "# Xi = extract_img_features(image_dir + files[img_idx])\n",
    "# Zi = logreg.predict(Xi)\n",
    "# plt.scatter(Xi[:, 0], Xi[:, 1], c=Zi, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display prediction as an image\n",
    "\n",
    "# w = gt_imgs[img_idx].shape[0]\n",
    "# h = gt_imgs[img_idx].shape[1]\n",
    "# predicted_im = label_to_img(w, h, patch_size, patch_size, Zi)\n",
    "# cimg = concatenate_images(imgs[img_idx], predicted_im)\n",
    "# fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "# plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "# new_img = make_img_overlay(imgs[img_idx], predicted_im)\n",
    "\n",
    "# plt.imshow(new_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #threshold function is disabled when resizing input images\n",
    "# path = \"data/training/groundtruth/satImage_\"\n",
    "# dim = (256, 256) #(w,h)\n",
    "\n",
    "# for i in range(1,101):\n",
    "#     if i < 10: \n",
    "#         image = cv2.imread(path + \"00\" + str(i) + \".png\", 0)\n",
    "#     elif i>=10 and i<100:\n",
    "#         image = cv2.imread(path + \"0\" + str(i) + \".png\", 0)\n",
    "#     else:\n",
    "#         image = cv2.imread(path + str(i) + \".png\", 0)\n",
    "        \n",
    "        \n",
    "#     resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "#     (thresh, im_bw) = cv2.threshold(resized, 128, 255, cv2.THRESH_BINARY)\n",
    "#     cv2.imwrite('mask_train/' + str(i) + '.png', im_bw)\n",
    "# #     print('mask_train/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"data/training/images/satImage_\"\n",
    "# dim = (256, 256) #(w,h)\n",
    "\n",
    "# for i in range(1,101):\n",
    "#     if i < 10: \n",
    "#         image = cv2.imread(path + \"00\" + str(i) + \".png\")\n",
    "#     elif i>=10 and i<100:\n",
    "#         image = cv2.imread(path + \"0\" + str(i) + \".png\")\n",
    "#     else:\n",
    "#         image = cv2.imread(path + str(i) + \".png\")\n",
    "        \n",
    "#     img = cv2.resize(image,dim,interpolation=cv2.INTER_AREA)\n",
    "#     cv2.imwrite('images_train/' + str(i) + '.png', img)\n",
    "\n",
    "# #     print('images_train/' + str(i) + '.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# masks = []\n",
    "# for i in range(1, 101):\n",
    "#     if i < 10: \n",
    "#         img = Image.open(\"data/training/images/satImage_\" + \"00\" + str(i) + \".png\")\n",
    "#     elif i>=10 and i<100:\n",
    "#         img = Image.open(\"data/training/images/satImage_\" + \"0\" + str(i) + \".png\")\n",
    "#     else:\n",
    "#         img = Image.open(\"data/training/images/satImage_\"  + str(i) + \".png\")\n",
    "\n",
    "#     print('Original Dimensions : ',image.shape)\n",
    "#     arr = np.array(img)\n",
    "#     images.append(arr)\n",
    "    \n",
    "# images = np.array(images)\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# masks = []\n",
    "# for i in range(1, 101):\n",
    "#     img = Image.open(\"images_train/\" + str(i) + \".png\")\n",
    "#     arr = np.array(img)\n",
    "#     images.append(arr)\n",
    "#     img = Image.open(\"mask_train/\" + str(i) + \".png\")\n",
    "#     arr = np.array(img)\n",
    "#     arr = np.expand_dims(arr, -1)\n",
    "#     masks.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = np.array(images)\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 101):\n",
    "#     if i < 10: \n",
    "#         img = Image.open(\"data/training/groundtruth/satImage_\" + \"00\" + str(i) + \".png\")\n",
    "#     elif i>=10 and i<100:\n",
    "#         img = Image.open(\"data/training/groundtruth/satImage_\" + \"0\" + str(i) + \".png\")\n",
    "#     else:\n",
    "#         img = Image.open(\"data/training/groundtruth/satImage_\"  + str(i) + \".png\")\n",
    "\n",
    "#     arr = np.array(img)\n",
    "#     arr = np.expand_dims(arr, -1)\n",
    "#     masks.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks = np.array(masks)\n",
    "# masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(\"Dataset_train.h5\", 'w') as hdf:\n",
    "#     hdf.create_dataset('images', data=images, compression='gzip', compression_opts=9)\n",
    "#     hdf.create_dataset('masks', data=masks, compression='gzip', compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np \n",
    "# import os\n",
    "# import cv2\n",
    "\n",
    "# from tensorflow.keras.models import *\n",
    "# from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.optimizers import *\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "# from tensorflow.keras import backend as keras\n",
    "\n",
    "# import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unet(input_size = (256, 256, 3)):\n",
    "#     inputs = Input(input_size)\n",
    "#     conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', \n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(inputs)\n",
    "    \n",
    "#     conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', \n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(conv1)\n",
    "    \n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "#     conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(pool1)\n",
    "    \n",
    "#     conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv2)\n",
    "    \n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "#     conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(pool2)\n",
    "    \n",
    "#     conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv3)\n",
    "    \n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "#     conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(pool3)\n",
    "    \n",
    "#     conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', \n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv4)\n",
    "    \n",
    "#     drop4 = Dropout(0.5)(conv4)\n",
    "    \n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "#     conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', \n",
    "#                                                  kernel_initializer = 'he_normal'\n",
    "#                                                  )(pool4)\n",
    "    \n",
    "#     conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', \n",
    "#                                                  kernel_initializer = 'he_normal'\n",
    "#                                                  )(conv5)\n",
    "    \n",
    "#     drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "#     up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', \n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(UpSampling2D(size = (2,2))(drop5))\n",
    "    \n",
    "#     merge6 = concatenate([drop4,up6])\n",
    "    \n",
    "#     conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(merge6)\n",
    "    \n",
    "#     conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv6)\n",
    "\n",
    "#     up7 = Conv2D(256, 2, activation = 'relu', padding = 'same',\n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(UpSampling2D(size = (2,2))(conv6))\n",
    "    \n",
    "#     merge7 = concatenate([conv3,up7])\n",
    "    \n",
    "#     conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(merge7)\n",
    "    \n",
    "#     conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv7)\n",
    "\n",
    "    \n",
    "#     up8 = Conv2D(128, 2, activation = 'relu', padding = 'same',\n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(UpSampling2D(size = (2,2))(conv7))\n",
    "    \n",
    "#     merge8 = concatenate([conv2,up8])\n",
    "    \n",
    "#     conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(merge8)\n",
    "    \n",
    "#     conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',\n",
    "#                                                 kernel_initializer = 'he_normal'\n",
    "#                                                 )(conv8)\n",
    "\n",
    "#     up9 = Conv2D(64, 2, activation = 'relu', padding = 'same',\n",
    "#                                              kernel_initializer = 'he_normal'\n",
    "#                                              )(UpSampling2D(size = (2,2))(conv8))\n",
    "    \n",
    "#     merge9 = concatenate([conv1,up9])\n",
    "    \n",
    "#     conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',\n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(merge9)\n",
    "    \n",
    "#     conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',\n",
    "#                                                kernel_initializer = 'he_normal'\n",
    "#                                                )(conv9)\n",
    "    \n",
    "#     conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same',\n",
    "#                                               kernel_initializer = 'he_normal'\n",
    "#                                               )(conv9)\n",
    "    \n",
    "#     conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "#     model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "#     model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print('*'*30)\n",
    "# print('Loading and preprocessing train data...')\n",
    "# print('*'*30)\n",
    "# file = h5py.File('Dataset_train.h5', 'r')\n",
    "# imgs_train = file.get('images')\n",
    "# imgs_mask_train = file.get('masks')\n",
    "# imgs_train = np.array(imgs_train)\n",
    "# imgs_mask_train = np.array(imgs_mask_train)\n",
    "\n",
    "# imgs_train = imgs_train.astype('float32')\n",
    "# mean = np.mean(imgs_train)  # mean for data centering\n",
    "# std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "# imgs_train -= mean\n",
    "# imgs_train /= std\n",
    "\n",
    "# imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "# imgs_mask_train /= 255  # scale masks to [0, 1]\n",
    "\n",
    "# print('*'*30)\n",
    "# print('Creating and compiling model...')\n",
    "# print('*'*30)\n",
    "# model = unet()\n",
    "# model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "# tensorboard = TensorBoard(log_dir='tensorboard/', write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_mask_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('*'*30)\n",
    "# print('Fitting model...')\n",
    "# print('*'*30)\n",
    "# with tf.device('/gpu:0'):\n",
    "#     history =  model.fit(imgs_train, imgs_mask_train, batch_size=10, verbose=1, epochs=10, shuffle=True,\n",
    "#               validation_split=0.2)\n",
    "# #               callbacks=[ModelCheckpoint, TensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = h5py.File('Dataset_test.h5', 'r')\n",
    "# imgs_test = file.get('images')\n",
    "# #imgs_mask_test = file.get('masks')\n",
    "# imgs_test = np.array(imgs_test)\n",
    "# #imgs_mask_test = np.array(imgs_mask_test)\n",
    "# imgs_test = imgs_test.astype('float32')\n",
    "# imgs_test -= mean\n",
    "# imgs_test /= std\n",
    "\n",
    "# print('*'*30)\n",
    "# print('Loading saved weights...')\n",
    "# print('*'*30)\n",
    "# model.load_weights('weights.h5')\n",
    "\n",
    "# print('*'*30)\n",
    "# print('Predicting masks on test data...')\n",
    "# print('*'*30)\n",
    "# imgs_mask_test = model.predict(imgs_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('*' * 30)\n",
    "# print('Saving predicted masks to files...')\n",
    "# print('*' * 30)\n",
    "# pred_dir = 'Preds2'\n",
    "# if not os.path.exists(pred_dir):\n",
    "#     os.mkdir(pred_dir)\n",
    "# for i, image in enumerate(imgs_mask_test):\n",
    "#     image = (image * 255).astype(np.uint8)\n",
    "#     cv2.imwrite(os.path.join(pred_dir, str(i + 1) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(60, 30))\n",
    "# plt.plot(history.history['loss'], linewidth=8, color='r')                   #visualising training and validation loss curves\n",
    "# plt.plot(history.history['val_loss'], linewidth=8, color='b')\n",
    "# plt.title('Model train vs Validation Loss', fontsize=100, fontweight=\"bold\")\n",
    "# plt.ylabel('Loss', fontsize=80)\n",
    "# plt.xlabel('Epoch', fontsize=80)\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right', fontsize=50)\n",
    "# plt.xticks(fontsize=60)\n",
    "# plt.yticks(fontsize=60)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# import os\n",
    "# import skimage.io as io\n",
    "# import skimage.transform as trans\n",
    "# import numpy as np\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# from tensorflow.keras.models import *\n",
    "# from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.optimizers import *\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "# from tensorflow.keras import backend as keras\n",
    "\n",
    "\n",
    "# def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "#     inputs = Input(input_size)\n",
    "#     conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "#     conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "#     conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "#     conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "#     conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "#     drop4 = Dropout(0.5)(conv4)\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "#     conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "#     conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "#     drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "#     up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "#     merge6 = concatenate([drop4,up6], axis = 3)\n",
    "#     conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "#     conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "#     up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "#     merge7 = concatenate([conv3,up7], axis = 3)\n",
    "#     conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "#     conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "#     up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "#     merge8 = concatenate([conv2,up8], axis = 3)\n",
    "#     conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "#     conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "#     up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "#     merge9 = concatenate([conv1,up9], axis = 3)\n",
    "#     conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "#     conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#     conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#     conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "#     model = Model(inputs = inputs, outputs = conv10)\n",
    "# #     model = Model()\n",
    "\n",
    "#     model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "#     #model.summary()\n",
    "\n",
    "#     if(pretrained_weights):\n",
    "#     \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import numpy as np \n",
    "# import os\n",
    "# import glob\n",
    "# import skimage.io as io\n",
    "# import skimage.transform as trans\n",
    "\n",
    "\n",
    "# def adjustData(img,gt):\n",
    "#     #make sure img value is between 0 and 1, and that mask is either 1 or 0\n",
    "#     if(np.max(img) > 1):\n",
    "#         img = img / 255\n",
    "#         gt = gt /255\n",
    "#         gt[gt > 0.5] = 1\n",
    "#         gt[gt <= 0.5] = 0\n",
    "#     return (img,gt)\n",
    "\n",
    "# def trainGenerator(batch_size,path,image_folder,gt_folder,augmentation_variables,save_to_dir = None,\n",
    "#                     target_size = (256,256),seed = 1):\n",
    "\n",
    "#     #create generators generating coresponding images using same seed, that will yield coresponding images\n",
    "#     image_generator = ImageDataGenerator(**augmentation_variables)\n",
    "#     gt_generator = ImageDataGenerator(**augmentation_variables)\n",
    "    \n",
    "# #     print(path)\n",
    "# #     print([image_folder])\n",
    "# #     print(gt_folder)\n",
    "#     image_generator = image_generator.flow_from_directory(\n",
    "#         path,\n",
    "#         classes = [image_folder],\n",
    "#         class_mode = None,\n",
    "#         color_mode = \"rgb\",\n",
    "#         target_size = target_size,\n",
    "#         batch_size = batch_size,\n",
    "#         save_to_dir = save_to_dir,\n",
    "#         seed = seed)\n",
    "    \n",
    "#     gt_generator = gt_generator.flow_from_directory(\n",
    "#         path,\n",
    "#         classes = [gt_folder],\n",
    "#         class_mode = None,\n",
    "#         color_mode = \"grayscale\",\n",
    "#         target_size = target_size,\n",
    "#         batch_size = batch_size,\n",
    "#         save_to_dir = save_to_dir,\n",
    "#         seed = seed)\n",
    "    \n",
    "#     #zip both generators into a shared generator\n",
    "#     train_generator = zip(image_generator, gt_generator)\n",
    "#     #adjust image values to be between 0 and 1, and gt images to be 0 or 1\n",
    "#     for (image,gt) in train_generator:\n",
    "#         image,gt = adjustData(image,gt)\n",
    "#         print(image.shape)\n",
    "#         yield (image,gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper functions\n",
    "\n",
    " \n",
    "# def img_float_to_uint8(img):\n",
    "#     rimg = img - np.min(img)\n",
    "#     rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "#     return rimg\n",
    "\n",
    "# # Concatenate an image and its groundtruth\n",
    "# def concatenate_images(img, gt_img):\n",
    "#     nChannels = len(gt_img.shape)\n",
    "#     w = gt_img.shape[0]\n",
    "#     h = gt_img.shape[1]\n",
    "#     if nChannels == 3:\n",
    "#         cimg = np.concatenate((img, gt_img), axis=1)\n",
    "#     else:\n",
    "#         gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "#         gt_img8 = img_float_to_uint8(gt_img)          \n",
    "#         gt_img_3c[:,:,0] = gt_img8\n",
    "#         gt_img_3c[:,:,1] = gt_img8\n",
    "#         gt_img_3c[:,:,2] = gt_img8\n",
    "#         img8 = img_float_to_uint8(img)\n",
    "#         cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "#     return cimg\n",
    "\n",
    "\n",
    "# # Extract 2-dimensional features consisting of average gray color as well as variance\n",
    "# def extract_features_2d(img):\n",
    "#     feat_m = np.mean(img)\n",
    "#     feat_v = np.var(img)\n",
    "#     feat = np.append(feat_m, feat_v)\n",
    "#     return feat\n",
    "\n",
    "# # Extract features for a given image\n",
    "# def extract_img_features(filename):\n",
    "#     img = load_image(filename)\n",
    "#     img_patches = img_crop(img, patch_size, patch_size)\n",
    "#     X = np.asarray([ extract_features_2d(img_patches[i]) for i in range(len(img_patches))])\n",
    "#     return X\n",
    "\n",
    "\n",
    "\n",
    "# def value_to_class(v, foreground_threshold):\n",
    "#     df = np.sum(v)\n",
    "#     if df > foreground_threshold:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# # Convert array of labels to an image\n",
    "\n",
    "# def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "#     im = np.zeros([imgwidth, imgheight])\n",
    "#     idx = 0\n",
    "#     for i in range(0,imgheight,h):\n",
    "#         for j in range(0,imgwidth,w):\n",
    "#             im[j:j+w, i:i+h] = labels[idx]\n",
    "#             idx = idx + 1\n",
    "#     return im\n",
    "\n",
    "# def make_img_overlay(img, predicted_img):\n",
    "#     w = img.shape[0]\n",
    "#     h = img.shape[1]\n",
    "#     color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "#     color_mask[:,:,0] = predicted_img*255\n",
    "\n",
    "#     img8 = img_float_to_uint8(img)\n",
    "#     background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "#     overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "#     new_img = Image.blend(background, overlay, 0.2)\n",
    "#     return new_img\n",
    "\n",
    "# #crop images into patches\n",
    "# def img_crop(im, w, h):\n",
    "#     list_patches = []\n",
    "#     imgwidth = im.shape[0]\n",
    "#     imgheight = im.shape[1]\n",
    "#     is_2d = len(im.shape) < 3\n",
    "#     print(im.shape)\n",
    "#     for i in range(0,imgheight,h):\n",
    "#         for j in range(0,imgwidth,w):\n",
    "#             if is_2d:\n",
    "#                 im_patch = im[j:j+w, i:i+h]\n",
    "#             else:\n",
    "#                 im_patch = im[j:j+w, i:i+h, :]\n",
    "#             list_patches.append(im_patch)\n",
    "#     return list_patches\n",
    "\n",
    "# def make_patches(imgs, w, h):\n",
    "#     # Extract patches from input images\n",
    "#     img_patches = [img_crop(imgs[i], w, h,) for i in range(len(imgs))]\n",
    "#     # Linearize list of patches\n",
    "#     #shape is 10*625 (10 images, cut up into 625 images with 16*16)\n",
    "#     img_patches=np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])    \n",
    "#     return img_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #this method is used in method beneath\n",
    "# def load_image(infilename):\n",
    "#     return mpimg.imread(infilename)\n",
    "\n",
    "# #method to load testing images\n",
    "# def load_test_images():\n",
    "#     root_dir = \"data/test_set_images/\"\n",
    "#     directory = root_dir\n",
    "#     # Get filenames and images for all the 50 submission images\n",
    "#     image_dir = [directory + \"test_{}/\".format(i) for i in range(1, 51)]\n",
    "#     filenames = [fn for imdir in image_dir for fn in os.listdir(imdir)]\n",
    "#     test_images = [load_image(image_dir[i] + filenames[i]) for i in range(0,50)]\n",
    "#     return test_images\n",
    "\n",
    "# #method to save predicted images\n",
    "# def save_result(save_path,npyfile):\n",
    "#     for i,item in enumerate(npyfile):\n",
    "#         img = item[:,:,0]\n",
    "#         io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "\n",
    "# #method used to make a deliverable csv file\n",
    "# def save_submission(final_pred, submission_filename, patch_size = 16):\n",
    "#     with open(submission_filename, 'w') as f:\n",
    "#         f.write('id,prediction\\n')\n",
    "#         for i in range(final_pred.shape[0]):\n",
    "#             for j in range(final_pred.shape[1]):\n",
    "#                 for k in range(final_pred.shape[2]):\n",
    "#                     name = '{:03d}_{}_{},{}'.format(i+1, j * patch_size, k * patch_size, int(final_pred[i,j,k]))\n",
    "#                     f.write(name + '\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os,sys\n",
    "# from PIL import Image\n",
    "\n",
    "# # from unet_model import *\n",
    "# # from image_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"data/training/groundtruth/satImage_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #using google drive to fetch images\n",
    "# # drive_dir = \"drive/My Drive/\"\n",
    "# train_dir = \"data/training/\"\n",
    "# weights_dir = \"data/weights/\"\n",
    "# image_folder = 'images'\n",
    "# gt_folder = 'groundtruth'\n",
    "# weights_filename ='weights.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator_variables = dict(rotation_range=90,\n",
    "#                            width_shift_range=0.4,\n",
    "#                            height_shift_range=0.4,\n",
    "#                            zoom_range=0.5,\n",
    "#                            horizontal_flip=True,\n",
    "#                            vertical_flip = True,\n",
    "#                            fill_mode='reflect')\n",
    "# batch_size = 2\n",
    "# steps_per_epoch = 10\n",
    "# epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = unet()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_dir + weights_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pending_train = True\n",
    "# if pending_train:\n",
    "#     train_generator = trainGenerator(batch_size,train_dir,image_folder,gt_folder,generator_variables)\n",
    "#     #add checkpoint to save \n",
    "#     checkpoint = ModelCheckpoint(weights_dir + weights_filename, monitor='loss', verbose=1, save_best_only=True)\n",
    "#     model.fit_generator(train_generator,steps_per_epoch=steps_per_epoch,epochs=epochs,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #treshold for setting a patch value to 1\n",
    "# foreground_treshold = 0.25\n",
    "# weights = 'weights.hdf5'\n",
    "# filename = \"predictions.csv\"\n",
    "# #Set to true if you want to save road predictions as image files\n",
    "# save_predicted_images = True\n",
    "# predict_path = \"prediction/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = unet()\n",
    "# model.load_weights(weights_dir + weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# test_imgs = load_test_images()\n",
    "# resized = []\n",
    "# dim = (256,256)\n",
    "# for im in test_imgs:\n",
    "#     resized.append(cv2.resize(im, dim, interpolation=cv2.INTER_AREA))\n",
    "# # resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_imgs = load_test_images()\n",
    "# # resized = []\n",
    "# # dim = (256,256)\n",
    "# # for im in test_imgs:\n",
    "# #     resized.append(cv2.resize(im, dim, interpolation=cv2.INTER_AREA))\n",
    "# # test_imgs = [x for x in test_imgs resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)]\n",
    "# # #make patches with the same size as original images\n",
    "# test_imgs = make_patches(resized, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_imgs.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #You may need to change this slice.\n",
    "# prediction = model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(save_predicted_images):\n",
    "#     save_result(predict_path,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #convert an image with predicted roads to patches\n",
    "# delivery = make_patches(prediction, 16,16)\n",
    "# #set patches to 1 or 0 based on mean color value\n",
    "# delivery = np.asarray([value_to_class(np.mean(delivery[i]), foreground_treshold) for i in range(len(delivery))])\n",
    "# #reshape in order to deliver\n",
    "# delivery = np.reshape(delivery, (-1,38,38))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALI IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential, load_model\n",
    "# from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import os\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "from helpers import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary for our model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# keras, model definition...\n",
    "cb = TQDMNotebookCallback()\n",
    "setattr(cb,'on_train_batch_begin',lambda x,y:None)\n",
    "setattr(cb,'on_train_batch_end',lambda x,y:None)\n",
    "\n",
    "# model.fit(X_train, Y_train, verbose=0, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "Loading 100 groundtruth images\n"
     ]
    }
   ],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/training/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files) \n",
    "\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" groundtruth images\")\n",
    "gt_imgs = np.asarray([load_image(gt_dir + files[i]) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "\n",
    "# We separate the images from the groundtruth images\n",
    "img_patches = [img_crop(imgs[i], image_size, image_size) for i in range(n)]\n",
    "gt_patches = [img_crop(gt_imgs[i], image_size, image_size) for i in range(n)]\n",
    "\n",
    "# Linearize the list and labeling them X and Y\n",
    "X = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "Y = np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 400)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating mini-batch and running data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch():\n",
    "    \n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 72\n",
    "    batch_size = 100\n",
    "    patch_size = 16\n",
    "    num_images = 100\n",
    "    \n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            # Select a random index represnting an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "            \n",
    "            # Width of original image\n",
    "            width = 400\n",
    "            \n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size//2, width - w_size//2, 2)\n",
    "            \n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][random_sample[0] - w_size // 2 : random_sample[0] + w_size//2,\n",
    "                                            random_sample[1] - w_size//2 : random_sample[1] + w_size//2]\n",
    "                \n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][random_sample[0] - patch_size//2:random_sample[0] + patch_size//2,\n",
    "                                                      random_sample[1]-patch_size//2:random_sample[1] + patch_size//2]\n",
    "            \n",
    "            # We set in the label depending on the threshold of 0.25\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical((np.array([np.mean(correspond_ground_truth)]) > 0.25) * 1, 2)\n",
    "            \n",
    "            # The image augmentation is based on both flipping and rotating (randomly in steps of 45)\n",
    "            # Random vertical and horizontal flip\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.flipud(sampled_image)\n",
    "            \n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.fliplr(sampled_image)\n",
    "                    \n",
    "            # Random rotation in steps of 45\n",
    "            rotations = [0, 45, 90, 135, 180, 225, 270, 315, 350]\n",
    "        \n",
    "            # We select a rotation degree randomly\n",
    "            rotation_choice = np.random.choice(len(rotations))\n",
    "            \n",
    "            # Rotate it using the random value (uses the scipy library)\n",
    "            sampled_image = scipy.ndimage.rotate(sampled_image, rotations[rotation_choice], order=1,\n",
    "                                                         reshape=False, mode='reflect')\n",
    "                        \n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield(batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the class (Same as in cnn_model.py, but provided here for better readability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "    \n",
    "    # Initialize the class\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.model = self.initialize_cnn_model(shape)\n",
    "    \n",
    "    def initialize_cnn_model(self, shape):\n",
    "        \n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "        \n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "        \n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL5, input_shape = shape, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, KERNEL3, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, KERNEL3, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, KERNEL3, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, KERNEL3, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, KERNEL3, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # Add output layer\n",
    "        model.add(Dense(2, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        \n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(lr=0.001),\n",
    "                      metrics=['accuracy'])\n",
    "            \n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "                      \n",
    "        return model\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        # We define the number of epochs and steps per epochs\n",
    "        EPOCHS = 15\n",
    "        STEPS_PER_EPOCH = 150\n",
    "        \n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "        \n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=4, verbose=1, mode='auto')\n",
    "        \n",
    "        # Place the callbacks in a list to be used when training\n",
    "        callbacks = [cb, early_stopping, lr_callback]\n",
    "        \n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        self.model.fit_generator(create_minibatch(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\\\n",
    "                                 use_multiprocessing=False, workers=1, callbacks=callbacks, verbose=1)\n",
    "    \n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:,0] < predictions[:,1]) * 1\n",
    "        \n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "    \n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        self.model = load_model(filename)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        # Save the model (used to then load to submit)\n",
    "        self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,275,586\n",
      "Trainable params: 2,275,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "model = cnn_model(shape = (72, 72, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dd37f742f646cda0ddb0e695a235d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=15, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1027c13948224b6795f2500c4c19d439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2D in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BiasAdd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LeakyRelu in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MaxPool in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GreaterEqual in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Square in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sigmoid in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Minimum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Maximum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Log in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Neg in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op NoOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BroadcastGradientArgs in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Tile in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Maximum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op FloorDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reciprocal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ZerosLike in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Select in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LessEqual in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op SigmoidGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op BiasAddGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LeakyReluGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MaxPoolGrad in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ShapeN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropInput in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Conv2DBackpropFilter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Pow in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sqrt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ResourceApplyAdam in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Greater in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "150/150 [==============================] - 32s 213ms/step - loss: 0.5749 - accuracy: 0.7396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a18b51d8aac4279a5cdbf174cfd2de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 0.5285 - accuracy: 0.7396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9378262fe6bd4033b7d55d48ae116830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 0.5080 - accuracy: 0.7437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738779cb809547f4a1ba838f05916136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 0.4747 - accuracy: 0.7686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692bd33ec5234bd98750c5b587baf343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 0.4197 - accuracy: 0.8003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b617dd9e090c443da32adff069a74f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "150/150 [==============================] - 30s 200ms/step - loss: 0.3933 - accuracy: 0.8172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4bc70ba2d54fa2958da0f58aa1b965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "150/150 [==============================] - 31s 207ms/step - loss: 0.3695 - accuracy: 0.8334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d84ea05b10a499eb59d83de10b5788f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "150/150 [==============================] - 31s 207ms/step - loss: 0.3353 - accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7319b05817eb4fe1b7add437eb5b8a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "150/150 [==============================] - 30s 203ms/step - loss: 0.3167 - accuracy: 0.8601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351165555e8146e1820b4408c308c8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=150, style=ProgressStyle(description_width='ini"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "150/150 [==============================] - 31s 209ms/step - loss: 0.2901 - accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8566eb7116c4ef8b8810ee203f39345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=150, style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.2753 - accuracy: 0.8820s - ETA: 1s - loss: 0.2775 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3409fb166a467aa47a37d486392fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=150, style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 0.2634 - accuracy: 0.8898 18s - loss: 0.2782 - accura - ETA: 16s - - ETA: 5s - - ETA: 2s - l\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822d02902faf44bab63266fa3648ced1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=150, style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 0.2573 - accuracy: 0.8944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8060f9046c148cab34c19c71d6a683b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=150, style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.2486 - accuracy: 0.8970\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6de76f56ee41be8488a166bb8c767f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=150, style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 0.2403 - accuracy: 0.8994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "# keras, model definition...\n",
    "# model.fit(X_train, Y_train, verbose=0, callbacks=[TQDMNotebookCallback()])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,275,586\n",
      "Trainable params: 2,275,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 72, 72, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,275,586\n",
      "Trainable params: 2,275,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_distributed_function_1062412 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_1/test_1.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_2/test_2.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_3/test_3.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_4/test_4.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_5/test_5.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_6/test_6.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_7/test_7.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_8/test_8.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_9/test_9.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_10/test_10.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_11/test_11.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_12/test_12.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_13/test_13.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_14/test_14.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_15/test_15.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_16/test_16.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_17/test_17.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_18/test_18.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_19/test_19.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_20/test_20.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_21/test_21.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_22/test_22.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_23/test_23.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_24/test_24.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_25/test_25.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_26/test_26.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_27/test_27.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_28/test_28.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_29/test_29.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_30/test_30.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_31/test_31.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_32/test_32.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_33/test_33.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_34/test_34.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_35/test_35.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_36/test_36.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_37/test_37.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_38/test_38.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_39/test_39.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_40/test_40.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_41/test_41.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_42/test_42.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_43/test_43.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_44/test_44.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_45/test_45.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_46/test_46.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_47/test_47.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_48/test_48.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_49/test_49.png\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Processing image => data/test_set_images/test_50/test_50.png\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "model = cnn_model(shape = (72,72,3))\n",
    "\n",
    "# Load the model\n",
    "model.load('final_model.h5')\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'data/test_set_images/test_'+ str(i) +'/test_' + str(i) + '.png'\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = 'final_submission.csv'\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
