{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import os\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from helpers import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary for our model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# from tensorflow.keras.models import Sequential, load_model\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     LeakyReLU,\n",
    "# )\n",
    "from tensorflow.compat.v2.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# keras, model definition...\n",
    "cb = TQDMNotebookCallback()\n",
    "setattr(cb, \"on_train_batch_begin\", lambda x, y: None)\n",
    "setattr(cb, \"on_train_batch_end\", lambda x, y: None)\n",
    "\n",
    "# model.fit(X_train, Y_train, verbose=0, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir_train = root_dir + \"training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n_train) + \" images\")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir_train = root_dir + \"training/groundtruth/\"\n",
    "print(\"Loading \" + str(n_train) + \" groundtruth images\")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "\n",
    "# We separate the images from the groundtruth images\n",
    "img_patches_train = [\n",
    "    img_crop(imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "gt_patches_train = [\n",
    "    img_crop(gt_imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "\n",
    "# Linearize the list and labeling them X and Y\n",
    "X_train = np.asarray(\n",
    "    [\n",
    "        img_patches_train[i][j]\n",
    "        for i in range(len(img_patches_train))\n",
    "        for j in range(len(img_patches_train[i]))\n",
    "    ]\n",
    ")\n",
    "Y_train = np.asarray(\n",
    "    [\n",
    "        gt_patches_train[i][j]\n",
    "        for i in range(len(gt_patches_train))\n",
    "        for j in range(len(gt_patches_train[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the directory for the images and load them\n",
    "# image_dir_val = root_dir + \"validating/images/\"\n",
    "# files = os.listdir(image_dir_val)\n",
    "# n_val = len(files)\n",
    "\n",
    "# print(\"Loading \" + str(n_val) + \" images\")\n",
    "# imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "\n",
    "# # Select the directory for groundtruth images and load them\n",
    "# gt_dir_val = root_dir + \"validating/groundtruth/\"\n",
    "# print(\"Loading \" + str(n_val) + \" groundtruth images\")\n",
    "# gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 400\n",
    "\n",
    "# # We separate the images from the groundtruth images\n",
    "# img_patches_val = [img_crop(imgs_val[i], image_size, image_size) for i in range(n_val)]\n",
    "# gt_patches_val = [\n",
    "#     img_crop(gt_imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "# ]\n",
    "\n",
    "# # Linearize the list and labeling them X and Y\n",
    "# X_val = np.asarray(\n",
    "#     [\n",
    "#         img_patches_val[i][j]\n",
    "#         for i in range(len(img_patches_val))\n",
    "#         for j in range(len(img_patches_val[i]))\n",
    "#     ]\n",
    "# )\n",
    "# Y_val = np.asarray(\n",
    "#     [\n",
    "#         gt_patches_val[i][j]\n",
    "#         for i in range(len(gt_patches_val))\n",
    "#         for j in range(len(gt_patches_val[i]))\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating mini-batch and running data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_minibatch(X, Y, n):\n",
    "\n",
    "#     # Fix the seed\n",
    "#     np.random.seed(1)\n",
    "\n",
    "#     # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "#     # and patch size should correspond to 16\n",
    "#     w_size = 72\n",
    "#     batch_size = 100\n",
    "#     patch_size = 16\n",
    "#     num_images = n\n",
    "\n",
    "#     while True:\n",
    "#         # Generate one minibatch\n",
    "#         batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "#         batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "#         for i in range(batch_size):\n",
    "\n",
    "#             # Select a random index represnting an image\n",
    "#             random_index = np.random.choice(num_images)\n",
    "\n",
    "#             # Width of original image\n",
    "#             width = 400\n",
    "\n",
    "#             # Sample a random window from the image\n",
    "#             random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "#             # Create a sub image of size 72x72\n",
    "#             sampled_image = X[random_index][\n",
    "#                 random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "#                 random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # Take its corresponding ground-truth image\n",
    "#             correspond_ground_truth = Y[random_index][\n",
    "#                 random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "#                 random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # We set in the label depending on the threshold of 0.2\n",
    "#             # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "#             label = to_categorical(\n",
    "#                 (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "#             )\n",
    "\n",
    "#             # The image augmentation is based on both flipping and rotating (randomly in steps of 45°)\n",
    "#             # Random vertical and horizontal flip\n",
    "#             if np.random.choice(2) == 1:\n",
    "#                 sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "#             if np.random.choice(2) == 1:\n",
    "#                 sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "#             # Random rotation in steps of 45°\n",
    "#             rotations = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "#             # We select a rotation degree randomly\n",
    "#             rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "#             # Rotate it using the random value (uses the scipy library)\n",
    "#             sampled_image = scipy.ndimage.rotate(\n",
    "#                 sampled_image,\n",
    "#                 rotations[rotation_choice],\n",
    "#                 order=1,\n",
    "#                 reshape=False,\n",
    "#                 mode=\"reflect\",\n",
    "#             )\n",
    "\n",
    "#             # We put in the sub image and its corresponding label before yielding it\n",
    "#             batch_image[i] = sampled_image\n",
    "#             batch_label[i] = label\n",
    "\n",
    "#         # Yield the mini_batch to the model\n",
    "#         yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cnn_model:\n",
    "\n",
    "#     # Initialize the class\n",
    "#     def __init__(self, shape, batch_normalization, activation):\n",
    "#         self.shape = shape\n",
    "#         self.batch_normalization = batch_normalization\n",
    "#         self.activation = activation\n",
    "#         self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "#     def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "#         #         print(activation)\n",
    "\n",
    "#         # INPUT\n",
    "#         # shape     - Size of the input images\n",
    "#         # OUTPUT\n",
    "#         # model    - Compiled CNN\n",
    "\n",
    "#         # Define hyperparamters\n",
    "#         KERNEL3 = (3, 3)\n",
    "#         KERNEL5 = (5, 5)\n",
    "\n",
    "#         # Define a model\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Add the layers\n",
    "#         # Selection of the model is described in the report\n",
    "#         # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "#         model.add(Conv2D(64, KERNEL3, input_shape=shape, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         #         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         #         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         #         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         #         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         #         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         #         model.add(Dropout(0.2))\n",
    "\n",
    "#         # Flatten it and use regularizers to avoid overfitting\n",
    "#         # The parameters have been chosen empirically\n",
    "#         model.add(Flatten())\n",
    "#         model.add(\n",
    "#             Dense(\n",
    "#                 128, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)\n",
    "#             )\n",
    "#         )\n",
    "#         #         if batch_normalization:\n",
    "#         #             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         # Add output layer\n",
    "#         model.add(\n",
    "#             Dense(2, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001))\n",
    "#         )\n",
    "#         model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#         # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "#         # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "#         model.compile(\n",
    "#             loss=\"binary_crossentropy\",\n",
    "#             optimizer=Adam(lr=0.005, amsgrad=True),\n",
    "#             metrics=[\"accuracy\", recall, f1],\n",
    "#         )\n",
    "\n",
    "#         # Print a summary of the model to see what has been generated\n",
    "#         model.summary()\n",
    "\n",
    "#         return model\n",
    "\n",
    "#     def train(self):\n",
    "\n",
    "#         # Early stopping callback after 10 steps\n",
    "#         early_stopping = EarlyStopping(\n",
    "#             monitor=\"val_f1\",\n",
    "#             min_delta=0.5,\n",
    "#             patience=20,\n",
    "#             verbose=1,\n",
    "#             mode=\"max\",\n",
    "#             restore_best_weights=True,\n",
    "#         )\n",
    "#         # Reduce learning rate on plateau after 4 steps\n",
    "#         lr_callback = ReduceLROnPlateau(\n",
    "#             monitor=\"val_f1\", factor=0.5, patience=4, verbose=1, mode=\"max\", cooldown=1\n",
    "#         )\n",
    "#         save_best = ModelCheckpoint(\n",
    "#             \"batch_relu_amsgrad_Earlystop_validation_kernel3_nodropout-{epoch:03d}-{f1:03f}-{val_f1:03f}.h5\",\n",
    "#             save_best_only=True,\n",
    "#             monitor=\"val_f1\",\n",
    "#             mode=\"max\",\n",
    "#             verbose=1,\n",
    "#         )\n",
    "\n",
    "#         # Place the callbacks in a list to be used when training\n",
    "#         #         callbacks = [cb, early_stopping, lr_callback]\n",
    "#         callbacks = [save_best, lr_callback]\n",
    "\n",
    "#         # Train the model using the previously defined functions and callbacks\n",
    "#         history = self.model.fit_generator(\n",
    "#             create_minibatch(X_train, Y_train, n_train),\n",
    "#             steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#             epochs=EPOCHS,\n",
    "#             use_multiprocessing=False,\n",
    "#             workers=1,\n",
    "#             callbacks=callbacks,\n",
    "#             verbose=1,\n",
    "#             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "#             validation_steps=STEPS_PER_EPOCH,\n",
    "#         )\n",
    "#         #         to_plot = self.model.fit_generator(\n",
    "#         #             create_minibatch(X_train, Y_train, n_train),\n",
    "#         #             steps_per_epoch=100,\n",
    "#         #             epochs=EPOCHS,\n",
    "#         #             use_multiprocessing=False,\n",
    "#         #             workers=1,\n",
    "#         #             callbacks=callbacks,\n",
    "#         #             verbose=1,\n",
    "#         #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "#         #             validation_steps=100,\n",
    "#         #         )\n",
    "#         return history\n",
    "\n",
    "#     def classify(self, X):\n",
    "#         # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "#         img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "#         # Predict\n",
    "#         predictions = self.model.predict(img_patches)\n",
    "#         predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "#         # Regroup patches into images\n",
    "#         return group_patches(predictions, X.shape[0])\n",
    "\n",
    "#     def load(self, filename):\n",
    "#         # Load the model (used for submission)\n",
    "#         dependencies = {\n",
    "#             \"recall\": recall,\n",
    "#             \"f1\": f1,\n",
    "#         }\n",
    "#         self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "# #     def save(self, filename):\n",
    "# #         # Save the model (used to then load to submit)\n",
    "# #         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# # We define the number of epochs and steps per epochs\n",
    "# EPOCHS = 100\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# batch_normalization = True\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model\n",
    "# history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"batch_relu_amsgrad_Earlystop_validation_kernel3_nodropout.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = False\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\n",
    "#     \"batch_relu_amsgrad_Earlystop_validation_kernel5_nodropout-040-0.954435-0.924519.h5\"\n",
    "# )\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = \"batch_relu_amsgrad_Earlystop_validation_kernel5_nodropout-040-0.954435-0.924519.csv\"\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_minibatch(X, Y, n):\n",
    "\n",
    "#     # Fix the seed\n",
    "#     np.random.seed(1)\n",
    "\n",
    "#     # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "#     # and patch size should correspond to 16\n",
    "#     w_size = 64\n",
    "#     batch_size = 100\n",
    "#     patch_size = 16\n",
    "#     num_images = n\n",
    "\n",
    "#     while True:\n",
    "#         # Generate one minibatch\n",
    "#         batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "#         batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "#         for i in range(batch_size):\n",
    "\n",
    "#             # Select a random index represnting an image\n",
    "#             random_index = np.random.choice(num_images)\n",
    "\n",
    "#             # Width of original image\n",
    "#             width = 400\n",
    "\n",
    "#             # Sample a random window from the image\n",
    "#             random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "#             # Create a sub image of size 72x72\n",
    "#             sampled_image = X[random_index][\n",
    "#                 random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "#                 random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # Take its corresponding ground-truth image\n",
    "#             correspond_ground_truth = Y[random_index][\n",
    "#                 random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "#                 random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # We set in the label depending on the threshold of 0.2\n",
    "#             # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "#             label = to_categorical(\n",
    "#                 (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "#             )\n",
    "\n",
    "#             # The image augmentation is based on both flipping and rotating (randomly in steps of 45°)\n",
    "#             # Random vertical and horizontal flip\n",
    "#             if np.random.choice(2) == 1:\n",
    "#                 sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "#             if np.random.choice(2) == 1:\n",
    "#                 sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "#             # Random rotation in steps of 45°\n",
    "#             rotations = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "#             # We select a rotation degree randomly\n",
    "#             rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "#             # Rotate it using the random value (uses the scipy library)\n",
    "#             sampled_image = scipy.ndimage.rotate(\n",
    "#                 sampled_image,\n",
    "#                 rotations[rotation_choice],\n",
    "#                 order=1,\n",
    "#                 reshape=False,\n",
    "#                 mode=\"reflect\",\n",
    "#             )\n",
    "\n",
    "#             # We put in the sub image and its corresponding label before yielding it\n",
    "#             batch_image[i] = sampled_image\n",
    "#             batch_label[i] = label\n",
    "\n",
    "#         # Yield the mini_batch to the model\n",
    "#         yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cnn_model:\n",
    "\n",
    "#     # Initialize the class\n",
    "#     def __init__(self, shape, batch_normalization, activation):\n",
    "#         self.shape = shape\n",
    "#         self.batch_normalization = batch_normalization\n",
    "#         self.activation = activation\n",
    "#         self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "#     def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "#         #         print(activation)\n",
    "\n",
    "#         # INPUT\n",
    "#         # shape     - Size of the input images\n",
    "#         # OUTPUT\n",
    "#         # model    - Compiled CNN\n",
    "\n",
    "#         # Define hyperparamters\n",
    "#         KERNEL3 = (3, 3)\n",
    "#         KERNEL5 = (5, 5)\n",
    "\n",
    "#         # Define a model\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Add the layers\n",
    "#         # Selection of the model is described in the report\n",
    "#         # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "#         # Layer 1\n",
    "#         model.add(Conv2D(64, KERNEL3, input_shape=shape, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(512, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(1024, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(512, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(UpSampling2D())\n",
    "#         #         model.add(concatenate([drop4, up6], axis=3))\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(UpSampling2D())\n",
    "#         #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(UpSampling2D())\n",
    "#         #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(64, KERNEL3, input_shape=shape, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(UpSampling2D())\n",
    "#         #         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         # Flatten it and use regularizers to avoid overfitting\n",
    "#         # The parameters have been chosen empirically\n",
    "#         model.add(Flatten())\n",
    "#         model.add(\n",
    "#             Dense(\n",
    "#                 64, kernel_regularizer=l2(0.000001), activity_regularizer=l2(0.000001)\n",
    "#             )\n",
    "#         )\n",
    "#         #         if batch_normalization:\n",
    "#         #             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         # Add output layer\n",
    "#         model.add(\n",
    "#             Dense(2, kernel_regularizer=l2(0.00001), activity_regularizer=l2(0.00001))\n",
    "#         )\n",
    "#         model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#         # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "#         # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "#         model.compile(\n",
    "#             loss=\"binary_crossentropy\",\n",
    "#             optimizer=Adam(lr=0.001, amsgrad=True),\n",
    "#             metrics=[\"accuracy\", recall, f1],\n",
    "#         )\n",
    "\n",
    "#         # Print a summary of the model to see what has been generated\n",
    "#         model.summary()\n",
    "\n",
    "#         return model\n",
    "\n",
    "#     def train(self):\n",
    "\n",
    "#         # Early stopping callback after 10 steps\n",
    "#         early_stopping = EarlyStopping(\n",
    "#             monitor=\"accuracy\",\n",
    "#             min_delta=0.5,\n",
    "#             patience=20,\n",
    "#             verbose=1,\n",
    "#             mode=\"auto\",\n",
    "#             restore_best_weights=True,\n",
    "#         )\n",
    "#         # Reduce learning rate on plateau after 4 steps\n",
    "#         lr_callback = ReduceLROnPlateau(\n",
    "#             monitor=\"accuracy\",\n",
    "#             factor=0.5,\n",
    "#             patience=4,\n",
    "#             verbose=1,\n",
    "#             mode=\"max\",\n",
    "#             cooldown=1,\n",
    "#         )\n",
    "#         save_best = ModelCheckpoint(\n",
    "#             \"Unet64_batch_relu_dropout_noVal-{epoch:03d}-{f1:03f}.h5\",\n",
    "#             save_best_only=True,\n",
    "#             monitor=\"accuracy\",\n",
    "#             mode=\"max\",\n",
    "#             verbose=1,\n",
    "#         )\n",
    "\n",
    "#         # Place the callbacks in a list to be used when training\n",
    "#         #         callbacks = [cb, early_stopping, lr_callback]\n",
    "#         callbacks = [save_best, lr_callback]\n",
    "\n",
    "#         # Train the model using the previously defined functions and callbacks\n",
    "#         history = self.model.fit_generator(\n",
    "#             create_minibatch(X_train, Y_train, n_train),\n",
    "#             steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#             epochs=EPOCHS,\n",
    "#             use_multiprocessing=False,\n",
    "#             workers=1,\n",
    "#             callbacks=callbacks,\n",
    "#             verbose=1,\n",
    "#             #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "#             #             validation_steps=STEPS_PER_EPOCH,\n",
    "#         )\n",
    "#         #         to_plot = self.model.fit_generator(\n",
    "#         #             create_minibatch(X_train, Y_train, n_train),\n",
    "#         #             steps_per_epoch=100,\n",
    "#         #             epochs=EPOCHS,\n",
    "#         #             use_multiprocessing=False,\n",
    "#         #             workers=1,\n",
    "#         #             callbacks=callbacks,\n",
    "#         #             verbose=1,\n",
    "#         #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "#         #             validation_steps=100,\n",
    "#         #         )\n",
    "#         return history\n",
    "\n",
    "#     def classify(self, X):\n",
    "#         # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "#         img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "#         # Predict\n",
    "#         predictions = self.model.predict(img_patches)\n",
    "#         predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "#         # Regroup patches into images\n",
    "#         return group_patches(predictions, X.shape[0])\n",
    "\n",
    "#     def load(self, filename):\n",
    "#         # Load the model (used for submission)\n",
    "#         dependencies = {\n",
    "#             \"recall\": recall,\n",
    "#             \"f1\": f1,\n",
    "#         }\n",
    "#         self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "# #     def save(self, filename):\n",
    "# #         # Save the model (used to then load to submit)\n",
    "# #         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# # We define the number of epochs and steps per epochs\n",
    "# EPOCHS = 200\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# batch_normalization = True\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(64, 64, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model\n",
    "# history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# # plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# # plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"Unet64_batch_relu_dropout_noVal.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = True\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(64, 64, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\"Unet64_batch_relu_dropout_noVal-111-0.951604.h5\")\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = \"Unet64_batch_relu_dropout_noVal-111-0.951604.csv\"\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Increase regulrization parameters\n",
    "2. Increase dropout prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch(X, Y, n):\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 64\n",
    "    batch_size = 100\n",
    "    patch_size = 16\n",
    "    num_images = n\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index represnting an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.2\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "            )\n",
    "\n",
    "            # The image augmentation is based on both flipping and rotating (randomly in steps of 45°)\n",
    "            # Random vertical and horizontal flip\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "            # Random rotation in steps of 45°\n",
    "            rotations = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "            # We select a rotation degree randomly\n",
    "            rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "            # Rotate it using the random value (uses the scipy library)\n",
    "            sampled_image = scipy.ndimage.rotate(\n",
    "                sampled_image,\n",
    "                rotations[rotation_choice],\n",
    "                order=1,\n",
    "                reshape=False,\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down(input_layer, filters, pool=True):\n",
    "    conv1 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(input_layer)\n",
    "    residual = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    if pool:\n",
    "        max_pool = MaxPool2D()(residual)\n",
    "        return max_pool, residual\n",
    "    else:\n",
    "        return residual\n",
    "\n",
    "\n",
    "def up(input_layer, residual, filters):\n",
    "    filters = int(filters)\n",
    "    upsample = UpSampling2D()(input_layer)\n",
    "    upconv = Conv2D(filters, kernel_size=(2, 2), padding=\"same\")(upsample)\n",
    "    concat = Concatenate(axis=3)([residual, upconv])\n",
    "    conv1 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(concat)\n",
    "    conv2 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    return conv2\n",
    "\n",
    "\n",
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        # Make a custom U-nets implementation.\n",
    "        filters = 64\n",
    "        input_layer = Input(shape=[64, 64, 3])\n",
    "        layers = [input_layer]\n",
    "        residuals = []\n",
    "\n",
    "        # Down 1, 128\n",
    "        d1, res1 = down(input_layer, filters)\n",
    "        residuals.append(res1)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 2, 64\n",
    "        d2, res2 = down(d1, filters)\n",
    "        residuals.append(res2)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 3, 32\n",
    "        d3, res3 = down(d2, filters)\n",
    "        residuals.append(res3)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 4, 16\n",
    "        d4, res4 = down(d3, filters)\n",
    "        residuals.append(res4)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 5, 8\n",
    "        d5 = down(d4, filters, pool=False)\n",
    "\n",
    "        # Up 1, 16\n",
    "        up1 = up(d5, residual=residuals[-1], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 2,  32\n",
    "        up2 = up(up1, residual=residuals[-2], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 3, 64\n",
    "        up3 = up(up2, residual=residuals[-3], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 4, 128\n",
    "        up4 = up(up3, residual=residuals[-4], filters=filters / 2)\n",
    "\n",
    "        flaten = Flatten()(up4)\n",
    "        dense1 = Dense(62, activation=\"relu\")(flaten)\n",
    "\n",
    "        out = Dense(2, activation=\"sigmoid\")(dense1)\n",
    "\n",
    "        model = Model(input_layer, out)\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(learning_rate=0.0005),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"accuracy\",\n",
    "            min_delta=0.5,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"accuracy\",\n",
    "            factor=0.5,\n",
    "            patience=4,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "            cooldown=1,\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"Unet64_batch_relu_dropout_noVal-{epoch:03d}-{f1:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"accuracy\",\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [save_best, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(X_train, Y_train, n_train),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "            #             validation_steps=STEPS_PER_EPOCH,\n",
    "        )\n",
    "        #         to_plot = self.model.fit_generator(\n",
    "        #             create_minibatch(X_train, Y_train, n_train),\n",
    "        #             steps_per_epoch=100,\n",
    "        #             epochs=EPOCHS,\n",
    "        #             use_multiprocessing=False,\n",
    "        #             workers=1,\n",
    "        #             callbacks=callbacks,\n",
    "        #             verbose=1,\n",
    "        #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "        #             validation_steps=100,\n",
    "        #         )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# We define the number of epochs and steps per epochs\n",
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH = 100\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(64, 64, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model\n",
    "history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"Unet64_batch_relu_dropout_noVal.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/training/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" groundtruth images\")\n",
    "gt_imgs = np.asarray([load_image(gt_dir + files[i]) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "\n",
    "# We separate the images from the groundtruth images\n",
    "img_patches = [img_crop(imgs[i], image_size, image_size) for i in range(n)]\n",
    "gt_patches = [img_crop(gt_imgs[i], image_size, image_size) for i in range(n)]\n",
    "\n",
    "# Linearize the list and labeling them X and Y\n",
    "X = np.asarray(\n",
    "    [\n",
    "        img_patches[i][j]\n",
    "        for i in range(len(img_patches))\n",
    "        for j in range(len(img_patches[i]))\n",
    "    ]\n",
    ")\n",
    "Y = np.asarray(\n",
    "    [\n",
    "        gt_patches[i][j]\n",
    "        for i in range(len(gt_patches))\n",
    "        for j in range(len(gt_patches[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch():\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 72\n",
    "    batch_size = 100\n",
    "    patch_size = 16\n",
    "    num_images = 100\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index represnting an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.2\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "            )\n",
    "\n",
    "            # The image augmentation is based on both flipping and rotating (randomly in steps of 45°)\n",
    "            # Random vertical and horizontal flip\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "            if np.random.choice(2) == 1:\n",
    "                sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "            # Random rotation in steps of 45°\n",
    "            rotations = [0, 45, 90, 135, 180, 225, 270, 315, 350]\n",
    "\n",
    "            # We select a rotation degree randomly\n",
    "            rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "            # Rotate it using the random value (uses the scipy library)\n",
    "            sampled_image = scipy.ndimage.rotate(\n",
    "                sampled_image,\n",
    "                rotations[rotation_choice],\n",
    "                order=1,\n",
    "                reshape=False,\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down(input_layer, filters, pool=True):\n",
    "    conv1 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(input_layer)\n",
    "    residual = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    if pool:\n",
    "        max_pool = MaxPool2D()(residual)\n",
    "        return max_pool, residual\n",
    "    else:\n",
    "        return residual\n",
    "\n",
    "\n",
    "def up(input_layer, residual, filters):\n",
    "    filters = int(filters)\n",
    "    upsample = UpSampling2D()(input_layer)\n",
    "    upconv = Conv2D(filters, kernel_size=(2, 2), padding=\"same\")(upsample)\n",
    "    concat = Concatenate(axis=3)([residual, upconv])\n",
    "    conv1 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(concat)\n",
    "    conv2 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    return conv2\n",
    "\n",
    "\n",
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        # Make a custom U-nets implementation.\n",
    "        filters = 64\n",
    "        input_layer = Input(shape=[128, 128, 3])\n",
    "        layers = [input_layer]\n",
    "        residuals = []\n",
    "\n",
    "        # Down 1, 128\n",
    "        d1, res1 = down(input_layer, filters)\n",
    "        residuals.append(res1)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 2, 64\n",
    "        d2, res2 = down(d1, filters)\n",
    "        residuals.append(res2)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 3, 32\n",
    "        d3, res3 = down(d2, filters)\n",
    "        residuals.append(res3)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 4, 16\n",
    "        d4, res4 = down(d3, filters)\n",
    "        residuals.append(res4)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 5, 8\n",
    "        d5 = down(d4, filters, pool=False)\n",
    "\n",
    "        # Up 1, 16\n",
    "        up1 = up(d5, residual=residuals[-1], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 2,  32\n",
    "        up2 = up(up1, residual=residuals[-2], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 3, 64\n",
    "        up3 = up(up2, residual=residuals[-3], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 4, 128\n",
    "        up4 = up(up3, residual=residuals[-4], filters=filters / 2)\n",
    "        out = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(up4)\n",
    "\n",
    "        model = Model(input_layer, out)\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.001),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"f1\", min_delta=0.5, patience=20, verbose=0, mode=\"max\"\n",
    "        )\n",
    "\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"f1\", factor=0.5, patience=4, verbose=0, mode=\"max\"\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"batch_relu_OLD_Ali_amsgrad_noise-{epoch:03d}-{f1:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"f1\",\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        callbacks = [lr_callback, save_best]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "    def save(self, filename):\n",
    "        # Save the model (used to then load to submit)\n",
    "        self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "EPOCHS = 120\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "model.save(\"batch_relu_OLD_Ali_amsgrad_noise.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_relu_OLD_Ali_amsgrad_noise.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"batch_relu_OLD_Ali_amsgrad_noise-092-0.952039.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu_OLD_Ali_amsgrad_noise-092-0.952039.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# We define the number of epochs and steps per epochs\n",
    "EPOCHS = 160\n",
    "STEPS_PER_EPOCH = 150\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model\n",
    "history = model.train()\n",
    "# model.save(\"no_batch_LeakyRelu_validation_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_160_dropout-0.2.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\n",
    "    \"saved_models/batch_LeakyReLU_validation_160_dropout-0.2-070-0.948567-0.928000.h5\"\n",
    ")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"to_submit_csv/batch_LeakyReLU_validation_160_dropout-0.2-070-0.948567-0.928000.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history.history[\"loss\"]\n",
    "# print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history[\"accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "# plt.title(\"model accuracy\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# N = EPOCHS\n",
    "# print(N)\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.show()\n",
    "# plt.savefig(\"model1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = False\n",
    "# EPOCHS = 200\n",
    "\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# model.train()\n",
    "# model.save(\"no_batch_relu_validation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = True\n",
    "# EPOCHS = 200\n",
    "\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# model.train()\n",
    "# model.save(\"batch_LeakyReLU_validation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 200\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_relu_validation_200.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"batch_relu_validation_200-145-0.951267-0.930033.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu_validation_200-145-0.951267-0.930033.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 160\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_160.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"batch_relu_validation_200-074-0.946167-0.927667.h5\")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"batch_relu_validation_200-074-0.946167-0.927667.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW BATCH ERICK V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as scipy\n",
    "\n",
    "\n",
    "def pad_matrix(mat, h_pad, w_pad, val=0):\n",
    "    h_pad = int(h_pad)\n",
    "    w_pad = int(w_pad)\n",
    "    if len(mat.shape) == 3:\n",
    "        padded_mat = np.pad(\n",
    "            mat,\n",
    "            ((h_pad, h_pad), (w_pad, w_pad), (0, 0)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=((val, val), (val, val), (0, 0)),\n",
    "        )\n",
    "    elif len(mat.shape) == 2:\n",
    "        padded_mat = np.pad(\n",
    "            mat,\n",
    "            ((h_pad, h_pad), (w_pad, w_pad)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=((val, val), (val, val)),\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"This method can only handle 2d or 3d arrays\")\n",
    "    return padded_mat\n",
    "\n",
    "\n",
    "def imag_rotation(X, Y, number_rotations=8):\n",
    "\n",
    "    w = X.shape[1]\n",
    "    w_2 = w // 2  # half of the width\n",
    "    padding = 82\n",
    "    Xrs = X\n",
    "    Yrs = Y\n",
    "    Xrs = np.expand_dims(Xrs, 0)\n",
    "    Yrs = np.expand_dims(Yrs, 0)\n",
    "    thetas = np.random.randint(0, high=360, size=number_rotations)\n",
    "    for theta in thetas:\n",
    "        Xr = pad_matrix(\n",
    "            X, padding, padding\n",
    "        )  # Selected for the specific case of images of (400,400)\n",
    "        Yr = pad_matrix(\n",
    "            Y, padding, padding\n",
    "        )  # Selected for the specific case of images of (400,400)\n",
    "        Xr = scipy.ndimage.rotate(Xr, theta, reshape=False)\n",
    "        Yr = scipy.ndimage.rotate(Yr, theta, reshape=False)\n",
    "        theta = theta * np.pi / 180\n",
    "        a = int(\n",
    "            w_2 / (np.sqrt(2) * np.cos(np.pi / 4 - np.mod(theta, np.pi / 2)))\n",
    "        )  # width and height of the biggest square inside the rotated square\n",
    "        w_p = w_2 + padding\n",
    "        Xr = Xr[w_p - a : w_p + a, w_p - a : w_p + a, :]\n",
    "        Yr = Yr[w_p - a : w_p + a, w_p - a : w_p + a]\n",
    "\n",
    "        Xr = cv2.resize(Xr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "        Yr = cv2.resize(Yr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        if np.random.choice(2) == 1:\n",
    "            Xr = np.flipud(Xr)\n",
    "            Yr = np.flipud(Yr)\n",
    "\n",
    "        if np.random.choice(2) == 1:\n",
    "            Xr = np.fliplr(Xr)\n",
    "            Yr = np.fliplr(Yr)\n",
    "\n",
    "        Xr = np.expand_dims(Xr, 0)\n",
    "        Yr = np.expand_dims(Yr, 0)\n",
    "        Xrs = np.append(Xrs, Xr, axis=0)\n",
    "        Yrs = np.append(Yrs, Yr, axis=0)\n",
    "\n",
    "    return Xrs, Yrs\n",
    "\n",
    "\n",
    "def imag_rotation_aug(Xr, Yr, number_rotations=8):\n",
    "\n",
    "    Xrs, Yrs = imag_rotation(Xr[0], Yr[0])\n",
    "    for i in range(1, len(Xr)):\n",
    "        Xrr, Yrr = imag_rotation(Xr[i], Yr[i])\n",
    "        Xrs = np.append(Xrs, Xrr, axis=0)\n",
    "        Yrs = np.append(Yrs, Yrr, axis=0)\n",
    "\n",
    "    Xrs_shuf = []\n",
    "    Yrs_shuf = []\n",
    "    index_shuf = list(range(len(Xrs)))\n",
    "    np.random.shuffle(index_shuf)\n",
    "    for i in index_shuf:\n",
    "        Xrs_shuf.append(Xrs[i])\n",
    "        Yrs_shuf.append(Yrs[i])\n",
    "\n",
    "    return Xrs_shuf, Yrs_shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"data/\"\n",
    "\n",
    "# Select the directory for the images and load them\n",
    "image_dir_train = root_dir + \"training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n_train) + \" images\")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir_train = root_dir + \"training/groundtruth/\"\n",
    "print(\"Loading \" + str(n_train) + \" groundtruth images\")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the directory for the images and load them\n",
    "image_dir_val = root_dir + \"validating/images/\"\n",
    "files = os.listdir(image_dir_val)\n",
    "n_val = len(files)\n",
    "\n",
    "print(\"Loading \" + str(n_val) + \" images\")\n",
    "imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "\n",
    "# Select the directory for groundtruth images and load them\n",
    "gt_dir_val = root_dir + \"validating/groundtruth/\"\n",
    "print(\"Loading \" + str(n_val) + \" groundtruth images\")\n",
    "gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = imag_rotation_aug(imgs_train, gt_imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = imag_rotation_aug(imgs_val, gt_imgs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatch(X, Y, n):\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "    # and patch size should correspond to 16\n",
    "    w_size = 72\n",
    "    batch_size = 80\n",
    "    patch_size = 72\n",
    "    num_images = n\n",
    "\n",
    "    while True:\n",
    "        # Generate one minibatch\n",
    "        batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "        batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            # Select a random index representing an image\n",
    "            random_index = np.random.choice(num_images)\n",
    "\n",
    "            # Width of original image\n",
    "            width = 400\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "            # Create a sub image of size 72x72\n",
    "            sampled_image = X[random_index][\n",
    "                random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "                random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "            ]\n",
    "\n",
    "            # Take its corresponding ground-truth image\n",
    "            correspond_ground_truth = Y[random_index][\n",
    "                random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "                random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "            ]\n",
    "\n",
    "            # We set in the label depending on the threshold of 0.2\n",
    "            # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "            label = to_categorical(\n",
    "                (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "            )\n",
    "\n",
    "            # We put in the sub image and its corresponding label before yielding it\n",
    "            batch_image[i] = sampled_image\n",
    "            batch_label[i] = label\n",
    "\n",
    "        # Yield the mini_batch to the model\n",
    "        yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(128, kernel_regularizer=l2(0.0001), activity_regularizer=l2(0.0001))\n",
    "        )\n",
    "        #         if batch_normalization:\n",
    "        #             model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.0001), activity_regularizer=l2(0.0001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.001),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0,\n",
    "            patience=15,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"auto\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [save_best, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(X_train, Y_train, n_train * 9),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            validation_data=create_minibatch(X_val, Y_val, n_val * 9),\n",
    "            validation_steps=STEPS_PER_EPOCH,\n",
    "        )\n",
    "        #         to_plot = self.model.fit_generator(\n",
    "        #             create_minibatch(X_train, Y_train, n_train),\n",
    "        #             steps_per_epoch=100,\n",
    "        #             epochs=EPOCHS,\n",
    "        #             use_multiprocessing=False,\n",
    "        #             workers=1,\n",
    "        #             callbacks=callbacks,\n",
    "        #             verbose=1,\n",
    "        #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "        #             validation_steps=100,\n",
    "        #         )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 200\n",
    "# EPOCHS = 2\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_erickv7.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\n",
    "    \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-099-0.956417-0.907208.h5\"\n",
    ")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = (\n",
    "    \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-099-0.956417-0.907208.csv\"\n",
    ")\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, shape, batch_normalization, activation):\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "    def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "        #         print(activation)\n",
    "\n",
    "        # INPUT\n",
    "        # shape     - Size of the input images\n",
    "        # OUTPUT\n",
    "        # model    - Compiled CNN\n",
    "\n",
    "        # Define hyperparamters\n",
    "        KERNEL3 = (3, 3)\n",
    "        KERNEL5 = (5, 5)\n",
    "\n",
    "        # Define a model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the layers\n",
    "        # Selection of the model is described in the report\n",
    "        # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "        model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Flatten it and use regularizers to avoid overfitting\n",
    "        # The parameters have been chosen empirically\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(128, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001))\n",
    "        )\n",
    "        #         if batch_normalization:\n",
    "        #             model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "            Activation(activation)\n",
    "        )\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(\n",
    "            Dense(2, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001))\n",
    "        )\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "        # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=0.0005, amsgrad=True),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0,\n",
    "            patience=15,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_f1\",\n",
    "            mode=\"max\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Place the callbacks in a list to be used when training\n",
    "        #         callbacks = [cb, early_stopping, lr_callback]\n",
    "        callbacks = [save_best, lr_callback]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(X_train, Y_train, n_train * 9),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            validation_data=create_minibatch(X_val, Y_val, n_val * 9),\n",
    "            validation_steps=STEPS_PER_EPOCH,\n",
    "        )\n",
    "        #         to_plot = self.model.fit_generator(\n",
    "        #             create_minibatch(X_train, Y_train, n_train),\n",
    "        #             steps_per_epoch=100,\n",
    "        #             epochs=EPOCHS,\n",
    "        #             use_multiprocessing=False,\n",
    "        #             workers=1,\n",
    "        #             callbacks=callbacks,\n",
    "        #             verbose=1,\n",
    "        #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "        #             validation_steps=100,\n",
    "        #         )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "batch_normalization = True\n",
    "EPOCHS = 150\n",
    "# EPOCHS = 2\n",
    "STEPS_PER_EPOCH = 150\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "# Train the model with batch\n",
    "history = model.train()\n",
    "# model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"f1\"], label=\"train_f1\")\n",
    "plt.plot(history.history[\"val_f1\"], label=\"val_f1\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"batch_LeakyReLU_validation_erickv7_dropout0.5_adagram.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "# from cnn_model import cnn_model\n",
    "\n",
    "# Instantiate the model\n",
    "batch_normalization = True\n",
    "activation = \"LeakyReLU\"\n",
    "model = cnn_model(\n",
    "    shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\n",
    "    \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-074-0.912500-0.858625.h5\"\n",
    ")\n",
    "\n",
    "# Print a summary to make sure the correct model is used\n",
    "model.model.summary()\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = (\n",
    "    \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-074-0.912500-0.858625.csv\"\n",
    ")\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
