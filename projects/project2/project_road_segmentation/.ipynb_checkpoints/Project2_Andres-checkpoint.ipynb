{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from helpers import *\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.compat.v2.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3844752603889989834\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4937233203\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17299788919217548665\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(8)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images, images loaded: 80 \n",
      "Loading groundtruth images, images loaded: 80 \n"
     ]
    }
   ],
   "source": [
    "image_dir_train = \"data/training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "print(f\"Loading training images, images loaded: {n_train} \")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "gt_dir_train = \"data/training/groundtruth/\"\n",
    "print(f\"Loading groundtruth images, images loaded: {n_train} \")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 400, 400, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 400, 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "# Patches for training\n",
    "img_patches_train = [\n",
    "    crop_image(imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "gt_patches_train = [\n",
    "    crop_image(gt_imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = np.asarray(\n",
    "    [\n",
    "        img_patches_train[i][j]\n",
    "        for i in range(len(img_patches_train))\n",
    "        for j in range(len(img_patches_train[i]))\n",
    "    ]\n",
    ")\n",
    "Y_train = np.asarray(\n",
    "    [\n",
    "        gt_patches_train[i][j]\n",
    "        for i in range(len(gt_patches_train))\n",
    "        for j in range(len(gt_patches_train[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 400, 400, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 400, 400)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validating images, images loaded: 20 \n",
      "Loading validating groundtruth, images loaded: 20 \n"
     ]
    }
   ],
   "source": [
    "image_dir_val = \"data/validating/images/\"\n",
    "files = os.listdir(image_dir_val)\n",
    "n_val = len(files)\n",
    "print(f\"Loading validating images, images loaded: {n_val} \")\n",
    "imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "gt_dir_val = \"data/validating/groundtruth/\"\n",
    "print(f\"Loading validating groundtruth, images loaded: {n_val} \")\n",
    "gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400, 400, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400, 400)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "# Patches for validating\n",
    "img_patches_val = [\n",
    "    crop_image(imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "]\n",
    "gt_patches_val = [\n",
    "    crop_image(gt_imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "]\n",
    "\n",
    "# Separate features and labels\n",
    "X_val = np.asarray(\n",
    "    [\n",
    "        img_patches_val[i][j]\n",
    "        for i in range(len(img_patches_val))\n",
    "        for j in range(len(img_patches_val[i]))\n",
    "    ]\n",
    ")\n",
    "Y_val = np.asarray(\n",
    "    [\n",
    "        gt_patches_val[i][j]\n",
    "        for i in range(len(gt_patches_val))\n",
    "        for j in range(len(gt_patches_val[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400, 400, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400, 400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = imag_rotation_aug(imgs_train, gt_imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 456, 456, 3)\n",
      "(720, 456, 456)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "n_train = Y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = imag_rotation_aug(imgs_val, gt_imgs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.asarray(X_val)\n",
    "Y_val = np.asarray(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 456, 456, 3)\n",
      "(180, 456, 456)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "n_val = Y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions to calcualte precision, recall and F-1 in the training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Compute the Precision for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "        Precision (numpy.float64): the Precision of the batch \n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Compute the Recall for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "       Recall (numpy.float64): the Recal of the batch \n",
    "    \"\"\"\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Compute the F-1 for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "       F-1 (numpy.float64): the F-1 of the batch \n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrelu = lambda x: tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "\n",
    "def down(input_layer, filters, pool=True):\n",
    "    \"\"\"Create convloutional and residual layers to reduce dimensions.\n",
    "    Args:\n",
    "        input_layer (layer): input layer before convolution\n",
    "        filters (numpy.int64): number of filters\n",
    "    Returns:\n",
    "        max_pool (layer): layer after max-pooling\n",
    "        residual (connection ): connection to connect with next layers\n",
    "    \"\"\"\n",
    "    batchnorm = BatchNormalization()(input_layer)\n",
    "    conv1 = Conv2D(filters, (5, 5), padding=\"same\", activation=lrelu)(batchnorm)\n",
    "    residual = Conv2D(filters, (3, 3), padding=\"same\", activation=lrelu)(conv1)\n",
    "    if pool:\n",
    "        max_pool = MaxPool2D()(residual)\n",
    "        return max_pool, residual\n",
    "    else:\n",
    "        return residual\n",
    "\n",
    "\n",
    "def up(input_layer, residual, filters):\n",
    "    \"\"\"Create convloutional and residual layers to increase dimensions.\n",
    "    Args:\n",
    "        input_layer (layer): input layer before convolution\\\n",
    "        residual (connection ): connection to connect with next layers\n",
    "        filters (numpy.int64): number of filters\n",
    "    Returns:\n",
    "        conv2 (layer): convolutional layer\n",
    "    \"\"\"\n",
    "    filters = int(filters)\n",
    "    batchnorm = BatchNormalization()(input_layer)\n",
    "    upsample = UpSampling2D()(batchnorm)\n",
    "    upconv = Conv2D(filters, kernel_size=(2, 2), padding=\"same\")(upsample)\n",
    "    concat = Concatenate(axis=3)([residual, upconv])\n",
    "    conv1 = Conv2D(filters, (5, 5), padding=\"same\", activation=\"relu\")(concat)\n",
    "    conv2 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    return conv2\n",
    "\n",
    "\n",
    "class U_NET:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.model = self.initialize_U_NET(shape)\n",
    "\n",
    "    def initialize_U_NET(self, shape):\n",
    "        \"\"\"Create Network Architecture.\n",
    "        Args:\n",
    "            shape (triplet): Size of the input layer height x width x colors (64 x 64 x 3)\n",
    "        Returns:\n",
    "            model (Neural Network): Architecture of the model\n",
    "        \"\"\"\n",
    "        # Make a custom U-nets implementation.\n",
    "        filters = 64\n",
    "        input_layer = Input(shape=shape)\n",
    "        layers = [input_layer]\n",
    "        residuals = []\n",
    "\n",
    "        # Down 1, 64\n",
    "        d1, res1 = down(input_layer, filters)\n",
    "        residuals.append(res1)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 2, 32\n",
    "        d2, res2 = down(d1, filters)\n",
    "        residuals.append(res2)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 3, 16\n",
    "        d3, res3 = down(d2, filters)\n",
    "        residuals.append(res3)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 4, 8\n",
    "        d4, res4 = down(d3, filters)\n",
    "        residuals.append(res4)\n",
    "        filters *= 2\n",
    "\n",
    "        # Down 5, 4\n",
    "        d5 = down(d4, filters, pool=False)\n",
    "\n",
    "        # Up 1, 8\n",
    "        up1 = up(d5, residual=residuals[-1], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 2,  16\n",
    "        up2 = up(up1, residual=residuals[-2], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 3, 32\n",
    "        up3 = up(up2, residual=residuals[-3], filters=filters / 2)\n",
    "        filters /= 2\n",
    "\n",
    "        # Up 4, 64\n",
    "        up4 = up(up3, residual=residuals[-4], filters=filters / 2)\n",
    "\n",
    "        flaten = Flatten()(up4)\n",
    "        batch_1 = BatchNormalization()(flaten)\n",
    "        dense1 = Dense(\n",
    "            64,\n",
    "            activation=lrelu,\n",
    "            kernel_regularizer=l2(0.00001),\n",
    "            activity_regularizer=l2(0.00001),\n",
    "        )(flaten)\n",
    "        batch_2 = BatchNormalization()(dense1)\n",
    "        out = Dense(\n",
    "            2,\n",
    "            activation=\"sigmoid\",\n",
    "            kernel_regularizer=l2(0.00001),\n",
    "            activity_regularizer=l2(0.00001),\n",
    "        )(batch_2)\n",
    "\n",
    "        model = Model(input_layer, out)\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        # Print a summary of the model to see what has been generated\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the Model.\n",
    "\n",
    "        Returns:\n",
    "            History (History_Keras): History of the training\n",
    "        \"\"\"\n",
    "        # Early stopping callback after 10 steps\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=10, verbose=1, restore_best_weights=True,\n",
    "        )\n",
    "        # Reduce learning rate on plateau after 4 steps\n",
    "        lr_callback = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "            cooldown=1,\n",
    "        )\n",
    "        save_best = ModelCheckpoint(\n",
    "            \"Unet_batchnorm-{epoch:03d}-{f1:03f}.h5\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            verbose=1,\n",
    "        )\n",
    "        callbacks = [save_best, lr_callback, early_stopping]\n",
    "\n",
    "        # Train the model using the previously defined functions and callbacks\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(\n",
    "                X_train, Y_train, n_train, WINDOW_SIZE, BATCH_SIZE, PATCH_SIZE\n",
    "            ),\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            epochs=EPOCHS,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            validation_data=create_minibatch(\n",
    "                X_val, Y_val, n_val, WINDOW_SIZE, BATCH_SIZE, PATCH_SIZE\n",
    "            ),\n",
    "            validation_steps=STEPS_PER_EPOCH / 3,\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def classify(self, X):\n",
    "        \"\"\"Classify Image as either road or not.\n",
    "        Args:\n",
    "            X (image): part of the image to classify\n",
    "        Returns:\n",
    "            Predictions : Predictions for each patch\n",
    "        \"\"\"\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return predictions.reshape(X.shape[0], -1)\n",
    "\n",
    "    #         return group_patches(predictions, X.shape[0])\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"Loads Saved Model.\n",
    "        Args:\n",
    "           filename (string): name of the model\n",
    "           \n",
    "        \"\"\"\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"Saves trained model.\n",
    "        Args:\n",
    "           filename (string): name of the model\n",
    "           \n",
    "        \"\"\"\n",
    "        self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 3)    12          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 64, 64, 64)   4864        batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 64)   256         max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 128)  204928      batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 128)  512         max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 256)  819456      batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 512)    3277312     batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 4, 4, 512)    0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 4, 4, 512)    2048        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 4, 4, 1024)   13108224    batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 4, 4, 1024)   9438208     conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 4, 4, 1024)   4096        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 8, 8, 1024)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 512)    2097664     up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 8, 8, 1024)   0           conv2d_73[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 512)    13107712    concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 512)    2048        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 16, 16, 512)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 256)  524544      up_sampling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 512)  0           conv2d_71[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 256)  3277056     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 32, 32, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 128)  131200      up_sampling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 256)  0           conv2d_69[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 128)  819328      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 128)  512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 64, 64, 128)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 64, 64, 64)   32832       up_sampling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 128)  0           conv2d_67[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 64, 64, 64)   204864      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 262144)       0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           16777280    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 64)           256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            130         batch_normalization_42[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 70,106,190\n",
      "Trainable params: 70,100,296\n",
      "Non-trainable params: 5,894\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We define parameters of the model\n",
    "BATCH_SIZE = 50\n",
    "WINDOW_SIZE = 64\n",
    "PATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = 50\n",
    "model = U_NET(shape=(WINDOW_SIZE, WINDOW_SIZE, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.7506 - accuracy: 0.5920 - recall: 0.5690 - f1: 0.5809\n",
      "Epoch 00001: val_loss improved from inf to 0.66485, saving model to Unet_batchnorm-001-0.579527.h5\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.7520 - accuracy: 0.5906 - recall: 0.5676 - f1: 0.5795 - val_loss: 0.6649 - val_accuracy: 0.6165 - val_recall: 0.8718 - val_f1: 0.6947\n",
      "Epoch 2/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.6072 - accuracy: 0.7045 - recall: 0.6788 - f1: 0.6952\n",
      "Epoch 00002: val_loss did not improve from 0.66485\n",
      "50/50 [==============================] - 39s 772ms/step - loss: 0.6080 - accuracy: 0.7030 - recall: 0.6772 - f1: 0.6936 - val_loss: 0.9154 - val_accuracy: 0.7612 - val_recall: 0.7612 - val_f1: 0.7612\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7478 - recall: 0.7380 - f1: 0.7452\n",
      "Epoch 00003: val_loss improved from 0.66485 to 0.65093, saving model to Unet_batchnorm-003-0.746356.h5\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 0.5480 - accuracy: 0.7488 - recall: 0.7396 - f1: 0.7464 - val_loss: 0.6509 - val_accuracy: 0.7141 - val_recall: 0.6435 - val_f1: 0.6914\n",
      "Epoch 4/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.7516 - recall: 0.7478 - f1: 0.7502\n",
      "Epoch 00004: val_loss improved from 0.65093 to 0.57907, saving model to Unet_batchnorm-004-0.750539.h5\n"
     ]
    }
   ],
   "source": [
    "history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"Unet_batchnorm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = False\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(64, 64, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\n",
    "#     \"RealUnet_relu_regularized_onedense_batchnorm_dropout_validation-010-0.894333.h5\"\n",
    "# )\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = (\n",
    "#     \"RealUnet_relu_regularized_onedense_batchnorm_dropout_validation-010-0.894333.csv\"\n",
    "# )\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a set of images\n",
    "# root_dir = \"data/training/\"\n",
    "\n",
    "# # Select the directory for the images and load them\n",
    "# image_dir = root_dir + \"images/\"\n",
    "# files = os.listdir(image_dir)\n",
    "# n = len(files)\n",
    "\n",
    "# print(\"Loading \" + str(n) + \" images\")\n",
    "# imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "# # Select the directory for groundtruth images and load them\n",
    "# gt_dir = root_dir + \"groundtruth/\"\n",
    "# print(\"Loading \" + str(n) + \" groundtruth images\")\n",
    "# gt_imgs = np.asarray([load_image(gt_dir + files[i]) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 400\n",
    "\n",
    "# # We separate the images from the groundtruth images\n",
    "# img_patches = [img_crop(imgs[i], image_size, image_size) for i in range(n)]\n",
    "# gt_patches = [img_crop(gt_imgs[i], image_size, image_size) for i in range(n)]\n",
    "\n",
    "# # Linearize the list and labeling them X and Y\n",
    "# X = np.asarray(\n",
    "#     [\n",
    "#         img_patches[i][j]\n",
    "#         for i in range(len(img_patches))\n",
    "#         for j in range(len(img_patches[i]))\n",
    "#     ]\n",
    "# )\n",
    "# Y = np.asarray(\n",
    "#     [\n",
    "#         gt_patches[i][j]\n",
    "#         for i in range(len(gt_patches))\n",
    "#         for j in range(len(gt_patches[i]))\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_minibatch():\n",
    "\n",
    "#     # Fix the seed\n",
    "#     np.random.seed(1)\n",
    "\n",
    "#     # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "#     # and patch size should correspond to 16\n",
    "#     w_size = 72\n",
    "#     batch_size = 100\n",
    "#     patch_size = 16\n",
    "#     num_images = 100\n",
    "\n",
    "#     while True:\n",
    "#         # Generate one minibatch\n",
    "#         batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "#         batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "#         for i in range(batch_size):\n",
    "\n",
    "#             # Select a random index represnting an image\n",
    "#             random_index = np.random.choice(num_images)\n",
    "\n",
    "#             # Width of original image\n",
    "#             width = 400\n",
    "\n",
    "#             # Sample a random window from the image\n",
    "#             random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "#             # Create a sub image of size 72x72\n",
    "#             sampled_image = X[random_index][\n",
    "#                 random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "#                 random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # Take its corresponding ground-truth image\n",
    "#             correspond_ground_truth = Y[random_index][\n",
    "#                 random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "#                 random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # We set in the label depending on the threshold of 0.2\n",
    "#             # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "#             label = to_categorical(\n",
    "#                 (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "#             )\n",
    "\n",
    "#             # The image augmentation is based on both flipping and rotating (randomly in steps of 45°)\n",
    "#             # Random vertical and horizontal flip\n",
    "#             if np.random.choice(2) == 1:\n",
    "#                 sampled_image = np.flipud(sampled_image)\n",
    "\n",
    "#             if np.random.choice(2) == 1:\n",
    "#                 sampled_image = np.fliplr(sampled_image)\n",
    "\n",
    "#             # Random rotation in steps of 45°\n",
    "#             rotations = [0, 45, 90, 135, 180, 225, 270, 315, 350]\n",
    "\n",
    "#             # We select a rotation degree randomly\n",
    "#             rotation_choice = np.random.choice(len(rotations))\n",
    "\n",
    "#             # Rotate it using the random value (uses the scipy library)\n",
    "#             sampled_image = scipy.ndimage.rotate(\n",
    "#                 sampled_image,\n",
    "#                 rotations[rotation_choice],\n",
    "#                 order=1,\n",
    "#                 reshape=False,\n",
    "#                 mode=\"reflect\",\n",
    "#             )\n",
    "\n",
    "#             # We put in the sub image and its corresponding label before yielding it\n",
    "#             batch_image[i] = sampled_image\n",
    "#             batch_label[i] = label\n",
    "\n",
    "#         # Yield the mini_batch to the model\n",
    "#         yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def down(input_layer, filters, pool=True):\n",
    "#     conv1 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(input_layer)\n",
    "#     residual = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "#     if pool:\n",
    "#         max_pool = MaxPool2D()(residual)\n",
    "#         return max_pool, residual\n",
    "#     else:\n",
    "#         return residual\n",
    "\n",
    "\n",
    "# def up(input_layer, residual, filters):\n",
    "#     filters = int(filters)\n",
    "#     upsample = UpSampling2D()(input_layer)\n",
    "#     upconv = Conv2D(filters, kernel_size=(2, 2), padding=\"same\")(upsample)\n",
    "#     concat = Concatenate(axis=3)([residual, upconv])\n",
    "#     conv1 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(concat)\n",
    "#     conv2 = Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "#     return conv2\n",
    "\n",
    "\n",
    "# class cnn_model:\n",
    "\n",
    "#     # Initialize the class\n",
    "#     def __init__(self, shape, batch_normalization, activation):\n",
    "#         self.shape = shape\n",
    "#         self.batch_normalization = batch_normalization\n",
    "#         self.activation = activation\n",
    "#         self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "#     def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "#         # Make a custom U-nets implementation.\n",
    "#         filters = 64\n",
    "#         input_layer = Input(shape=[128, 128, 3])\n",
    "#         layers = [input_layer]\n",
    "#         residuals = []\n",
    "\n",
    "#         # Down 1, 128\n",
    "#         d1, res1 = down(input_layer, filters)\n",
    "#         residuals.append(res1)\n",
    "#         filters *= 2\n",
    "\n",
    "#         # Down 2, 64\n",
    "#         d2, res2 = down(d1, filters)\n",
    "#         residuals.append(res2)\n",
    "#         filters *= 2\n",
    "\n",
    "#         # Down 3, 32\n",
    "#         d3, res3 = down(d2, filters)\n",
    "#         residuals.append(res3)\n",
    "#         filters *= 2\n",
    "\n",
    "#         # Down 4, 16\n",
    "#         d4, res4 = down(d3, filters)\n",
    "#         residuals.append(res4)\n",
    "#         filters *= 2\n",
    "\n",
    "#         # Down 5, 8\n",
    "#         d5 = down(d4, filters, pool=False)\n",
    "\n",
    "#         # Up 1, 16\n",
    "#         up1 = up(d5, residual=residuals[-1], filters=filters / 2)\n",
    "#         filters /= 2\n",
    "\n",
    "#         # Up 2,  32\n",
    "#         up2 = up(up1, residual=residuals[-2], filters=filters / 2)\n",
    "#         filters /= 2\n",
    "\n",
    "#         # Up 3, 64\n",
    "#         up3 = up(up2, residual=residuals[-3], filters=filters / 2)\n",
    "#         filters /= 2\n",
    "\n",
    "#         # Up 4, 128\n",
    "#         up4 = up(up3, residual=residuals[-4], filters=filters / 2)\n",
    "#         out = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(up4)\n",
    "\n",
    "#         model = Model(input_layer, out)\n",
    "#         model.compile(\n",
    "#             loss=\"binary_crossentropy\",\n",
    "#             optimizer=Adam(lr=0.001),\n",
    "#             metrics=[\"accuracy\", recall, f1],\n",
    "#         )\n",
    "\n",
    "#         # Print a summary of the model to see what has been generated\n",
    "#         model.summary()\n",
    "\n",
    "#         return model\n",
    "\n",
    "#     def train(self):\n",
    "\n",
    "#         # Early stopping callback after 10 steps\n",
    "#         early_stopping = EarlyStopping(\n",
    "#             monitor=\"f1\", min_delta=0.5, patience=20, verbose=0, mode=\"max\"\n",
    "#         )\n",
    "\n",
    "#         # Reduce learning rate on plateau after 4 steps\n",
    "#         lr_callback = ReduceLROnPlateau(\n",
    "#             monitor=\"f1\", factor=0.5, patience=4, verbose=0, mode=\"max\"\n",
    "#         )\n",
    "\n",
    "#         # Place the callbacks in a list to be used when training\n",
    "#         #         callbacks = [cb, early_stopping, lr_callback]\n",
    "#         save_best = ModelCheckpoint(\n",
    "#             \"batch_relu_OLD_Ali_amsgrad_noise-{epoch:03d}-{f1:03f}.h5\",\n",
    "#             save_best_only=True,\n",
    "#             monitor=\"f1\",\n",
    "#             mode=\"max\",\n",
    "#             verbose=1,\n",
    "#         )\n",
    "\n",
    "#         callbacks = [lr_callback, save_best]\n",
    "\n",
    "#         # Train the model using the previously defined functions and callbacks\n",
    "#         history = self.model.fit_generator(\n",
    "#             create_minibatch(),\n",
    "#             steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#             epochs=EPOCHS,\n",
    "#             use_multiprocessing=False,\n",
    "#             workers=1,\n",
    "#             callbacks=callbacks,\n",
    "#             verbose=1,\n",
    "#         )\n",
    "\n",
    "#         return history\n",
    "\n",
    "#     def classify(self, X):\n",
    "#         # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "#         img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "#         # Predict\n",
    "#         predictions = self.model.predict(img_patches)\n",
    "#         predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "#         # Regroup patches into images\n",
    "#         return group_patches(predictions, X.shape[0])\n",
    "\n",
    "#     def load(self, filename):\n",
    "#         # Load the model (used for submission)\n",
    "#         dependencies = {\n",
    "#             \"recall\": recall,\n",
    "#             \"f1\": f1,\n",
    "#         }\n",
    "#         self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "#     def save(self, filename):\n",
    "#         # Save the model (used to then load to submit)\n",
    "#         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# EPOCHS = 120\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# batch_normalization = True\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# history = model.train()\n",
    "# model.save(\"batch_relu_OLD_Ali_amsgrad_noise.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# # plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# # plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"batch_relu_OLD_Ali_amsgrad_noise.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = True\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\"batch_relu_OLD_Ali_amsgrad_noise-092-0.952039.h5\")\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = \"batch_relu_OLD_Ali_amsgrad_noise-092-0.952039.csv\"\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# # We define the number of epochs and steps per epochs\n",
    "# EPOCHS = 160\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# batch_normalization = True\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model\n",
    "# history = model.train()\n",
    "# # model.save(\"no_batch_LeakyRelu_validation_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"batch_LeakyReLU_validation_160_dropout-0.2.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = True\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\n",
    "#     \"saved_models/batch_LeakyReLU_validation_160_dropout-0.2-070-0.948567-0.928000.h5\"\n",
    "# )\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = \"to_submit_csv/batch_LeakyReLU_validation_160_dropout-0.2-070-0.948567-0.928000.csv\"\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history.history[\"loss\"]\n",
    "# print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history[\"accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "# plt.title(\"model accuracy\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# N = EPOCHS\n",
    "# print(N)\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.show()\n",
    "# plt.savefig(\"model1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = False\n",
    "# EPOCHS = 200\n",
    "\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# model.train()\n",
    "# model.save(\"no_batch_relu_validation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = True\n",
    "# EPOCHS = 200\n",
    "\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# model.train()\n",
    "# model.save(\"batch_LeakyReLU_validation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = True\n",
    "# EPOCHS = 200\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# history = model.train()\n",
    "# # model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"batch_relu_validation_200.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = True\n",
    "# activation = \"relu\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\"batch_relu_validation_200-145-0.951267-0.930033.h5\")\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = \"batch_relu_validation_200-145-0.951267-0.930033.csv\"\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = True\n",
    "# EPOCHS = 160\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# history = model.train()\n",
    "# # model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"batch_LeakyReLU_validation_160.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = True\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\"batch_relu_validation_200-074-0.946167-0.927667.h5\")\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = \"batch_relu_validation_200-074-0.946167-0.927667.csv\"\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW BATCH ERICK V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy as scipy\n",
    "\n",
    "\n",
    "# def pad_matrix(mat, h_pad, w_pad, val=0):\n",
    "#     h_pad = int(h_pad)\n",
    "#     w_pad = int(w_pad)\n",
    "#     if len(mat.shape) == 3:\n",
    "#         padded_mat = np.pad(\n",
    "#             mat,\n",
    "#             ((h_pad, h_pad), (w_pad, w_pad), (0, 0)),\n",
    "#             mode=\"constant\",\n",
    "#             constant_values=((val, val), (val, val), (0, 0)),\n",
    "#         )\n",
    "#     elif len(mat.shape) == 2:\n",
    "#         padded_mat = np.pad(\n",
    "#             mat,\n",
    "#             ((h_pad, h_pad), (w_pad, w_pad)),\n",
    "#             mode=\"constant\",\n",
    "#             constant_values=((val, val), (val, val)),\n",
    "#         )\n",
    "#     else:\n",
    "#         raise ValueError(\"This method can only handle 2d or 3d arrays\")\n",
    "#     return padded_mat\n",
    "\n",
    "\n",
    "# def imag_rotation(X, Y, number_rotations=8):\n",
    "\n",
    "#     w = X.shape[1]\n",
    "#     w_2 = w // 2  # half of the width\n",
    "#     padding = 82\n",
    "#     Xrs = X\n",
    "#     Yrs = Y\n",
    "#     Xrs = np.expand_dims(Xrs, 0)\n",
    "#     Yrs = np.expand_dims(Yrs, 0)\n",
    "#     thetas = np.random.randint(0, high=360, size=number_rotations)\n",
    "#     for theta in thetas:\n",
    "#         Xr = pad_matrix(\n",
    "#             X, padding, padding\n",
    "#         )  # Selected for the specific case of images of (400,400)\n",
    "#         Yr = pad_matrix(\n",
    "#             Y, padding, padding\n",
    "#         )  # Selected for the specific case of images of (400,400)\n",
    "#         Xr = scipy.ndimage.rotate(Xr, theta, reshape=False)\n",
    "#         Yr = scipy.ndimage.rotate(Yr, theta, reshape=False)\n",
    "#         theta = theta * np.pi / 180\n",
    "#         a = int(\n",
    "#             w_2 / (np.sqrt(2) * np.cos(np.pi / 4 - np.mod(theta, np.pi / 2)))\n",
    "#         )  # width and height of the biggest square inside the rotated square\n",
    "#         w_p = w_2 + padding\n",
    "#         Xr = Xr[w_p - a : w_p + a, w_p - a : w_p + a, :]\n",
    "#         Yr = Yr[w_p - a : w_p + a, w_p - a : w_p + a]\n",
    "\n",
    "#         Xr = cv2.resize(Xr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "#         Yr = cv2.resize(Yr, dsize=(w_2 * 2, w_2 * 2), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "#         if np.random.choice(2) == 1:\n",
    "#             Xr = np.flipud(Xr)\n",
    "#             Yr = np.flipud(Yr)\n",
    "\n",
    "#         if np.random.choice(2) == 1:\n",
    "#             Xr = np.fliplr(Xr)\n",
    "#             Yr = np.fliplr(Yr)\n",
    "\n",
    "#         Xr = np.expand_dims(Xr, 0)\n",
    "#         Yr = np.expand_dims(Yr, 0)\n",
    "#         Xrs = np.append(Xrs, Xr, axis=0)\n",
    "#         Yrs = np.append(Yrs, Yr, axis=0)\n",
    "\n",
    "#     return Xrs, Yrs\n",
    "\n",
    "\n",
    "# def imag_rotation_aug(Xr, Yr, number_rotations=8):\n",
    "\n",
    "#     Xrs, Yrs = imag_rotation(Xr[0], Yr[0])\n",
    "#     for i in range(1, len(Xr)):\n",
    "#         Xrr, Yrr = imag_rotation(Xr[i], Yr[i])\n",
    "#         Xrs = np.append(Xrs, Xrr, axis=0)\n",
    "#         Yrs = np.append(Yrs, Yrr, axis=0)\n",
    "\n",
    "#     Xrs_shuf = []\n",
    "#     Yrs_shuf = []\n",
    "#     index_shuf = list(range(len(Xrs)))\n",
    "#     np.random.shuffle(index_shuf)\n",
    "#     for i in index_shuf:\n",
    "#         Xrs_shuf.append(Xrs[i])\n",
    "#         Yrs_shuf.append(Yrs[i])\n",
    "\n",
    "#     return Xrs_shuf, Yrs_shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a set of images\n",
    "# root_dir = \"data/\"\n",
    "\n",
    "# # Select the directory for the images and load them\n",
    "# image_dir_train = root_dir + \"training/images/\"\n",
    "# files = os.listdir(image_dir_train)\n",
    "# n_train = len(files)\n",
    "\n",
    "# print(\"Loading \" + str(n_train) + \" images\")\n",
    "# imgs_train = np.asarray(\n",
    "#     [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    "# )\n",
    "\n",
    "# # Select the directory for groundtruth images and load them\n",
    "# gt_dir_train = root_dir + \"training/groundtruth/\"\n",
    "# print(\"Loading \" + str(n_train) + \" groundtruth images\")\n",
    "# gt_imgs_train = np.asarray(\n",
    "#     [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the directory for the images and load them\n",
    "# image_dir_val = root_dir + \"validating/images/\"\n",
    "# files = os.listdir(image_dir_val)\n",
    "# n_val = len(files)\n",
    "\n",
    "# print(\"Loading \" + str(n_val) + \" images\")\n",
    "# imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "\n",
    "# # Select the directory for groundtruth images and load them\n",
    "# gt_dir_val = root_dir + \"validating/groundtruth/\"\n",
    "# print(\"Loading \" + str(n_val) + \" groundtruth images\")\n",
    "# gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, Y_train = imag_rotation_aug(imgs_train, gt_imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val, Y_val = imag_rotation_aug(imgs_val, gt_imgs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_minibatch(X, Y, n):\n",
    "\n",
    "#     # Fix the seed\n",
    "#     np.random.seed(1)\n",
    "\n",
    "#     # We define the window size of 72, batch size of 100 (empirically chosen)\n",
    "#     # and patch size should correspond to 16\n",
    "#     w_size = 72\n",
    "#     batch_size = 80\n",
    "#     patch_size = 72\n",
    "#     num_images = n\n",
    "\n",
    "#     while True:\n",
    "#         # Generate one minibatch\n",
    "#         batch_image = np.empty((batch_size, w_size, w_size, 3))\n",
    "#         batch_label = np.empty((batch_size, 2))\n",
    "\n",
    "#         for i in range(batch_size):\n",
    "\n",
    "#             # Select a random index representing an image\n",
    "#             random_index = np.random.choice(num_images)\n",
    "\n",
    "#             # Width of original image\n",
    "#             width = 400\n",
    "\n",
    "#             # Sample a random window from the image\n",
    "#             random_sample = np.random.randint(w_size // 2, width - w_size // 2, 2)\n",
    "\n",
    "#             # Create a sub image of size 72x72\n",
    "#             sampled_image = X[random_index][\n",
    "#                 random_sample[0] - w_size // 2 : random_sample[0] + w_size // 2,\n",
    "#                 random_sample[1] - w_size // 2 : random_sample[1] + w_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # Take its corresponding ground-truth image\n",
    "#             correspond_ground_truth = Y[random_index][\n",
    "#                 random_sample[0] - patch_size // 2 : random_sample[0] + patch_size // 2,\n",
    "#                 random_sample[1] - patch_size // 2 : random_sample[1] + patch_size // 2,\n",
    "#             ]\n",
    "\n",
    "#             # We set in the label depending on the threshold of 0.2\n",
    "#             # The label becomes either 0 or 1 by applying to_categorical with parameter 2\n",
    "#             label = to_categorical(\n",
    "#                 (np.array([np.mean(correspond_ground_truth)]) > 0.2) * 1, 2\n",
    "#             )\n",
    "\n",
    "#             # We put in the sub image and its corresponding label before yielding it\n",
    "#             batch_image[i] = sampled_image\n",
    "#             batch_label[i] = label\n",
    "\n",
    "#         # Yield the mini_batch to the model\n",
    "#         yield (batch_image, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cnn_model:\n",
    "\n",
    "#     # Initialize the class\n",
    "#     def __init__(self, shape, batch_normalization, activation):\n",
    "#         self.shape = shape\n",
    "#         self.batch_normalization = batch_normalization\n",
    "#         self.activation = activation\n",
    "#         self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "#     def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "#         #         print(activation)\n",
    "\n",
    "#         # INPUT\n",
    "#         # shape     - Size of the input images\n",
    "#         # OUTPUT\n",
    "#         # model    - Compiled CNN\n",
    "\n",
    "#         # Define hyperparamters\n",
    "#         KERNEL3 = (3, 3)\n",
    "#         KERNEL5 = (5, 5)\n",
    "\n",
    "#         # Define a model\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Add the layers\n",
    "#         # Selection of the model is described in the report\n",
    "#         # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "#         model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "#         # Flatten it and use regularizers to avoid overfitting\n",
    "#         # The parameters have been chosen empirically\n",
    "#         model.add(Flatten())\n",
    "#         model.add(\n",
    "#             Dense(128, kernel_regularizer=l2(0.0001), activity_regularizer=l2(0.0001))\n",
    "#         )\n",
    "#         #         if batch_normalization:\n",
    "#         #             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         # Add output layer\n",
    "#         model.add(\n",
    "#             Dense(2, kernel_regularizer=l2(0.0001), activity_regularizer=l2(0.0001))\n",
    "#         )\n",
    "#         model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#         # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "#         # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "#         model.compile(\n",
    "#             loss=\"binary_crossentropy\",\n",
    "#             optimizer=Adam(lr=0.001),\n",
    "#             metrics=[\"accuracy\", recall, f1],\n",
    "#         )\n",
    "\n",
    "#         # Print a summary of the model to see what has been generated\n",
    "#         model.summary()\n",
    "\n",
    "#         return model\n",
    "\n",
    "#     def train(self):\n",
    "\n",
    "#         # Early stopping callback after 10 steps\n",
    "#         early_stopping = EarlyStopping(\n",
    "#             monitor=\"val_loss\",\n",
    "#             min_delta=0,\n",
    "#             patience=15,\n",
    "#             verbose=1,\n",
    "#             mode=\"auto\",\n",
    "#             restore_best_weights=True,\n",
    "#         )\n",
    "\n",
    "#         # Reduce learning rate on plateau after 4 steps\n",
    "#         lr_callback = ReduceLROnPlateau(\n",
    "#             monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "#         )\n",
    "#         save_best = ModelCheckpoint(\n",
    "#             \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5\",\n",
    "#             save_best_only=True,\n",
    "#             monitor=\"val_loss\",\n",
    "#             mode=\"auto\",\n",
    "#             verbose=1,\n",
    "#         )\n",
    "\n",
    "#         # Place the callbacks in a list to be used when training\n",
    "#         #         callbacks = [cb, early_stopping, lr_callback]\n",
    "#         callbacks = [save_best, lr_callback]\n",
    "\n",
    "#         # Train the model using the previously defined functions and callbacks\n",
    "#         history = self.model.fit_generator(\n",
    "#             create_minibatch(X_train, Y_train, n_train * 9),\n",
    "#             steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#             epochs=EPOCHS,\n",
    "#             use_multiprocessing=False,\n",
    "#             workers=1,\n",
    "#             callbacks=callbacks,\n",
    "#             verbose=1,\n",
    "#             validation_data=create_minibatch(X_val, Y_val, n_val * 9),\n",
    "#             validation_steps=STEPS_PER_EPOCH,\n",
    "#         )\n",
    "#         #         to_plot = self.model.fit_generator(\n",
    "#         #             create_minibatch(X_train, Y_train, n_train),\n",
    "#         #             steps_per_epoch=100,\n",
    "#         #             epochs=EPOCHS,\n",
    "#         #             use_multiprocessing=False,\n",
    "#         #             workers=1,\n",
    "#         #             callbacks=callbacks,\n",
    "#         #             verbose=1,\n",
    "#         #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "#         #             validation_steps=100,\n",
    "#         #         )\n",
    "#         return history\n",
    "\n",
    "#     def classify(self, X):\n",
    "#         # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "#         img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "#         # Predict\n",
    "#         predictions = self.model.predict(img_patches)\n",
    "#         predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "#         # Regroup patches into images\n",
    "#         return group_patches(predictions, X.shape[0])\n",
    "\n",
    "#     def load(self, filename):\n",
    "#         # Load the model (used for submission)\n",
    "#         dependencies = {\n",
    "#             \"recall\": recall,\n",
    "#             \"f1\": f1,\n",
    "#         }\n",
    "#         self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "# #     def save(self, filename):\n",
    "# #         # Save the model (used to then load to submit)\n",
    "# #         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = True\n",
    "# EPOCHS = 200\n",
    "# # EPOCHS = 2\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# history = model.train()\n",
    "# # model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"batch_LeakyReLU_validation_erickv7.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = True\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\n",
    "#     \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-099-0.956417-0.907208.h5\"\n",
    "# )\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = (\n",
    "#     \"batch_LeakyReLU_validation_160_dropout-0.2_erickAugv7-099-0.956417-0.907208.csv\"\n",
    "# )\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cnn_model:\n",
    "\n",
    "#     # Initialize the class\n",
    "#     def __init__(self, shape, batch_normalization, activation):\n",
    "#         self.shape = shape\n",
    "#         self.batch_normalization = batch_normalization\n",
    "#         self.activation = activation\n",
    "#         self.model = self.initialize_cnn_model(shape, batch_normalization, activation)\n",
    "\n",
    "#     def initialize_cnn_model(self, shape, batch_normalization, activation):\n",
    "#         #         print(activation)\n",
    "\n",
    "#         # INPUT\n",
    "#         # shape     - Size of the input images\n",
    "#         # OUTPUT\n",
    "#         # model    - Compiled CNN\n",
    "\n",
    "#         # Define hyperparamters\n",
    "#         KERNEL3 = (3, 3)\n",
    "#         KERNEL5 = (5, 5)\n",
    "\n",
    "#         # Define a model\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Add the layers\n",
    "#         # Selection of the model is described in the report\n",
    "#         # We use padding = 'same' to avoid issues with the matrix sizes\n",
    "#         model.add(Conv2D(64, KERNEL5, input_shape=shape, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Conv2D(128, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Conv2D(256, KERNEL3, padding=\"same\"))\n",
    "#         if batch_normalization:\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         # Flatten it and use regularizers to avoid overfitting\n",
    "#         # The parameters have been chosen empirically\n",
    "#         model.add(Flatten())\n",
    "#         model.add(\n",
    "#             Dense(128, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001))\n",
    "#         )\n",
    "#         #         if batch_normalization:\n",
    "#         #             model.add(BatchNormalization())\n",
    "#         model.add(LeakyReLU(alpha=0.1)) if activation == \"LeakyReLU\" else model.add(\n",
    "#             Activation(activation)\n",
    "#         )\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         # Add output layer\n",
    "#         model.add(\n",
    "#             Dense(2, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001))\n",
    "#         )\n",
    "#         model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#         # Compile the model using the binary crossentropy loss and the Adam optimizer for it\n",
    "#         # We used the accuracy as a metric, but F1 score is also a plausible choice\n",
    "#         model.compile(\n",
    "#             loss=\"binary_crossentropy\",\n",
    "#             optimizer=Adam(lr=0.0005, amsgrad=True),\n",
    "#             metrics=[\"accuracy\", recall, f1],\n",
    "#         )\n",
    "\n",
    "#         # Print a summary of the model to see what has been generated\n",
    "#         model.summary()\n",
    "\n",
    "#         return model\n",
    "\n",
    "#     def train(self):\n",
    "\n",
    "#         # Early stopping callback after 10 steps\n",
    "#         early_stopping = EarlyStopping(\n",
    "#             monitor=\"val_loss\",\n",
    "#             min_delta=0,\n",
    "#             patience=15,\n",
    "#             verbose=1,\n",
    "#             mode=\"auto\",\n",
    "#             restore_best_weights=True,\n",
    "#         )\n",
    "\n",
    "#         # Reduce learning rate on plateau after 4 steps\n",
    "#         lr_callback = ReduceLROnPlateau(\n",
    "#             monitor=\"loss\", factor=0.5, patience=4, verbose=1, mode=\"auto\"\n",
    "#         )\n",
    "#         save_best = ModelCheckpoint(\n",
    "#             \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5\",\n",
    "#             save_best_only=True,\n",
    "#             monitor=\"val_f1\",\n",
    "#             mode=\"max\",\n",
    "#             verbose=1,\n",
    "#         )\n",
    "\n",
    "#         # Place the callbacks in a list to be used when training\n",
    "#         #         callbacks = [cb, early_stopping, lr_callback]\n",
    "#         callbacks = [save_best, lr_callback]\n",
    "\n",
    "#         # Train the model using the previously defined functions and callbacks\n",
    "#         history = self.model.fit_generator(\n",
    "#             create_minibatch(X_train, Y_train, n_train * 9),\n",
    "#             steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#             epochs=EPOCHS,\n",
    "#             use_multiprocessing=False,\n",
    "#             workers=1,\n",
    "#             callbacks=callbacks,\n",
    "#             verbose=1,\n",
    "#             validation_data=create_minibatch(X_val, Y_val, n_val * 9),\n",
    "#             validation_steps=STEPS_PER_EPOCH,\n",
    "#         )\n",
    "#         #         to_plot = self.model.fit_generator(\n",
    "#         #             create_minibatch(X_train, Y_train, n_train),\n",
    "#         #             steps_per_epoch=100,\n",
    "#         #             epochs=EPOCHS,\n",
    "#         #             use_multiprocessing=False,\n",
    "#         #             workers=1,\n",
    "#         #             callbacks=callbacks,\n",
    "#         #             verbose=1,\n",
    "#         #             validation_data=create_minibatch(X_val, Y_val, n_val),\n",
    "#         #             validation_steps=100,\n",
    "#         #         )\n",
    "#         return history\n",
    "\n",
    "#     def classify(self, X):\n",
    "#         # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "#         img_patches = create_patches(X, 16, 16, padding=28)\n",
    "\n",
    "#         # Predict\n",
    "#         predictions = self.model.predict(img_patches)\n",
    "#         predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "#         # Regroup patches into images\n",
    "#         return group_patches(predictions, X.shape[0])\n",
    "\n",
    "#     def load(self, filename):\n",
    "#         # Load the model (used for submission)\n",
    "#         dependencies = {\n",
    "#             \"recall\": recall,\n",
    "#             \"f1\": f1,\n",
    "#         }\n",
    "#         self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "\n",
    "# #     def save(self, filename):\n",
    "# #         # Save the model (used to then load to submit)\n",
    "# #         self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model with the size 72x72, the window size of the images to be fed\n",
    "# batch_normalization = True\n",
    "# EPOCHS = 150\n",
    "# # EPOCHS = 2\n",
    "# STEPS_PER_EPOCH = 150\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "# # Train the model with batch\n",
    "# history = model.train()\n",
    "# # model.save(\"batch_relu_validation_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(history.history[\"f1\"], label=\"train_f1\")\n",
    "# plt.plot(history.history[\"val_f1\"], label=\"val_f1\")\n",
    "# plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(\"batch_LeakyReLU_validation_erickv7_dropout0.5_adagram.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import *\n",
    "\n",
    "# # from cnn_model import cnn_model\n",
    "\n",
    "# # Instantiate the model\n",
    "# batch_normalization = True\n",
    "# activation = \"LeakyReLU\"\n",
    "# model = cnn_model(\n",
    "#     shape=(72, 72, 3), batch_normalization=batch_normalization, activation=activation\n",
    "# )\n",
    "\n",
    "# # Load the model\n",
    "# model.load(\n",
    "#     \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-074-0.912500-0.858625.h5\"\n",
    "# )\n",
    "\n",
    "# # Print a summary to make sure the correct model is used\n",
    "# model.model.summary()\n",
    "\n",
    "# # We add all test images to an array, used later for generating a submission\n",
    "# image_filenames = []\n",
    "# for i in range(1, 51):\n",
    "#     image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "#     image_filenames.append(image_filename)\n",
    "\n",
    "# # Set-up submission filename\n",
    "# submission_filename = (\n",
    "#     \"batch_LeakyReLU_validation_200_dropout-0.5_erickAugv7-074-0.912500-0.858625.csv\"\n",
    "# )\n",
    "\n",
    "# # Generates the submission\n",
    "# generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
