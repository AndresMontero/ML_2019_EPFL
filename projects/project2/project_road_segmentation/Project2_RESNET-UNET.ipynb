{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose \n",
    "from tensorflow.compat.v2.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.python.client import device_lib\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = \"data/training/images/\"\n",
    "files = os.listdir(image_dir_train)\n",
    "n_train = len(files)\n",
    "print(f\"Loading training images, images loaded: {n_train} \")\n",
    "imgs_train = np.asarray(\n",
    "    [load_image(image_dir_train + files[i]) for i in range(n_train)]\n",
    ")\n",
    "gt_dir_train = \"data/training/groundtruth/\"\n",
    "print(f\"Loading groundtruth images, images loaded: {n_train} \")\n",
    "gt_imgs_train = np.asarray(\n",
    "    [load_image(gt_dir_train + files[i]) for i in range(n_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 400\n",
    "# Patches for training\n",
    "img_patches_train = [\n",
    "    crop_image(imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "gt_patches_train = [\n",
    "    crop_image(gt_imgs_train[i], image_size, image_size) for i in range(n_train)\n",
    "]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = np.asarray(\n",
    "    [\n",
    "        img_patches_train[i][j]\n",
    "        for i in range(len(img_patches_train))\n",
    "        for j in range(len(img_patches_train[i]))\n",
    "    ]\n",
    ")\n",
    "Y_train = np.asarray(\n",
    "    [\n",
    "        gt_patches_train[i][j]\n",
    "        for i in range(len(gt_patches_train))\n",
    "        for j in range(len(gt_patches_train[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_val = \"data/validating/images/\"\n",
    "files = os.listdir(image_dir_val)\n",
    "n_val = len(files)\n",
    "print(f\"Loading validating images, images loaded: {n_val} \")\n",
    "imgs_val = np.asarray([load_image(image_dir_val + files[i]) for i in range(n_val)])\n",
    "gt_dir_val = \"data/validating/groundtruth/\"\n",
    "print(f\"Loading validating groundtruth, images loaded: {n_val} \")\n",
    "gt_imgs_val = np.asarray([load_image(gt_dir_val + files[i]) for i in range(n_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patches for validating\n",
    "img_patches_val = [\n",
    "    crop_image(imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "]\n",
    "gt_patches_val = [\n",
    "    crop_image(gt_imgs_val[i], image_size, image_size) for i in range(n_val)\n",
    "]\n",
    "\n",
    "# Separate features and labels\n",
    "X_val = np.asarray(\n",
    "    [\n",
    "        img_patches_val[i][j]\n",
    "        for i in range(len(img_patches_val))\n",
    "        for j in range(len(img_patches_val[i]))\n",
    "    ]\n",
    ")\n",
    "Y_val = np.asarray(\n",
    "    [\n",
    "        gt_patches_val[i][j]\n",
    "        for i in range(len(gt_patches_val))\n",
    "        for j in range(len(gt_patches_val[i]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "n_train = Y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "n_val = Y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions to calcualte precision, recall and F-1 in the training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Compute the Precision for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "        Precision (numpy.float64): the Precision of the batch \n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Compute the Recall for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "       Recall (numpy.float64): the Recal of the batch \n",
    "    \"\"\"\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Compute the F-1 for the batch.\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): the ground truth labels\n",
    "        y_pred (numpy.ndarray): the predicted labels \n",
    "    Returns:\n",
    "       F-1 (numpy.float64): the F-1 of the batch \n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-UNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_unet_model:\n",
    "    \"\"\" This class creates the ResNet-UNet model\n",
    "    \n",
    "    Loads a ResNet50 with the weights pre-trained on the \"Imagenet\" \n",
    "    dataset, then adds decoder blocks and finally a block with dense\n",
    "    layers\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, shape, batch_normalization, activation, dropout, amsgrad=False, lr=1e-4\n",
    "    ):\n",
    "        \"\"\"Initialize the resnet_unet model\n",
    "            Args:\n",
    "                shape: (tuple):             input shape\n",
    "                batch_normalization (bool): use batch normalization\n",
    "                activation (str):           select which activation to use\n",
    "                dropout (float):            select the probability of dropout\n",
    "                amsgrad (bool):             use amsgrad for Adam optimizer\n",
    "                lr (float):                 learning rate\n",
    "            Returns:\n",
    "                resnet unet model object       \n",
    "        \"\"\"\n",
    "        self.shape = shape\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.amsgrad = amsgrad\n",
    "        self.lr = lr\n",
    "\n",
    "    def conv_act(self, inputs, out_filters, activation=\"relu\"):\n",
    "        \"\"\"Create a 2D convolutional layer with an activation\n",
    "            Args:\n",
    "                inputs (tensorflow.python.framework.ops.Tensor): inputs to the block\n",
    "                out_filters (int)                              : number of output filters\n",
    "                activation (str):                              : activation function\n",
    "            Returns:\n",
    "                A tensorflow.python.framework.ops.Tensor object\n",
    "        \"\"\"\n",
    "        return Conv2D(\n",
    "            filters=out_filters,\n",
    "            activation=activation,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "        )(inputs)\n",
    "\n",
    "    def decoder(\n",
    "        self,\n",
    "        inputs,\n",
    "        mid_filters=512,\n",
    "        out_filters=256,\n",
    "        activation=\"relu\",\n",
    "        block_name=\"decoder\",\n",
    "    ):\n",
    "        \"\"\" Create a decoder block\n",
    "            Args:\n",
    "                inputs (tensorflow.python.framework.ops.Tensor): inputs to the block\n",
    "                mid_filters (int):                             : number of mid filters\n",
    "                out_filters (int)                              : number of output filters\n",
    "                activation (str):                              : activation function\n",
    "                block_name (str):                              : name of the block to use\n",
    "            Returns:\n",
    "                A tensorflow.python.framework.ops.Tensor object\n",
    "        \"\"\"    \n",
    "        with K.name_scope(block_name):\n",
    "            if activation == \"leaky_relu\":\n",
    "                activation = None\n",
    "                conv = LeakyReLU(alpha=0.3)(\n",
    "                    self.conv_act(inputs, mid_filters, activation)\n",
    "                )\n",
    "            else:\n",
    "                conv = self.conv_act(inputs, mid_filters, activation)\n",
    "            conv_tr = Conv2DTranspose(\n",
    "                filters=out_filters,\n",
    "                activation=activation,\n",
    "                kernel_size=4,\n",
    "                strides=2,\n",
    "                padding=\"same\",\n",
    "            )(conv)\n",
    "        return conv_tr\n",
    "\n",
    "    def create_resnet_unet_model(self):ke\n",
    "        # Set max pooling parameters\n",
    "        max_pooling_size = 2\n",
    "        max_pooling_strd = 2\n",
    "\n",
    "        # load a pretrained ResNet\n",
    "        num_classes = 2\n",
    "        resnet50 = ResNet50(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            classes=num_classes,\n",
    "            input_shape=self.shape,\n",
    "        )\n",
    "\n",
    "        resnet50.compile(\n",
    "            optimizer=Adam(lr=self.lr, amsgrad=self.amsgrad), loss=\"binary_crossentropy\"\n",
    "        )\n",
    "\n",
    "        # ResNet convolution outputs\n",
    "        conv5_out = resnet50.get_layer(\"conv5_block3_out\").output\n",
    "        conv4_out = resnet50.get_layer(\"conv4_block6_out\").output\n",
    "        conv3_out = resnet50.get_layer(\"conv3_block4_out\").output\n",
    "        conv2_out = resnet50.get_layer(\"conv2_block3_out\").output\n",
    "\n",
    "        pool = MaxPooling2D(max_pooling_size, strides=max_pooling_strd, padding=\"same\")(\n",
    "            resnet50.get_output_at(0)\n",
    "        )\n",
    "        \n",
    "        dec_center = self.decoder(\n",
    "            pool,\n",
    "            mid_filters=self.shape[0] * 2,\n",
    "            out_filters=self.shape[0],\n",
    "            activation=self.activation,\n",
    "            block_name=\"decoder_center\",\n",
    "        )\n",
    "        \n",
    "        if self.batch_normalization:\n",
    "            dec_center = BatchNormalization()(dec_center)\n",
    "        if self.dropout > 0:\n",
    "            dec_center = Dropout(dropout)(dec_center)\n",
    "        \n",
    "        cat1 = Concatenate()([dec_center, conv5_out])\n",
    "        dec5 = self.decoder(\n",
    "            cat1,\n",
    "            mid_filters=int(self.shape[0] * 2),\n",
    "            out_filters=int(self.shape[0]),\n",
    "            activation=self.activation,\n",
    "            block_name=\"decoder5\",\n",
    "        )\n",
    "        \n",
    "        if self.batch_normalization:\n",
    "            dec5 = BatchNormalization()(dec5)\n",
    "        if self.dropout > 0:\n",
    "            dec5 = Dropout(self.dropout)(dec5)\n",
    "\n",
    "        cat2 = Concatenate()([dec5, conv4_out])\n",
    "        dec4 = self.decoder(\n",
    "            cat2,\n",
    "            mid_filters=int(self.shape[0] * 2),\n",
    "            out_filters=int(self.shape[0]),\n",
    "            activation=self.activation,\n",
    "            block_name=\"decoder4\",\n",
    "        )\n",
    "        \n",
    "        if self.batch_normalization:\n",
    "            dec4 = BatchNormalization()(dec4)\n",
    "        if self.dropout > 0:\n",
    "            dec4 = Dropout(self.dropout)(dec4)\n",
    "   \n",
    "        cat3 = Concatenate()([dec4, conv3_out])\n",
    "        dec3 = self.decoder(\n",
    "            cat3,\n",
    "            mid_filters=int(self.shape[0]),\n",
    "            out_filters=int(self.shape[0] // 4),\n",
    "            activation=self.activation,\n",
    "            block_name=\"decoder3\",\n",
    "        )\n",
    "        \n",
    "        if self.batch_normalization:\n",
    "            dec3 = BatchNormalization()(dec3)\n",
    "        if self.dropout > 0:\n",
    "            dec3 = Dropout(self.dropout)(dec3)\n",
    "        \n",
    "        cat2 = Concatenate()([dec3, conv2_out])\n",
    "        dec2 = self.decoder(\n",
    "            cat2,\n",
    "            mid_filters=int(self.shape[0] // 2),\n",
    "            out_filters=int(self.shape[0] // 2),\n",
    "            activation=self.activation,\n",
    "            block_name=\"decoder2\",\n",
    "        )\n",
    "       \n",
    "        if self.batch_normalization:\n",
    "            dec2 = BatchNormalization()(dec2)\n",
    "        if dropout > 0:\n",
    "            dec2 = Dropout(self.dropout)(dec2)\n",
    "            \n",
    "        dec1 = self.decoder(\n",
    "            dec2,\n",
    "            mid_filters=int(self.shape[0] // 2),\n",
    "            out_filters=int(self.shape[0] // 8),\n",
    "            activation=self.activation,\n",
    "            block_name=\"decoder1\",\n",
    "        )\n",
    "        if self.batch_normalization:\n",
    "            dec1 = BatchNormalization()(dec1)\n",
    "        if self.dropout > 0:\n",
    "            dec1 = Dropout(self.dropout)(dec1)\n",
    "\n",
    "        dec0 = self.conv_act(dec1, out_filters=int(self.shape[0] // 8))\n",
    "        conv_f = Conv2D(1, 1, activation=\"sigmoid\", padding=\"same\")(dec0)\n",
    "        flatten_0 = Flatten()(conv_f)\n",
    "        dense_0 = Dense(\n",
    "            self.shape[0] / 2,\n",
    "            kernel_regularizer=l2(1e-6),\n",
    "            activity_regularizer=l2(1e-6),\n",
    "        )(flatten_0)\n",
    "        dropout_0 = Dropout(0.5)(dense_0)\n",
    "        lk_relu_0 = LeakyReLU(alpha=0.1)(dropout_0)\n",
    "        dense_1 = Dense(2, kernel_regularizer=l2(3e-6), activity_regularizer=l2(1e-6))(\n",
    "            lk_relu_0\n",
    "        )\n",
    "        dropout_1 = Dropout(0.2)(dense_1)\n",
    "        output = Activation(\"sigmoid\")(dropout_1)\n",
    "        model = Model(inputs=resnet50.get_input_at(0), outputs=output)\n",
    "\n",
    "        # Compile the model using the Adam optimizer with accuracy, recall and f1 metrics\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=Adam(lr=lr, amsgrad=self.amsgrad),\n",
    "            metrics=[\"accuracy\", recall, f1],\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        epochs,\n",
    "        steps_per_epoch,\n",
    "        n_train=85,\n",
    "        n_val=15,\n",
    "        batch_size=100,\n",
    "        data_aug_factor=1,\n",
    "    ):\n",
    "\n",
    "        # Reduce the learning rate of the model after 30 steps\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor=\"loss\", factor=0.5, patience=10, verbose=1, mode=\"auto\"\n",
    "        )\n",
    "\n",
    "        # Save the best model\n",
    "        weights_filename = \"model_\"\n",
    "        if self.batch_normalization:\n",
    "            weights_filename = weights_filename + \"batch_\"\n",
    "        weights_filename = (\n",
    "            weights_filename\n",
    "            + self.activation\n",
    "            + \"_\"\n",
    "            + str(epochs)\n",
    "            + \"_\"\n",
    "            + \"dropout_\"\n",
    "            + str(self.dropout)\n",
    "            + \"_\"\n",
    "            + \"{epoch:03d}_\"\n",
    "            + \"{f1:03f}_\"\n",
    "            + \"{val_accuracy:03f}.h5\"\n",
    "        )\n",
    "        save_best_model = ModelCheckpoint(\n",
    "            weights_filename,\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"auto\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        cbs = [save_best_model, reduce_lr]\n",
    "\n",
    "        # Train the model\n",
    "        history = self.model.fit_generator(\n",
    "            create_minibatch(\n",
    "                X_train,\n",
    "                Y_train,\n",
    "                data_aug_factor * n_train,\n",
    "                batch_size=batch_size,\n",
    "                patch_size=16,\n",
    "                width=400,\n",
    "            ),\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "            use_multiprocessing=False,\n",
    "            workers=1,\n",
    "            callbacks=cbs,\n",
    "            verbose=1,\n",
    "            validation_data=create_minibatch(\n",
    "                X_val,\n",
    "                Y_val,\n",
    "                data_aug_factor * n_val,\n",
    "                batch_size=batch_size,\n",
    "                patch_size=16,\n",
    "                width=400,\n",
    "            ),\n",
    "            validation_steps=steps_per_epoch,\n",
    "        )\n",
    "\n",
    "        return history\n",
    "\n",
    "    def classify_patches(self, X):\n",
    "        \"\"\"Classify Image as either road or not.\n",
    "        Args:\n",
    "            X (image): part of the image to classify\n",
    "        Returns:\n",
    "            Predictions : Predictions for each patch\n",
    "        \"\"\"\n",
    "        # Subdivide the images into blocks with a stride and patch_size of 16\n",
    "        img_patches = create_patches(X, 16, 16, padding=24)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict(img_patches)\n",
    "        predictions = (predictions[:, 0] < predictions[:, 1]) * 1\n",
    "\n",
    "        # Regroup patches into images\n",
    "        return predictions.reshape(X.shape[0], -1)\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"Loads Saved Model.\n",
    "        Args:\n",
    "           filename (string): name of the model\n",
    "           \n",
    "        \"\"\"\n",
    "        # Load the model (used for submission)\n",
    "        dependencies = {\"recall\": recall, \"f1\": f1}\n",
    "        self.model = load_model(filename, custom_objects=dependencies)\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"Saves trained model.\n",
    "        Args:\n",
    "           filename (string): name of the model\n",
    "           \n",
    "        \"\"\"\n",
    "        self.model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(64,64,3))\n",
    "conv_2d = tf.keras.layers.Conv2D(100,64,64)(inputs)\n",
    "print(type(inputs))\n",
    "print(type(conv_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_factor = 1\n",
    "batch_normalization = True\n",
    "activation = \"relu\"\n",
    "dropout = 0\n",
    "amsgrad = False\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "EPOCHS = 80\n",
    "STEPS_PER_EPOCH = 100\n",
    "batch_size = 100\n",
    "\n",
    "model = resnet_unet_model(\n",
    "    shape=(64, 64, 3),\n",
    "    batch_normalization=batch_normalization,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    amsgrad=amsgrad,\n",
    "    lr=lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.train(\n",
    "    EPOCHS, STEPS_PER_EPOCH, n_train, n_val, batch_size, data_aug_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history[\"loss\"][1:], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"][1:], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"][1:], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"][1:], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"Unet_batchnorm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "lr = 1e-4\n",
    "model = resnet_unet_model(\n",
    "    shape=(64, 64, 3),\n",
    "    batch_normalization=batch_normalization,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    amsgrad=amsgrad,\n",
    "    lr=lr,\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model.load(\"model_batch_relu_80_dropout_0_024_0.804204_0.920300.h5\")\n",
    "\n",
    "# We add all test images to an array, used later for generating a submission\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = \"data/test_set_images/test_\" + str(i) + \"/test_\" + str(i) + \".png\"\n",
    "    image_filenames.append(image_filename)\n",
    "\n",
    "# Set-up submission filename\n",
    "submission_filename = \"resnet_unet.csv\"\n",
    "\n",
    "# Generates the submission\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}